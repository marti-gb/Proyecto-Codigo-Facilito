{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551de785-5e7d-4ff3-91e0-a50afa034a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33128.4141 - mae: 182.0023 - val_loss: 9566.4961 - val_mae: 97.7980\n",
      "Epoch 2/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8567.6621 - mae: 92.5126 - val_loss: 25399.6582 - val_mae: 159.3652\n",
      "Epoch 3/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 23628.1484 - mae: 153.6812 - val_loss: 9392.0811 - val_mae: 96.8999\n",
      "Epoch 4/3000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 8515.1377 - mae: 92.2335 - val_loss: 2.7706 - val_mae: 1.5563\n",
      "Epoch 5/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 15.9867 - mae: 3.1410 - val_loss: 6085.4966 - val_mae: 77.9987\n",
      "Epoch 6/3000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 6625.3926 - mae: 81.3645 - val_loss: 10912.6523 - val_mae: 104.4561\n",
      "Epoch 7/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 11594.6230 - mae: 107.6558 - val_loss: 6591.8643 - val_mae: 81.1802\n",
      "Epoch 8/3000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 7161.8521 - mae: 84.5969 - val_loss: 822.4640 - val_mae: 28.6468\n",
      "Epoch 9/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1063.2130 - mae: 32.5137 - val_loss: 887.2181 - val_mae: 29.7516\n",
      "Epoch 10/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 652.0719 - mae: 25.3962 - val_loss: 5175.7798 - val_mae: 71.9273\n",
      "Epoch 11/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 4526.9648 - mae: 67.2240 - val_loss: 7129.0728 - val_mae: 84.4203\n",
      "Epoch 12/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 6346.9731 - mae: 79.6168 - val_loss: 4557.8682 - val_mae: 67.4957\n",
      "Epoch 13/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3955.9131 - mae: 62.8340 - val_loss: 970.8108 - val_mae: 31.1257\n",
      "Epoch 14/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 723.3966 - mae: 26.7633 - val_loss: 112.7977 - val_mae: 10.5358\n",
      "Epoch 15/3000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 218.2971 - mae: 14.5572 - val_loss: 1856.7662 - val_mae: 43.0712\n",
      "Epoch 16/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2198.6699 - mae: 46.8276 - val_loss: 3179.9094 - val_mae: 56.3768\n",
      "Epoch 17/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3608.5771 - mae: 60.0246 - val_loss: 2326.0425 - val_mae: 48.2124\n",
      "Epoch 18/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2701.8884 - mae: 51.9243 - val_loss: 563.2092 - val_mae: 23.6959\n",
      "Epoch 19/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 768.0182 - mae: 27.6020 - val_loss: 59.6725 - val_mae: 7.6034\n",
      "Epoch 20/3000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 18.5747 - mae: 3.6219 - val_loss: 1213.0894 - val_mae: 34.8008\n",
      "Epoch 21/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 933.5494 - mae: 30.4370 - val_loss: 2416.8787 - val_mae: 49.1407\n",
      "Epoch 22/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2002.8385 - mae: 44.6705 - val_loss: 2213.1980 - val_mae: 47.0227\n",
      "Epoch 23/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1820.1760 - mae: 42.5775 - val_loss: 948.4082 - val_mae: 30.7641\n",
      "Epoch 24/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 706.9331 - mae: 26.4557 - val_loss: 51.9084 - val_mae: 7.0746\n",
      "Epoch 25/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 15.3765 - mae: 3.2888 - val_loss: 240.4979 - val_mae: 15.4516\n",
      "Epoch 26/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 381.8461 - mae: 19.3810 - val_loss: 855.1222 - val_mae: 29.2137\n",
      "Epoch 27/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1096.8934 - mae: 33.0288 - val_loss: 915.4622 - val_mae: 30.2289\n",
      "Epoch 28/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1164.0343 - mae: 34.0304 - val_loss: 373.8268 - val_mae: 19.2898\n",
      "Epoch 29/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 543.0521 - mae: 23.1714 - val_loss: 3.3246 - val_mae: 1.3795\n",
      "Epoch 30/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 33.9044 - mae: 5.2419 - val_loss: 292.8531 - val_mae: 17.0567\n",
      "Epoch 31/3000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 173.2095 - mae: 12.9028 - val_loss: 845.3839 - val_mae: 29.0412\n",
      "Epoch 32/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 621.9650 - mae: 24.8000 - val_loss: 959.6391 - val_mae: 30.9456\n",
      "Epoch 33/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 719.6396 - mae: 26.6963 - val_loss: 528.2642 - val_mae: 22.9412\n",
      "Epoch 34/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 358.7757 - mae: 18.7610 - val_loss: 78.8107 - val_mae: 8.7701\n",
      "Epoch 35/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 28.7067 - mae: 4.7069 - val_loss: 36.2248 - val_mae: 5.8653\n",
      "Epoch 36/3000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 102.5077 - mae: 9.8085 - val_loss: 241.8238 - val_mae: 15.4935\n",
      "Epoch 37/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 380.7863 - mae: 19.3559 - val_loss: 287.9145 - val_mae: 16.9157\n",
      "Epoch 38/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 437.1404 - mae: 20.7614 - val_loss: 107.5823 - val_mae: 10.2844\n",
      "Epoch 39/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 207.1618 - mae: 14.1759 - val_loss: 3.3219 - val_mae: 1.7014\n",
      "Epoch 40/3000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 14.0793 - mae: 2.8700 - val_loss: 163.7592 - val_mae: 12.7206\n",
      "Epoch 41/3000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 81.6083 - mae: 8.6624 - val_loss: 393.2348 - val_mae: 19.7799\n",
      "Epoch 42/3000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 252.3214 - mae: 15.6729 - val_loss: 400.6565 - val_mae: 19.9664\n",
      "Epoch 43/3000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 258.3379 - mae: 15.8638 - val_loss: 191.7970 - val_mae: 13.7778\n",
      "Epoch 44/3000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 101.2231 - mae: 9.7292 - val_loss: 19.7074 - val_mae: 4.2172\n",
      "Epoch 45/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 6.4617 - mae: 2.2430 - val_loss: 22.8211 - val_mae: 4.5761\n",
      "Epoch 46/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 78.0122 - mae: 8.4713 - val_loss: 84.2636 - val_mae: 9.0775\n",
      "Epoch 47/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 173.4145 - mae: 12.9323 - val_loss: 62.5925 - val_mae: 7.7922\n",
      "Epoch 48/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 141.9350 - mae: 11.6513 - val_loss: 4.9428 - val_mae: 1.7901\n",
      "Epoch 49/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 38.0916 - mae: 5.6407 - val_loss: 39.6794 - val_mae: 6.1414\n",
      "Epoch 50/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 11.1748 - mae: 2.8630 - val_loss: 154.8396 - val_mae: 12.3627\n",
      "Epoch 51/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 76.4592 - mae: 8.3647 - val_loss: 209.3884 - val_mae: 14.4001\n",
      "Epoch 52/3000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 114.5185 - mae: 10.3924 - val_loss: 139.5065 - val_mae: 11.7257\n",
      "Epoch 53/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 66.4371 - mae: 7.7441 - val_loss: 36.7434 - val_mae: 5.8955\n",
      "Epoch 54/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 10.2235 - mae: 2.7683 - val_loss: 2.0330 - val_mae: 1.0064\n",
      "Epoch 55/3000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 23.4746 - mae: 4.1495 - val_loss: 18.1225 - val_mae: 4.0222\n",
      "Epoch 56/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 68.0501 - mae: 7.8652 - val_loss: 17.0726 - val_mae: 3.8885\n",
      "Epoch 57/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 65.8902 - mae: 7.7269 - val_loss: 2.0479 - val_mae: 1.0071\n",
      "Epoch 58/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 23.2428 - mae: 4.1239 - val_loss: 26.1291 - val_mae: 4.9104\n",
      "Epoch 59/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 7.3435 - mae: 2.4261 - val_loss: 85.4470 - val_mae: 9.1320\n",
      "Epoch 60/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 33.5236 - mae: 5.2105 - val_loss: 113.0209 - val_mae: 10.5333\n",
      "Epoch 61/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 50.0417 - mae: 6.6069 - val_loss: 77.7796 - val_mae: 8.7013\n",
      "Epoch 62/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 29.3416 - mae: 4.7946 - val_loss: 24.7833 - val_mae: 4.7682\n",
      "Epoch 63/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 7.0879 - mae: 2.3815 - val_loss: 2.6193 - val_mae: 1.5101\n",
      "Epoch 64/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 15.6156 - mae: 3.0996 - val_loss: 3.9575 - val_mae: 1.5287\n",
      "Epoch 65/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 33.2526 - mae: 5.2040 - val_loss: 2.7325 - val_mae: 1.1510\n",
      "Epoch 66/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 27.7711 - mae: 4.6473 - val_loss: 5.7807 - val_mae: 2.1642\n",
      "Epoch 67/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 9.8128 - mae: 2.4495 - val_loss: 30.8597 - val_mae: 5.3634\n",
      "Epoch 68/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.5599 - mae: 2.5759 - val_loss: 61.7541 - val_mae: 7.7223\n",
      "Epoch 69/3000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 21.2195 - mae: 3.9453 - val_loss: 65.0206 - val_mae: 7.9304\n",
      "Epoch 70/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 22.9018 - mae: 4.1310 - val_loss: 38.9430 - val_mae: 6.0679\n",
      "Epoch 71/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 11.2387 - mae: 2.8520 - val_loss: 12.6452 - val_mae: 3.2457\n",
      "Epoch 72/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.5157 - mae: 2.1471 - val_loss: 3.0413 - val_mae: 1.6442\n",
      "Epoch 73/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 14.0853 - mae: 2.9083 - val_loss: 2.2244 - val_mae: 1.2989\n",
      "Epoch 74/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 17.8997 - mae: 3.4291 - val_loss: 4.5129 - val_mae: 1.9709\n",
      "Epoch 75/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 11.1343 - mae: 2.5938 - val_loss: 16.5094 - val_mae: 3.7897\n",
      "Epoch 76/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.1833 - mae: 2.1304 - val_loss: 36.0139 - val_mae: 5.8174\n",
      "Epoch 77/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 10.2865 - mae: 2.7509 - val_loss: 45.5586 - val_mae: 6.5858\n",
      "Epoch 78/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 13.9861 - mae: 3.1310 - val_loss: 35.8099 - val_mae: 5.7985\n",
      "Epoch 79/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 10.2444 - mae: 2.7449 - val_loss: 18.2315 - val_mae: 4.0063\n",
      "Epoch 80/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 6.2192 - mae: 2.1721 - val_loss: 7.2368 - val_mae: 2.3778\n",
      "Epoch 81/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 8.3755 - mae: 2.3401 - val_loss: 4.3222 - val_mae: 1.9423\n",
      "Epoch 82/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 11.2750 - mae: 2.6125 - val_loss: 6.1310 - val_mae: 2.2351\n",
      "Epoch 83/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 9.1749 - mae: 2.4013 - val_loss: 13.8402 - val_mae: 3.4106\n",
      "Epoch 84/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.2377 - mae: 2.1146 - val_loss: 26.0229 - val_mae: 4.8781\n",
      "Epoch 85/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 7.4286 - mae: 2.4161 - val_loss: 33.3111 - val_mae: 5.5741\n",
      "Epoch 86/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 9.4963 - mae: 2.6645 - val_loss: 29.0688 - val_mae: 5.1792\n",
      "Epoch 87/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 8.2203 - mae: 2.5170 - val_loss: 18.3003 - val_mae: 4.0071\n",
      "Epoch 88/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 6.1963 - mae: 2.1684 - val_loss: 9.9706 - val_mae: 2.7990\n",
      "Epoch 89/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.9501 - mae: 2.2055 - val_loss: 7.0443 - val_mae: 2.3656\n",
      "Epoch 90/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.3448 - mae: 2.3378 - val_loss: 8.5686 - val_mae: 2.5932\n",
      "Epoch 91/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.4704 - mae: 2.2568 - val_loss: 14.3642 - val_mae: 3.4778\n",
      "Epoch 92/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.1318 - mae: 2.1009 - val_loss: 22.2841 - val_mae: 4.4721\n",
      "Epoch 93/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.6940 - mae: 2.2892 - val_loss: 26.4725 - val_mae: 4.9170\n",
      "Epoch 94/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 7.5880 - mae: 2.4285 - val_loss: 23.4686 - val_mae: 4.6009\n",
      "Epoch 95/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 6.9196 - mae: 2.3296 - val_loss: 16.5374 - val_mae: 3.7731\n",
      "Epoch 96/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.0765 - mae: 2.1150 - val_loss: 11.0716 - val_mae: 2.9614\n",
      "Epoch 97/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.5428 - mae: 2.1609 - val_loss: 9.2709 - val_mae: 2.6999\n",
      "Epoch 98/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.0733 - mae: 2.2186 - val_loss: 11.0158 - val_mae: 2.9496\n",
      "Epoch 99/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 6.5330 - mae: 2.1602 - val_loss: 15.6332 - val_mae: 3.6476\n",
      "Epoch 100/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.0437 - mae: 2.0977 - val_loss: 20.6335 - val_mae: 4.2770\n",
      "Epoch 101/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.4388 - mae: 2.2301 - val_loss: 22.2598 - val_mae: 4.4621\n",
      "Epoch 102/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.7087 - mae: 2.2864 - val_loss: 19.3931 - val_mae: 4.1279\n",
      "Epoch 103/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.2735 - mae: 2.1918 - val_loss: 14.7547 - val_mae: 3.5212\n",
      "Epoch 104/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 6.0328 - mae: 2.0897 - val_loss: 11.5648 - val_mae: 3.0342\n",
      "Epoch 105/3000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 6.3527 - mae: 2.1361 - val_loss: 11.0763 - val_mae: 2.9524\n",
      "Epoch 106/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 6.4421 - mae: 2.1498 - val_loss: 13.1600 - val_mae: 3.2842\n",
      "Epoch 107/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.1096 - mae: 2.0962 - val_loss: 16.7088 - val_mae: 3.7847\n",
      "Epoch 108/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.0353 - mae: 2.1149 - val_loss: 19.3887 - val_mae: 4.1224\n",
      "Epoch 109/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 6.2702 - mae: 2.1878 - val_loss: 19.1895 - val_mae: 4.0974\n",
      "Epoch 110/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.2452 - mae: 2.1811 - val_loss: 16.5051 - val_mae: 3.7551\n",
      "Epoch 111/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.0156 - mae: 2.1090 - val_loss: 13.5464 - val_mae: 3.3375\n",
      "Epoch 112/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.0400 - mae: 2.0851 - val_loss: 12.1056 - val_mae: 3.1134\n",
      "Epoch 113/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.1867 - mae: 2.1107 - val_loss: 12.6899 - val_mae: 3.2047\n",
      "Epoch 114/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.1033 - mae: 2.0986 - val_loss: 14.8236 - val_mae: 3.5207\n",
      "Epoch 115/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.9695 - mae: 2.0857 - val_loss: 17.1343 - val_mae: 3.8336\n",
      "Epoch 116/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.0374 - mae: 2.1234 - val_loss: 17.9523 - val_mae: 3.9380\n",
      "Epoch 117/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.1039 - mae: 2.1430 - val_loss: 16.7497 - val_mae: 3.7816\n",
      "Epoch 118/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.0071 - mae: 2.1134 - val_loss: 14.6128 - val_mae: 3.4871\n",
      "Epoch 119/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.9518 - mae: 2.0824 - val_loss: 13.0653 - val_mae: 3.2570\n",
      "Epoch 120/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.0217 - mae: 2.0859 - val_loss: 12.9189 - val_mae: 3.2335\n",
      "Epoch 121/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 6.0275 - mae: 2.0877 - val_loss: 14.0975 - val_mae: 3.4098\n",
      "Epoch 122/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.9485 - mae: 2.0766 - val_loss: 15.7779 - val_mae: 3.6468\n",
      "Epoch 123/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.9457 - mae: 2.0956 - val_loss: 16.7534 - val_mae: 3.7773\n",
      "Epoch 124/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.9926 - mae: 2.1123 - val_loss: 16.3301 - val_mae: 3.7201\n",
      "Epoch 125/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.9641 - mae: 2.1053 - val_loss: 14.9393 - val_mae: 3.5276\n",
      "Epoch 126/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9174 - mae: 2.0831 - val_loss: 13.6490 - val_mae: 3.3391\n",
      "Epoch 127/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.9385 - mae: 2.0732 - val_loss: 13.2548 - val_mae: 3.2788\n",
      "Epoch 128/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.9549 - mae: 2.0761 - val_loss: 13.8842 - val_mae: 3.3725\n",
      "Epoch 129/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.9178 - mae: 2.0722 - val_loss: 15.0372 - val_mae: 3.5383\n",
      "Epoch 130/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.9021 - mae: 2.0831 - val_loss: 15.8624 - val_mae: 3.6522\n",
      "Epoch 131/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.9238 - mae: 2.0976 - val_loss: 15.7557 - val_mae: 3.6368\n",
      "Epoch 132/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.9162 - mae: 2.0958 - val_loss: 14.8635 - val_mae: 3.5114\n",
      "Epoch 133/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.8882 - mae: 2.0801 - val_loss: 13.8946 - val_mae: 3.3700\n",
      "Epoch 134/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 5.8917 - mae: 2.0708 - val_loss: 13.4949 - val_mae: 3.3095\n",
      "Epoch 135/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.9012 - mae: 2.0704 - val_loss: 13.8465 - val_mae: 3.3613\n",
      "Epoch 136/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.8832 - mae: 2.0704 - val_loss: 14.6309 - val_mae: 3.4752\n",
      "Epoch 137/3000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 5.8705 - mae: 2.0764 - val_loss: 15.2426 - val_mae: 3.5613\n",
      "Epoch 138/3000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 5.8787 - mae: 2.0871 - val_loss: 15.2219 - val_mae: 3.5577\n",
      "Epoch 139/3000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 5.8749 - mae: 2.0867 - val_loss: 14.6225 - val_mae: 3.4719\n",
      "Epoch 140/3000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 5.8590 - mae: 2.0760 - val_loss: 13.9256 - val_mae: 3.3694\n",
      "Epoch 141/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.8578 - mae: 2.0693 - val_loss: 13.6131 - val_mae: 3.3221\n",
      "Epoch 142/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.8610 - mae: 2.0689 - val_loss: 13.8404 - val_mae: 3.3554\n",
      "Epoch 143/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.8505 - mae: 2.0688 - val_loss: 14.3817 - val_mae: 3.4343\n",
      "Epoch 144/3000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 5.8422 - mae: 2.0717 - val_loss: 14.7995 - val_mae: 3.4939\n",
      "Epoch 145/3000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.8444 - mae: 2.0793 - val_loss: 14.7699 - val_mae: 3.4890\n",
      "Epoch 146/3000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.8405 - mae: 2.0788 - val_loss: 14.3375 - val_mae: 3.4259\n",
      "Epoch 147/3000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.8308 - mae: 2.0709 - val_loss: 13.8465 - val_mae: 3.3529\n",
      "Epoch 148/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.8288 - mae: 2.0675 - val_loss: 13.6399 - val_mae: 3.3214\n",
      "Epoch 149/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.8282 - mae: 2.0672 - val_loss: 13.8175 - val_mae: 3.3473\n",
      "Epoch 150/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.8209 - mae: 2.0670 - val_loss: 14.1965 - val_mae: 3.4028\n",
      "Epoch 151/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.8154 - mae: 2.0683 - val_loss: 14.4571 - val_mae: 3.4402\n",
      "Epoch 152/3000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 5.8148 - mae: 2.0731 - val_loss: 14.3905 - val_mae: 3.4300\n",
      "Epoch 153/3000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 5.8105 - mae: 2.0719 - val_loss: 14.0590 - val_mae: 3.3808\n",
      "Epoch 154/3000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 5.8041 - mae: 2.0668 - val_loss: 13.7217 - val_mae: 3.3300\n",
      "Epoch 155/3000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 5.8019 - mae: 2.0655 - val_loss: 13.6109 - val_mae: 3.3128\n",
      "Epoch 156/3000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.7993 - mae: 2.0652 - val_loss: 13.7671 - val_mae: 3.3357\n",
      "Epoch 157/3000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 5.7937 - mae: 2.0650 - val_loss: 14.0291 - val_mae: 3.3741\n",
      "Epoch 158/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.7899 - mae: 2.0668 - val_loss: 14.1671 - val_mae: 3.3940\n",
      "Epoch 159/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.7877 - mae: 2.0682 - val_loss: 14.0652 - val_mae: 3.3784\n",
      "Epoch 160/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.7833 - mae: 2.0673 - val_loss: 13.8062 - val_mae: 3.3394\n",
      "Epoch 161/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.7788 - mae: 2.0648 - val_loss: 13.5865 - val_mae: 3.3059\n",
      "Epoch 162/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.7763 - mae: 2.0634 - val_loss: 13.5509 - val_mae: 3.3000\n",
      "Epoch 163/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 5.7729 - mae: 2.0630 - val_loss: 13.6891 - val_mae: 3.3203\n",
      "Epoch 164/3000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.7683 - mae: 2.0638 - val_loss: 13.8591 - val_mae: 3.3453\n",
      "Epoch 165/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.7652 - mae: 2.0654 - val_loss: 13.9046 - val_mae: 3.3516\n",
      "Epoch 166/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.7623 - mae: 2.0659 - val_loss: 13.7815 - val_mae: 3.3328\n",
      "Epoch 167/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.7581 - mae: 2.0647 - val_loss: 13.5845 - val_mae: 3.3027\n",
      "Epoch 168/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.7546 - mae: 2.0628 - val_loss: 13.4567 - val_mae: 3.2828\n",
      "Epoch 169/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.7517 - mae: 2.0615 - val_loss: 13.4719 - val_mae: 3.2847\n",
      "Epoch 170/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.7480 - mae: 2.0617 - val_loss: 13.5856 - val_mae: 3.3015\n",
      "Epoch 171/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.7443 - mae: 2.0628 - val_loss: 13.6786 - val_mae: 3.3151\n",
      "Epoch 172/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.7413 - mae: 2.0636 - val_loss: 13.6589 - val_mae: 3.3117\n",
      "Epoch 173/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 5.7379 - mae: 2.0634 - val_loss: 13.5338 - val_mae: 3.2923\n",
      "Epoch 174/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.7343 - mae: 2.0622 - val_loss: 13.3952 - val_mae: 3.2708\n",
      "Epoch 175/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 5.7311 - mae: 2.0609 - val_loss: 13.3368 - val_mae: 3.2614\n",
      "Epoch 176/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.7280 - mae: 2.0603 - val_loss: 13.3786 - val_mae: 3.2673\n",
      "Epoch 177/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.7244 - mae: 2.0607 - val_loss: 13.4581 - val_mae: 3.2790\n",
      "Epoch 178/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.7212 - mae: 2.0614 - val_loss: 13.4879 - val_mae: 3.2831\n",
      "Epoch 179/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.7181 - mae: 2.0617 - val_loss: 13.4290 - val_mae: 3.2737\n",
      "Epoch 180/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.7148 - mae: 2.0611 - val_loss: 13.3195 - val_mae: 3.2566\n",
      "Epoch 181/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.7114 - mae: 2.0600 - val_loss: 13.2351 - val_mae: 3.2432\n",
      "Epoch 182/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.7084 - mae: 2.0591 - val_loss: 13.2237 - val_mae: 3.2410\n",
      "Epoch 183/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.7052 - mae: 2.0589 - val_loss: 13.2687 - val_mae: 3.2475\n",
      "Epoch 184/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.7019 - mae: 2.0593 - val_loss: 13.3087 - val_mae: 3.2533\n",
      "Epoch 185/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.6988 - mae: 2.0597 - val_loss: 13.2916 - val_mae: 3.2503\n",
      "Epoch 186/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.6957 - mae: 2.0595 - val_loss: 13.2187 - val_mae: 3.2387\n",
      "Epoch 187/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.6924 - mae: 2.0587 - val_loss: 13.1370 - val_mae: 3.2257\n",
      "Epoch 188/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.6894 - mae: 2.0578 - val_loss: 13.0975 - val_mae: 3.2191\n",
      "Epoch 189/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.6863 - mae: 2.0573 - val_loss: 13.1101 - val_mae: 3.2206\n",
      "Epoch 190/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.6831 - mae: 2.0574 - val_loss: 13.1406 - val_mae: 3.2248\n",
      "Epoch 191/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.6800 - mae: 2.0576 - val_loss: 13.1424 - val_mae: 3.2246\n",
      "Epoch 192/3000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.6770 - mae: 2.0576 - val_loss: 13.0980 - val_mae: 3.2173\n",
      "Epoch 193/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.6739 - mae: 2.0571 - val_loss: 13.0308 - val_mae: 3.2075\n",
      "Epoch 194/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.6708 - mae: 2.0563 - val_loss: 12.9817 - val_mae: 3.2015\n",
      "Epoch 195/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.6678 - mae: 2.0557 - val_loss: 12.9721 - val_mae: 3.2002\n",
      "Epoch 196/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.6648 - mae: 2.0555 - val_loss: 12.9879 - val_mae: 3.2021\n",
      "Epoch 197/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.6617 - mae: 2.0556 - val_loss: 12.9944 - val_mae: 3.2028\n",
      "Epoch 198/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.6588 - mae: 2.0556 - val_loss: 12.9683 - val_mae: 3.1996\n",
      "Epoch 199/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.6558 - mae: 2.0553 - val_loss: 12.9175 - val_mae: 3.1933\n",
      "Epoch 200/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.6528 - mae: 2.0547 - val_loss: 12.8703 - val_mae: 3.1875\n",
      "Epoch 201/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.6499 - mae: 2.0542 - val_loss: 12.8498 - val_mae: 3.1849\n",
      "Epoch 202/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.6471 - mae: 2.0540 - val_loss: 12.8535 - val_mae: 3.1853\n",
      "Epoch 203/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.6443 - mae: 2.0540 - val_loss: 12.8581 - val_mae: 3.1858\n",
      "Epoch 204/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.6415 - mae: 2.0541 - val_loss: 12.8417 - val_mae: 3.1837\n",
      "Epoch 205/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.6387 - mae: 2.0539 - val_loss: 12.8029 - val_mae: 3.1788\n",
      "Epoch 206/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.6359 - mae: 2.0535 - val_loss: 12.7609 - val_mae: 3.1736\n",
      "Epoch 207/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 5.6332 - mae: 2.0530 - val_loss: 12.7352 - val_mae: 3.1703\n",
      "Epoch 208/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.6304 - mae: 2.0528 - val_loss: 12.7296 - val_mae: 3.1696\n",
      "Epoch 209/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.6278 - mae: 2.0527 - val_loss: 12.7300 - val_mae: 3.1695\n",
      "Epoch 210/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.6251 - mae: 2.0527 - val_loss: 12.7175 - val_mae: 3.1679\n",
      "Epoch 211/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.6223 - mae: 2.0525 - val_loss: 12.6877 - val_mae: 3.1641\n",
      "Epoch 212/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.6196 - mae: 2.0522 - val_loss: 12.6515 - val_mae: 3.1595\n",
      "Epoch 213/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.6169 - mae: 2.0518 - val_loss: 12.6246 - val_mae: 3.1561\n",
      "Epoch 214/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.6143 - mae: 2.0515 - val_loss: 12.6134 - val_mae: 3.1546\n",
      "Epoch 215/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.6116 - mae: 2.0513 - val_loss: 12.6092 - val_mae: 3.1540\n",
      "Epoch 216/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.6090 - mae: 2.0512 - val_loss: 12.5981 - val_mae: 3.1525\n",
      "Epoch 217/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.6064 - mae: 2.0511 - val_loss: 12.5739 - val_mae: 3.1494\n",
      "Epoch 218/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 5.6037 - mae: 2.0508 - val_loss: 12.5428 - val_mae: 3.1454\n",
      "Epoch 219/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 5.6011 - mae: 2.0504 - val_loss: 12.5171 - val_mae: 3.1421\n",
      "Epoch 220/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5985 - mae: 2.0501 - val_loss: 12.5028 - val_mae: 3.1402\n",
      "Epoch 221/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.5959 - mae: 2.0499 - val_loss: 12.4951 - val_mae: 3.1392\n",
      "Epoch 222/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.5933 - mae: 2.0497 - val_loss: 12.4836 - val_mae: 3.1376\n",
      "Epoch 223/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.5907 - mae: 2.0496 - val_loss: 12.4627 - val_mae: 3.1349\n",
      "Epoch 224/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.5882 - mae: 2.0493 - val_loss: 12.4360 - val_mae: 3.1314\n",
      "Epoch 225/3000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 5.5856 - mae: 2.0489 - val_loss: 12.4121 - val_mae: 3.1283\n",
      "Epoch 226/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.5831 - mae: 2.0486 - val_loss: 12.3965 - val_mae: 3.1262\n",
      "Epoch 227/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.5805 - mae: 2.0484 - val_loss: 12.3864 - val_mae: 3.1249\n",
      "Epoch 228/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.5780 - mae: 2.0482 - val_loss: 12.3743 - val_mae: 3.1232\n",
      "Epoch 229/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.5755 - mae: 2.0480 - val_loss: 12.3554 - val_mae: 3.1207\n",
      "Epoch 230/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5729 - mae: 2.0477 - val_loss: 12.3317 - val_mae: 3.1177\n",
      "Epoch 231/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5704 - mae: 2.0474 - val_loss: 12.3099 - val_mae: 3.1150\n",
      "Epoch 232/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.5679 - mae: 2.0471 - val_loss: 12.2940 - val_mae: 3.1130\n",
      "Epoch 233/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.5654 - mae: 2.0468 - val_loss: 12.2825 - val_mae: 3.1116\n",
      "Epoch 234/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.5630 - mae: 2.0466 - val_loss: 12.2698 - val_mae: 3.1100\n",
      "Epoch 235/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.5605 - mae: 2.0464 - val_loss: 12.2521 - val_mae: 3.1078\n",
      "Epoch 236/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.5580 - mae: 2.0461 - val_loss: 12.2308 - val_mae: 3.1052\n",
      "Epoch 237/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.5555 - mae: 2.0458 - val_loss: 12.2108 - val_mae: 3.1027\n",
      "Epoch 238/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.5531 - mae: 2.0455 - val_loss: 12.1949 - val_mae: 3.1007\n",
      "Epoch 239/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.5506 - mae: 2.0452 - val_loss: 12.1827 - val_mae: 3.0992\n",
      "Epoch 240/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5482 - mae: 2.0450 - val_loss: 12.1695 - val_mae: 3.0975\n",
      "Epoch 241/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.5457 - mae: 2.0447 - val_loss: 12.1526 - val_mae: 3.0954\n",
      "Epoch 242/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.5433 - mae: 2.0444 - val_loss: 12.1331 - val_mae: 3.0929\n",
      "Epoch 243/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.5409 - mae: 2.0441 - val_loss: 12.1145 - val_mae: 3.0906\n",
      "Epoch 244/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.5385 - mae: 2.0438 - val_loss: 12.0993 - val_mae: 3.0887\n",
      "Epoch 245/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.5360 - mae: 2.0435 - val_loss: 12.0864 - val_mae: 3.0870\n",
      "Epoch 246/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5337 - mae: 2.0432 - val_loss: 12.0730 - val_mae: 3.0853\n",
      "Epoch 247/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5314 - mae: 2.0430 - val_loss: 12.0572 - val_mae: 3.0833\n",
      "Epoch 248/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.5291 - mae: 2.0428 - val_loss: 12.0396 - val_mae: 3.0811\n",
      "Epoch 249/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.5268 - mae: 2.0425 - val_loss: 12.0230 - val_mae: 3.0790\n",
      "Epoch 250/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.5246 - mae: 2.0423 - val_loss: 12.0086 - val_mae: 3.0772\n",
      "Epoch 251/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.5223 - mae: 2.0420 - val_loss: 11.9959 - val_mae: 3.0755\n",
      "Epoch 252/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.5200 - mae: 2.0418 - val_loss: 11.9825 - val_mae: 3.0738\n",
      "Epoch 253/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.5178 - mae: 2.0416 - val_loss: 11.9670 - val_mae: 3.0719\n",
      "Epoch 254/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 5.5156 - mae: 2.0414 - val_loss: 11.9504 - val_mae: 3.0697\n",
      "Epoch 255/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 5.5134 - mae: 2.0411 - val_loss: 11.9351 - val_mae: 3.0678\n",
      "Epoch 256/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.5112 - mae: 2.0409 - val_loss: 11.9216 - val_mae: 3.0660\n",
      "Epoch 257/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.5090 - mae: 2.0406 - val_loss: 11.9089 - val_mae: 3.0644\n",
      "Epoch 258/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.5068 - mae: 2.0404 - val_loss: 11.8954 - val_mae: 3.0627\n",
      "Epoch 259/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.5046 - mae: 2.0402 - val_loss: 11.8802 - val_mae: 3.0607\n",
      "Epoch 260/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.5024 - mae: 2.0399 - val_loss: 11.8650 - val_mae: 3.0588\n",
      "Epoch 261/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.5002 - mae: 2.0397 - val_loss: 11.8506 - val_mae: 3.0569\n",
      "Epoch 262/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.4980 - mae: 2.0394 - val_loss: 11.8377 - val_mae: 3.0552\n",
      "Epoch 263/3000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 5.4959 - mae: 2.0392 - val_loss: 11.8251 - val_mae: 3.0536\n",
      "Epoch 264/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 5.4937 - mae: 2.0390 - val_loss: 11.8116 - val_mae: 3.0519\n",
      "Epoch 265/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.4916 - mae: 2.0387 - val_loss: 11.7972 - val_mae: 3.0500\n",
      "Epoch 266/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.4895 - mae: 2.0385 - val_loss: 11.7828 - val_mae: 3.0481\n",
      "Epoch 267/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.4873 - mae: 2.0382 - val_loss: 11.7692 - val_mae: 3.0464\n",
      "Epoch 268/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4852 - mae: 2.0380 - val_loss: 11.7565 - val_mae: 3.0447\n",
      "Epoch 269/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.4830 - mae: 2.0377 - val_loss: 11.7441 - val_mae: 3.0431\n",
      "Epoch 270/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.4809 - mae: 2.0375 - val_loss: 11.7311 - val_mae: 3.0414\n",
      "Epoch 271/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.4788 - mae: 2.0372 - val_loss: 11.7173 - val_mae: 3.0396\n",
      "Epoch 272/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.4767 - mae: 2.0370 - val_loss: 11.7035 - val_mae: 3.0378\n",
      "Epoch 273/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.4745 - mae: 2.0367 - val_loss: 11.6905 - val_mae: 3.0361\n",
      "Epoch 274/3000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 5.4724 - mae: 2.0364 - val_loss: 11.6785 - val_mae: 3.0345\n",
      "Epoch 275/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.4703 - mae: 2.0362 - val_loss: 11.6664 - val_mae: 3.0329\n",
      "Epoch 276/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.4682 - mae: 2.0360 - val_loss: 11.6536 - val_mae: 3.0312\n",
      "Epoch 277/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.4662 - mae: 2.0357 - val_loss: 11.6402 - val_mae: 3.0295\n",
      "Epoch 278/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.4640 - mae: 2.0354 - val_loss: 11.6274 - val_mae: 3.0278\n",
      "Epoch 279/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 5.4620 - mae: 2.0352 - val_loss: 11.6150 - val_mae: 3.0262\n",
      "Epoch 280/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.4599 - mae: 2.0349 - val_loss: 11.6032 - val_mae: 3.0246\n",
      "Epoch 281/3000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.4578 - mae: 2.0346 - val_loss: 11.5915 - val_mae: 3.0230\n",
      "Epoch 282/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.4558 - mae: 2.0344 - val_loss: 11.5793 - val_mae: 3.0214\n",
      "Epoch 283/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.4539 - mae: 2.0342 - val_loss: 11.5670 - val_mae: 3.0198\n",
      "Epoch 284/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.4519 - mae: 2.0339 - val_loss: 11.5549 - val_mae: 3.0182\n",
      "Epoch 285/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.4499 - mae: 2.0337 - val_loss: 11.5433 - val_mae: 3.0167\n",
      "Epoch 286/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4479 - mae: 2.0335 - val_loss: 11.5318 - val_mae: 3.0151\n",
      "Epoch 287/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.4460 - mae: 2.0332 - val_loss: 11.5204 - val_mae: 3.0136\n",
      "Epoch 288/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4439 - mae: 2.0330 - val_loss: 11.5086 - val_mae: 3.0121\n",
      "Epoch 289/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.4420 - mae: 2.0328 - val_loss: 11.4968 - val_mae: 3.0105\n",
      "Epoch 290/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.4400 - mae: 2.0325 - val_loss: 11.4852 - val_mae: 3.0089\n",
      "Epoch 291/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.4381 - mae: 2.0323 - val_loss: 11.4741 - val_mae: 3.0075\n",
      "Epoch 292/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.4361 - mae: 2.0320 - val_loss: 11.4630 - val_mae: 3.0060\n",
      "Epoch 293/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.4342 - mae: 2.0318 - val_loss: 11.4518 - val_mae: 3.0045\n",
      "Epoch 294/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 5.4322 - mae: 2.0316 - val_loss: 11.4405 - val_mae: 3.0030\n",
      "Epoch 295/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.4303 - mae: 2.0313 - val_loss: 11.4293 - val_mae: 3.0015\n",
      "Epoch 296/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4283 - mae: 2.0311 - val_loss: 11.4181 - val_mae: 3.0000\n",
      "Epoch 297/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4264 - mae: 2.0308 - val_loss: 11.4073 - val_mae: 2.9985\n",
      "Epoch 298/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.4244 - mae: 2.0306 - val_loss: 11.3967 - val_mae: 2.9971\n",
      "Epoch 299/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.4225 - mae: 2.0303 - val_loss: 11.3860 - val_mae: 2.9957\n",
      "Epoch 300/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4205 - mae: 2.0300 - val_loss: 11.3749 - val_mae: 2.9942\n",
      "Epoch 301/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.4186 - mae: 2.0298 - val_loss: 11.3642 - val_mae: 2.9927\n",
      "Epoch 302/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.4166 - mae: 2.0295 - val_loss: 11.3538 - val_mae: 2.9913\n",
      "Epoch 303/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.4147 - mae: 2.0293 - val_loss: 11.3433 - val_mae: 2.9899\n",
      "Epoch 304/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4127 - mae: 2.0290 - val_loss: 11.3328 - val_mae: 2.9885\n",
      "Epoch 305/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.4108 - mae: 2.0288 - val_loss: 11.3223 - val_mae: 2.9871\n",
      "Epoch 306/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.4089 - mae: 2.0285 - val_loss: 11.3117 - val_mae: 2.9856\n",
      "Epoch 307/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4069 - mae: 2.0282 - val_loss: 11.3013 - val_mae: 2.9842\n",
      "Epoch 308/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.4050 - mae: 2.0280 - val_loss: 11.2913 - val_mae: 2.9829\n",
      "Epoch 309/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.4031 - mae: 2.0277 - val_loss: 11.2814 - val_mae: 2.9815\n",
      "Epoch 310/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.4011 - mae: 2.0274 - val_loss: 11.2712 - val_mae: 2.9801\n",
      "Epoch 311/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.3992 - mae: 2.0272 - val_loss: 11.2609 - val_mae: 2.9788\n",
      "Epoch 312/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.3972 - mae: 2.0269 - val_loss: 11.2508 - val_mae: 2.9774\n",
      "Epoch 313/3000\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 5.3953 - mae: 2.0266 - val_loss: 11.2408 - val_mae: 2.9760\n",
      "Epoch 314/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 5.3934 - mae: 2.0264 - val_loss: 11.2311 - val_mae: 2.9747\n",
      "Epoch 315/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.3915 - mae: 2.0261 - val_loss: 11.2214 - val_mae: 2.9734\n",
      "Epoch 316/3000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 5.3895 - mae: 2.0258 - val_loss: 11.2115 - val_mae: 2.9720\n",
      "Epoch 317/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.3876 - mae: 2.0256 - val_loss: 11.2014 - val_mae: 2.9707\n",
      "Epoch 318/3000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 5.3857 - mae: 2.0253 - val_loss: 11.1918 - val_mae: 2.9693\n",
      "Epoch 319/3000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 5.3838 - mae: 2.0250 - val_loss: 11.1823 - val_mae: 2.9680\n",
      "Epoch 320/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.3818 - mae: 2.0247 - val_loss: 11.1728 - val_mae: 2.9668\n",
      "Epoch 321/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.3799 - mae: 2.0244 - val_loss: 11.1632 - val_mae: 2.9654\n",
      "Epoch 322/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.3779 - mae: 2.0242 - val_loss: 11.1537 - val_mae: 2.9641\n",
      "Epoch 323/3000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 5.3760 - mae: 2.0239 - val_loss: 11.1440 - val_mae: 2.9628\n",
      "Epoch 324/3000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.3741 - mae: 2.0236 - val_loss: 11.1347 - val_mae: 2.9615\n",
      "Epoch 325/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.3721 - mae: 2.0233 - val_loss: 11.1254 - val_mae: 2.9603\n",
      "Epoch 326/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.3702 - mae: 2.0230 - val_loss: 11.1160 - val_mae: 2.9590\n",
      "Epoch 327/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.3683 - mae: 2.0227 - val_loss: 11.1069 - val_mae: 2.9577\n",
      "Epoch 328/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.3663 - mae: 2.0224 - val_loss: 11.0976 - val_mae: 2.9564\n",
      "Epoch 329/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.3644 - mae: 2.0222 - val_loss: 11.0883 - val_mae: 2.9552\n",
      "Epoch 330/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.3624 - mae: 2.0219 - val_loss: 11.0791 - val_mae: 2.9539\n",
      "Epoch 331/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.3606 - mae: 2.0216 - val_loss: 11.0700 - val_mae: 2.9527\n",
      "Epoch 332/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.3586 - mae: 2.0213 - val_loss: 11.0611 - val_mae: 2.9514\n",
      "Epoch 333/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.3567 - mae: 2.0210 - val_loss: 11.0520 - val_mae: 2.9502\n",
      "Epoch 334/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3547 - mae: 2.0207 - val_loss: 11.0429 - val_mae: 2.9489\n",
      "Epoch 335/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.3528 - mae: 2.0204 - val_loss: 11.0338 - val_mae: 2.9477\n",
      "Epoch 336/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.3509 - mae: 2.0201 - val_loss: 11.0251 - val_mae: 2.9465\n",
      "Epoch 337/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.3489 - mae: 2.0198 - val_loss: 11.0163 - val_mae: 2.9453\n",
      "Epoch 338/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.3470 - mae: 2.0195 - val_loss: 11.0075 - val_mae: 2.9440\n",
      "Epoch 339/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.3450 - mae: 2.0192 - val_loss: 10.9986 - val_mae: 2.9428\n",
      "Epoch 340/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.3431 - mae: 2.0189 - val_loss: 10.9898 - val_mae: 2.9416\n",
      "Epoch 341/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.3412 - mae: 2.0186 - val_loss: 10.9810 - val_mae: 2.9404\n",
      "Epoch 342/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.3392 - mae: 2.0183 - val_loss: 10.9724 - val_mae: 2.9392\n",
      "Epoch 343/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.3373 - mae: 2.0180 - val_loss: 10.9638 - val_mae: 2.9380\n",
      "Epoch 344/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.3353 - mae: 2.0177 - val_loss: 10.9551 - val_mae: 2.9368\n",
      "Epoch 345/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3334 - mae: 2.0174 - val_loss: 10.9464 - val_mae: 2.9356\n",
      "Epoch 346/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.3314 - mae: 2.0171 - val_loss: 10.9377 - val_mae: 2.9344\n",
      "Epoch 347/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.3295 - mae: 2.0168 - val_loss: 10.9293 - val_mae: 2.9332\n",
      "Epoch 348/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.3275 - mae: 2.0164 - val_loss: 10.9210 - val_mae: 2.9321\n",
      "Epoch 349/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.3255 - mae: 2.0161 - val_loss: 10.9123 - val_mae: 2.9308\n",
      "Epoch 350/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.3236 - mae: 2.0158 - val_loss: 10.9038 - val_mae: 2.9297\n",
      "Epoch 351/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.3216 - mae: 2.0155 - val_loss: 10.8953 - val_mae: 2.9285\n",
      "Epoch 352/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.3197 - mae: 2.0152 - val_loss: 10.8870 - val_mae: 2.9273\n",
      "Epoch 353/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.3177 - mae: 2.0149 - val_loss: 10.8787 - val_mae: 2.9262\n",
      "Epoch 354/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.3157 - mae: 2.0145 - val_loss: 10.8704 - val_mae: 2.9250\n",
      "Epoch 355/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.3138 - mae: 2.0142 - val_loss: 10.8621 - val_mae: 2.9239\n",
      "Epoch 356/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.3118 - mae: 2.0139 - val_loss: 10.8537 - val_mae: 2.9227\n",
      "Epoch 357/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.3099 - mae: 2.0136 - val_loss: 10.8455 - val_mae: 2.9215\n",
      "Epoch 358/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.3079 - mae: 2.0133 - val_loss: 10.8372 - val_mae: 2.9204\n",
      "Epoch 359/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.3059 - mae: 2.0129 - val_loss: 10.8291 - val_mae: 2.9192\n",
      "Epoch 360/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.3040 - mae: 2.0126 - val_loss: 10.8209 - val_mae: 2.9181\n",
      "Epoch 361/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.3019 - mae: 2.0123 - val_loss: 10.8129 - val_mae: 2.9170\n",
      "Epoch 362/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.3000 - mae: 2.0120 - val_loss: 10.8046 - val_mae: 2.9158\n",
      "Epoch 363/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.2980 - mae: 2.0116 - val_loss: 10.7965 - val_mae: 2.9147\n",
      "Epoch 364/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.2960 - mae: 2.0113 - val_loss: 10.7885 - val_mae: 2.9136\n",
      "Epoch 365/3000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 5.2941 - mae: 2.0110 - val_loss: 10.7805 - val_mae: 2.9125\n",
      "Epoch 366/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.2921 - mae: 2.0107 - val_loss: 10.7726 - val_mae: 2.9114\n",
      "Epoch 367/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.2901 - mae: 2.0103 - val_loss: 10.7649 - val_mae: 2.9103\n",
      "Epoch 368/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.2881 - mae: 2.0100 - val_loss: 10.7567 - val_mae: 2.9091\n",
      "Epoch 369/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.2861 - mae: 2.0097 - val_loss: 10.7486 - val_mae: 2.9080\n",
      "Epoch 370/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.2841 - mae: 2.0093 - val_loss: 10.7407 - val_mae: 2.9069\n",
      "Epoch 371/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.2822 - mae: 2.0090 - val_loss: 10.7329 - val_mae: 2.9058\n",
      "Epoch 372/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.2802 - mae: 2.0087 - val_loss: 10.7253 - val_mae: 2.9047\n",
      "Epoch 373/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.2782 - mae: 2.0083 - val_loss: 10.7174 - val_mae: 2.9036\n",
      "Epoch 374/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.2762 - mae: 2.0080 - val_loss: 10.7094 - val_mae: 2.9025\n",
      "Epoch 375/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.2742 - mae: 2.0076 - val_loss: 10.7015 - val_mae: 2.9014\n",
      "Epoch 376/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.2722 - mae: 2.0073 - val_loss: 10.6938 - val_mae: 2.9003\n",
      "Epoch 377/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.2702 - mae: 2.0070 - val_loss: 10.6862 - val_mae: 2.8992\n",
      "Epoch 378/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.2682 - mae: 2.0066 - val_loss: 10.6784 - val_mae: 2.8981\n",
      "Epoch 379/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2662 - mae: 2.0063 - val_loss: 10.6706 - val_mae: 2.8970\n",
      "Epoch 380/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.2641 - mae: 2.0059 - val_loss: 10.6628 - val_mae: 2.8959\n",
      "Epoch 381/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.2622 - mae: 2.0056 - val_loss: 10.6552 - val_mae: 2.8949\n",
      "Epoch 382/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.2601 - mae: 2.0052 - val_loss: 10.6477 - val_mae: 2.8938\n",
      "Epoch 383/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.2582 - mae: 2.0049 - val_loss: 10.6400 - val_mae: 2.8927\n",
      "Epoch 384/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.2561 - mae: 2.0046 - val_loss: 10.6322 - val_mae: 2.8916\n",
      "Epoch 385/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.2541 - mae: 2.0042 - val_loss: 10.6246 - val_mae: 2.8905\n",
      "Epoch 386/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.2521 - mae: 2.0039 - val_loss: 10.6172 - val_mae: 2.8897\n",
      "Epoch 387/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.2501 - mae: 2.0035 - val_loss: 10.6097 - val_mae: 2.8889\n",
      "Epoch 388/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.2481 - mae: 2.0032 - val_loss: 10.6020 - val_mae: 2.8881\n",
      "Epoch 389/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.2461 - mae: 2.0028 - val_loss: 10.5943 - val_mae: 2.8873\n",
      "Epoch 390/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.2440 - mae: 2.0025 - val_loss: 10.5867 - val_mae: 2.8865\n",
      "Epoch 391/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.2420 - mae: 2.0021 - val_loss: 10.5794 - val_mae: 2.8857\n",
      "Epoch 392/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.2400 - mae: 2.0018 - val_loss: 10.5721 - val_mae: 2.8849\n",
      "Epoch 393/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2380 - mae: 2.0014 - val_loss: 10.5645 - val_mae: 2.8841\n",
      "Epoch 394/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.2359 - mae: 2.0010 - val_loss: 10.5570 - val_mae: 2.8833\n",
      "Epoch 395/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.2339 - mae: 2.0007 - val_loss: 10.5493 - val_mae: 2.8824\n",
      "Epoch 396/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.2319 - mae: 2.0003 - val_loss: 10.5420 - val_mae: 2.8817\n",
      "Epoch 397/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.2298 - mae: 2.0000 - val_loss: 10.5347 - val_mae: 2.8809\n",
      "Epoch 398/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2278 - mae: 1.9996 - val_loss: 10.5273 - val_mae: 2.8801\n",
      "Epoch 399/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.2257 - mae: 1.9992 - val_loss: 10.5196 - val_mae: 2.8792\n",
      "Epoch 400/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.2237 - mae: 1.9989 - val_loss: 10.5122 - val_mae: 2.8784\n",
      "Epoch 401/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.2216 - mae: 1.9985 - val_loss: 10.5047 - val_mae: 2.8776\n",
      "Epoch 402/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.2196 - mae: 1.9982 - val_loss: 10.4974 - val_mae: 2.8768\n",
      "Epoch 403/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.2175 - mae: 1.9978 - val_loss: 10.4901 - val_mae: 2.8760\n",
      "Epoch 404/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.2155 - mae: 1.9974 - val_loss: 10.4828 - val_mae: 2.8752\n",
      "Epoch 405/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.2135 - mae: 1.9971 - val_loss: 10.4752 - val_mae: 2.8744\n",
      "Epoch 406/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.2114 - mae: 1.9967 - val_loss: 10.4677 - val_mae: 2.8736\n",
      "Epoch 407/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.2093 - mae: 1.9963 - val_loss: 10.4606 - val_mae: 2.8728\n",
      "Epoch 408/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.2073 - mae: 1.9960 - val_loss: 10.4533 - val_mae: 2.8720\n",
      "Epoch 409/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.2053 - mae: 1.9956 - val_loss: 10.4460 - val_mae: 2.8711\n",
      "Epoch 410/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.2032 - mae: 1.9952 - val_loss: 10.4384 - val_mae: 2.8703\n",
      "Epoch 411/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.2012 - mae: 1.9949 - val_loss: 10.4312 - val_mae: 2.8695\n",
      "Epoch 412/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.1991 - mae: 1.9945 - val_loss: 10.4240 - val_mae: 2.8687\n",
      "Epoch 413/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.1970 - mae: 1.9941 - val_loss: 10.4167 - val_mae: 2.8679\n",
      "Epoch 414/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.1949 - mae: 1.9938 - val_loss: 10.4092 - val_mae: 2.8671\n",
      "Epoch 415/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.1929 - mae: 1.9934 - val_loss: 10.4020 - val_mae: 2.8662\n",
      "Epoch 416/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.1908 - mae: 1.9930 - val_loss: 10.3948 - val_mae: 2.8654\n",
      "Epoch 417/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.1887 - mae: 1.9926 - val_loss: 10.3876 - val_mae: 2.8646\n",
      "Epoch 418/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.1866 - mae: 1.9923 - val_loss: 10.3803 - val_mae: 2.8638\n",
      "Epoch 419/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1846 - mae: 1.9919 - val_loss: 10.3730 - val_mae: 2.8630\n",
      "Epoch 420/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.1825 - mae: 1.9915 - val_loss: 10.3657 - val_mae: 2.8621\n",
      "Epoch 421/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.1804 - mae: 1.9911 - val_loss: 10.3585 - val_mae: 2.8613\n",
      "Epoch 422/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.1783 - mae: 1.9908 - val_loss: 10.3514 - val_mae: 2.8605\n",
      "Epoch 423/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.1763 - mae: 1.9904 - val_loss: 10.3442 - val_mae: 2.8597\n",
      "Epoch 424/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.1741 - mae: 1.9900 - val_loss: 10.3369 - val_mae: 2.8589\n",
      "Epoch 425/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.1721 - mae: 1.9896 - val_loss: 10.3296 - val_mae: 2.8580\n",
      "Epoch 426/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.1700 - mae: 1.9893 - val_loss: 10.3224 - val_mae: 2.8572\n",
      "Epoch 427/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.1679 - mae: 1.9889 - val_loss: 10.3153 - val_mae: 2.8564\n",
      "Epoch 428/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.1659 - mae: 1.9885 - val_loss: 10.3081 - val_mae: 2.8556\n",
      "Epoch 429/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1638 - mae: 1.9881 - val_loss: 10.3008 - val_mae: 2.8547\n",
      "Epoch 430/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.1617 - mae: 1.9877 - val_loss: 10.2937 - val_mae: 2.8539\n",
      "Epoch 431/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.1595 - mae: 1.9873 - val_loss: 10.2864 - val_mae: 2.8531\n",
      "Epoch 432/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1574 - mae: 1.9870 - val_loss: 10.2794 - val_mae: 2.8523\n",
      "Epoch 433/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.1553 - mae: 1.9866 - val_loss: 10.2720 - val_mae: 2.8514\n",
      "Epoch 434/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.1532 - mae: 1.9862 - val_loss: 10.2648 - val_mae: 2.8506\n",
      "Epoch 435/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.1512 - mae: 1.9858 - val_loss: 10.2577 - val_mae: 2.8497\n",
      "Epoch 436/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.1490 - mae: 1.9854 - val_loss: 10.2505 - val_mae: 2.8489\n",
      "Epoch 437/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.1469 - mae: 1.9850 - val_loss: 10.2435 - val_mae: 2.8481\n",
      "Epoch 438/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.1448 - mae: 1.9846 - val_loss: 10.2364 - val_mae: 2.8473\n",
      "Epoch 439/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.1427 - mae: 1.9843 - val_loss: 10.2291 - val_mae: 2.8464\n",
      "Epoch 440/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.1406 - mae: 1.9839 - val_loss: 10.2219 - val_mae: 2.8456\n",
      "Epoch 441/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.1385 - mae: 1.9835 - val_loss: 10.2148 - val_mae: 2.8447\n",
      "Epoch 442/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.1363 - mae: 1.9831 - val_loss: 10.2078 - val_mae: 2.8439\n",
      "Epoch 443/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.1342 - mae: 1.9827 - val_loss: 10.2007 - val_mae: 2.8431\n",
      "Epoch 444/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.1321 - mae: 1.9823 - val_loss: 10.1934 - val_mae: 2.8422\n",
      "Epoch 445/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.1300 - mae: 1.9819 - val_loss: 10.1861 - val_mae: 2.8414\n",
      "Epoch 446/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.1278 - mae: 1.9815 - val_loss: 10.1790 - val_mae: 2.8405\n",
      "Epoch 447/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.1257 - mae: 1.9811 - val_loss: 10.1720 - val_mae: 2.8397\n",
      "Epoch 448/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.1236 - mae: 1.9807 - val_loss: 10.1649 - val_mae: 2.8389\n",
      "Epoch 449/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.1215 - mae: 1.9803 - val_loss: 10.1575 - val_mae: 2.8380\n",
      "Epoch 450/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.1194 - mae: 1.9799 - val_loss: 10.1504 - val_mae: 2.8372\n",
      "Epoch 451/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1172 - mae: 1.9795 - val_loss: 10.1435 - val_mae: 2.8363\n",
      "Epoch 452/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.1151 - mae: 1.9792 - val_loss: 10.1363 - val_mae: 2.8355\n",
      "Epoch 453/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.1129 - mae: 1.9788 - val_loss: 10.1291 - val_mae: 2.8346\n",
      "Epoch 454/3000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 5.1108 - mae: 1.9784 - val_loss: 10.1220 - val_mae: 2.8338\n",
      "Epoch 455/3000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 5.1087 - mae: 1.9780 - val_loss: 10.1149 - val_mae: 2.8329\n",
      "Epoch 456/3000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 5.1066 - mae: 1.9776 - val_loss: 10.1078 - val_mae: 2.8321\n",
      "Epoch 457/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.1044 - mae: 1.9772 - val_loss: 10.1006 - val_mae: 2.8312\n",
      "Epoch 458/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.1022 - mae: 1.9768 - val_loss: 10.0935 - val_mae: 2.8304\n",
      "Epoch 459/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.1001 - mae: 1.9764 - val_loss: 10.0864 - val_mae: 2.8295\n",
      "Epoch 460/3000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.0980 - mae: 1.9760 - val_loss: 10.0792 - val_mae: 2.8286\n",
      "Epoch 461/3000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 5.0958 - mae: 1.9756 - val_loss: 10.0722 - val_mae: 2.8278\n",
      "Epoch 462/3000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.0937 - mae: 1.9752 - val_loss: 10.0651 - val_mae: 2.8269\n",
      "Epoch 463/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.0915 - mae: 1.9748 - val_loss: 10.0580 - val_mae: 2.8261\n",
      "Epoch 464/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0894 - mae: 1.9744 - val_loss: 10.0506 - val_mae: 2.8252\n",
      "Epoch 465/3000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 5.0872 - mae: 1.9740 - val_loss: 10.0435 - val_mae: 2.8244\n",
      "Epoch 466/3000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 5.0851 - mae: 1.9736 - val_loss: 10.0366 - val_mae: 2.8235\n",
      "Epoch 467/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 5.0829 - mae: 1.9732 - val_loss: 10.0295 - val_mae: 2.8227\n",
      "Epoch 468/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.0808 - mae: 1.9727 - val_loss: 10.0223 - val_mae: 2.8218\n",
      "Epoch 469/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.0786 - mae: 1.9723 - val_loss: 10.0150 - val_mae: 2.8209\n",
      "Epoch 470/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.0765 - mae: 1.9719 - val_loss: 10.0079 - val_mae: 2.8200\n",
      "Epoch 471/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.0743 - mae: 1.9715 - val_loss: 10.0008 - val_mae: 2.8192\n",
      "Epoch 472/3000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 5.0721 - mae: 1.9711 - val_loss: 9.9936 - val_mae: 2.8183\n",
      "Epoch 473/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0699 - mae: 1.9707 - val_loss: 9.9865 - val_mae: 2.8174\n",
      "Epoch 474/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.0677 - mae: 1.9703 - val_loss: 9.9794 - val_mae: 2.8166\n",
      "Epoch 475/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.0656 - mae: 1.9699 - val_loss: 9.9723 - val_mae: 2.8157\n",
      "Epoch 476/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.0634 - mae: 1.9695 - val_loss: 9.9649 - val_mae: 2.8148\n",
      "Epoch 477/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.0612 - mae: 1.9691 - val_loss: 9.9578 - val_mae: 2.8139\n",
      "Epoch 478/3000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 5.0591 - mae: 1.9687 - val_loss: 9.9508 - val_mae: 2.8131\n",
      "Epoch 479/3000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 5.0569 - mae: 1.9682 - val_loss: 9.9437 - val_mae: 2.8122\n",
      "Epoch 480/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.0547 - mae: 1.9678 - val_loss: 9.9364 - val_mae: 2.8113\n",
      "Epoch 481/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0525 - mae: 1.9674 - val_loss: 9.9291 - val_mae: 2.8104\n",
      "Epoch 482/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.0503 - mae: 1.9670 - val_loss: 9.9221 - val_mae: 2.8095\n",
      "Epoch 483/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.0482 - mae: 1.9666 - val_loss: 9.9151 - val_mae: 2.8087\n",
      "Epoch 484/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.0460 - mae: 1.9662 - val_loss: 9.9079 - val_mae: 2.8078\n",
      "Epoch 485/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0438 - mae: 1.9658 - val_loss: 9.9006 - val_mae: 2.8069\n",
      "Epoch 486/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.0416 - mae: 1.9654 - val_loss: 9.8935 - val_mae: 2.8060\n",
      "Epoch 487/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.0394 - mae: 1.9649 - val_loss: 9.8866 - val_mae: 2.8052\n",
      "Epoch 488/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.0372 - mae: 1.9645 - val_loss: 9.8797 - val_mae: 2.8043\n",
      "Epoch 489/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.0350 - mae: 1.9641 - val_loss: 9.8722 - val_mae: 2.8034\n",
      "Epoch 490/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.0328 - mae: 1.9637 - val_loss: 9.8649 - val_mae: 2.8025\n",
      "Epoch 491/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.0306 - mae: 1.9633 - val_loss: 9.8579 - val_mae: 2.8017\n",
      "Epoch 492/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.0284 - mae: 1.9628 - val_loss: 9.8510 - val_mae: 2.8008\n",
      "Epoch 493/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.0262 - mae: 1.9624 - val_loss: 9.8438 - val_mae: 2.7999\n",
      "Epoch 494/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.0240 - mae: 1.9620 - val_loss: 9.8365 - val_mae: 2.7990\n",
      "Epoch 495/3000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 5.0218 - mae: 1.9616 - val_loss: 9.8293 - val_mae: 2.7981\n",
      "Epoch 496/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.0196 - mae: 1.9612 - val_loss: 9.8223 - val_mae: 2.7972\n",
      "Epoch 497/3000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 5.0174 - mae: 1.9607 - val_loss: 9.8152 - val_mae: 2.7964\n",
      "Epoch 498/3000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 5.0152 - mae: 1.9603 - val_loss: 9.8080 - val_mae: 2.7955\n",
      "Epoch 499/3000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 5.0130 - mae: 1.9599 - val_loss: 9.8006 - val_mae: 2.7945\n",
      "Epoch 500/3000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 5.0108 - mae: 1.9595 - val_loss: 9.7935 - val_mae: 2.7937\n",
      "Epoch 501/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.0085 - mae: 1.9590 - val_loss: 9.7866 - val_mae: 2.7928\n",
      "Epoch 502/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.0064 - mae: 1.9586 - val_loss: 9.7795 - val_mae: 2.7919\n",
      "Epoch 503/3000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 5.0041 - mae: 1.9582 - val_loss: 9.7721 - val_mae: 2.7910\n",
      "Epoch 504/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.0019 - mae: 1.9578 - val_loss: 9.7647 - val_mae: 2.7901\n",
      "Epoch 505/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9998 - mae: 1.9573 - val_loss: 9.7578 - val_mae: 2.7892\n",
      "Epoch 506/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.9975 - mae: 1.9569 - val_loss: 9.7508 - val_mae: 2.7883\n",
      "Epoch 507/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.9953 - mae: 1.9565 - val_loss: 9.7437 - val_mae: 2.7874\n",
      "Epoch 508/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.9931 - mae: 1.9561 - val_loss: 9.7364 - val_mae: 2.7865\n",
      "Epoch 509/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.9909 - mae: 1.9557 - val_loss: 9.7292 - val_mae: 2.7856\n",
      "Epoch 510/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.9887 - mae: 1.9552 - val_loss: 9.7223 - val_mae: 2.7848\n",
      "Epoch 511/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.9865 - mae: 1.9548 - val_loss: 9.7152 - val_mae: 2.7839\n",
      "Epoch 512/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.9843 - mae: 1.9544 - val_loss: 9.7081 - val_mae: 2.7830\n",
      "Epoch 513/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.9821 - mae: 1.9540 - val_loss: 9.7011 - val_mae: 2.7821\n",
      "Epoch 514/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9799 - mae: 1.9536 - val_loss: 9.6941 - val_mae: 2.7812\n",
      "Epoch 515/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.9777 - mae: 1.9531 - val_loss: 9.6871 - val_mae: 2.7804\n",
      "Epoch 516/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.9755 - mae: 1.9527 - val_loss: 9.6802 - val_mae: 2.7795\n",
      "Epoch 517/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.9733 - mae: 1.9523 - val_loss: 9.6731 - val_mae: 2.7786\n",
      "Epoch 518/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.9711 - mae: 1.9519 - val_loss: 9.6661 - val_mae: 2.7778\n",
      "Epoch 519/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.9689 - mae: 1.9514 - val_loss: 9.6592 - val_mae: 2.7769\n",
      "Epoch 520/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.9667 - mae: 1.9510 - val_loss: 9.6524 - val_mae: 2.7760\n",
      "Epoch 521/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.9644 - mae: 1.9506 - val_loss: 9.6455 - val_mae: 2.7752\n",
      "Epoch 522/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.9623 - mae: 1.9502 - val_loss: 9.6383 - val_mae: 2.7743\n",
      "Epoch 523/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9600 - mae: 1.9497 - val_loss: 9.6313 - val_mae: 2.7734\n",
      "Epoch 524/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.9578 - mae: 1.9493 - val_loss: 9.6245 - val_mae: 2.7725\n",
      "Epoch 525/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.9556 - mae: 1.9489 - val_loss: 9.6177 - val_mae: 2.7717\n",
      "Epoch 526/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.9534 - mae: 1.9485 - val_loss: 9.6107 - val_mae: 2.7708\n",
      "Epoch 527/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9512 - mae: 1.9481 - val_loss: 9.6037 - val_mae: 2.7699\n",
      "Epoch 528/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.9490 - mae: 1.9476 - val_loss: 9.5968 - val_mae: 2.7691\n",
      "Epoch 529/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9467 - mae: 1.9472 - val_loss: 9.5898 - val_mae: 2.7682\n",
      "Epoch 530/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9445 - mae: 1.9468 - val_loss: 9.5829 - val_mae: 2.7673\n",
      "Epoch 531/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.9423 - mae: 1.9464 - val_loss: 9.5759 - val_mae: 2.7664\n",
      "Epoch 532/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.9401 - mae: 1.9459 - val_loss: 9.5691 - val_mae: 2.7656\n",
      "Epoch 533/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.9379 - mae: 1.9455 - val_loss: 9.5621 - val_mae: 2.7647\n",
      "Epoch 534/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9357 - mae: 1.9451 - val_loss: 9.5551 - val_mae: 2.7638\n",
      "Epoch 535/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.9334 - mae: 1.9446 - val_loss: 9.5482 - val_mae: 2.7629\n",
      "Epoch 536/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.9312 - mae: 1.9442 - val_loss: 9.5412 - val_mae: 2.7620\n",
      "Epoch 537/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.9290 - mae: 1.9438 - val_loss: 9.5344 - val_mae: 2.7612\n",
      "Epoch 538/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.9267 - mae: 1.9434 - val_loss: 9.5275 - val_mae: 2.7603\n",
      "Epoch 539/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.9244 - mae: 1.9429 - val_loss: 9.5205 - val_mae: 2.7594\n",
      "Epoch 540/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9223 - mae: 1.9425 - val_loss: 9.5135 - val_mae: 2.7585\n",
      "Epoch 541/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9200 - mae: 1.9421 - val_loss: 9.5066 - val_mae: 2.7577\n",
      "Epoch 542/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.9178 - mae: 1.9416 - val_loss: 9.4996 - val_mae: 2.7568\n",
      "Epoch 543/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.9156 - mae: 1.9412 - val_loss: 9.4928 - val_mae: 2.7559\n",
      "Epoch 544/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.9133 - mae: 1.9408 - val_loss: 9.4858 - val_mae: 2.7550\n",
      "Epoch 545/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.9111 - mae: 1.9403 - val_loss: 9.4787 - val_mae: 2.7541\n",
      "Epoch 546/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.9089 - mae: 1.9399 - val_loss: 9.4718 - val_mae: 2.7532\n",
      "Epoch 547/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9066 - mae: 1.9395 - val_loss: 9.4648 - val_mae: 2.7523\n",
      "Epoch 548/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.9044 - mae: 1.9390 - val_loss: 9.4579 - val_mae: 2.7515\n",
      "Epoch 549/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.9022 - mae: 1.9386 - val_loss: 9.4510 - val_mae: 2.7506\n",
      "Epoch 550/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.8999 - mae: 1.9382 - val_loss: 9.4440 - val_mae: 2.7497\n",
      "Epoch 551/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.8977 - mae: 1.9377 - val_loss: 9.4370 - val_mae: 2.7488\n",
      "Epoch 552/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.8954 - mae: 1.9373 - val_loss: 9.4300 - val_mae: 2.7479\n",
      "Epoch 553/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.8932 - mae: 1.9369 - val_loss: 9.4231 - val_mae: 2.7470\n",
      "Epoch 554/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.8909 - mae: 1.9364 - val_loss: 9.4164 - val_mae: 2.7462\n",
      "Epoch 555/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.8887 - mae: 1.9360 - val_loss: 9.4092 - val_mae: 2.7452\n",
      "Epoch 556/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.8864 - mae: 1.9356 - val_loss: 9.4021 - val_mae: 2.7443\n",
      "Epoch 557/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.8842 - mae: 1.9351 - val_loss: 9.3952 - val_mae: 2.7434\n",
      "Epoch 558/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.8819 - mae: 1.9347 - val_loss: 9.3884 - val_mae: 2.7426\n",
      "Epoch 559/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.8797 - mae: 1.9342 - val_loss: 9.3813 - val_mae: 2.7417\n",
      "Epoch 560/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.8774 - mae: 1.9338 - val_loss: 9.3744 - val_mae: 2.7408\n",
      "Epoch 561/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.8752 - mae: 1.9334 - val_loss: 9.3673 - val_mae: 2.7399\n",
      "Epoch 562/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.8730 - mae: 1.9329 - val_loss: 9.3604 - val_mae: 2.7390\n",
      "Epoch 563/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.8707 - mae: 1.9325 - val_loss: 9.3534 - val_mae: 2.7381\n",
      "Epoch 564/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.8684 - mae: 1.9320 - val_loss: 9.3464 - val_mae: 2.7372\n",
      "Epoch 565/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.8662 - mae: 1.9316 - val_loss: 9.3394 - val_mae: 2.7363\n",
      "Epoch 566/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.8639 - mae: 1.9312 - val_loss: 9.3325 - val_mae: 2.7354\n",
      "Epoch 567/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.8617 - mae: 1.9307 - val_loss: 9.3254 - val_mae: 2.7345\n",
      "Epoch 568/3000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 4.8594 - mae: 1.9303 - val_loss: 9.3184 - val_mae: 2.7336\n",
      "Epoch 569/3000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 4.8571 - mae: 1.9298 - val_loss: 9.3113 - val_mae: 2.7327\n",
      "Epoch 570/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 4.8549 - mae: 1.9294 - val_loss: 9.3044 - val_mae: 2.7318\n",
      "Epoch 571/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.8526 - mae: 1.9289 - val_loss: 9.2973 - val_mae: 2.7309\n",
      "Epoch 572/3000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 4.8503 - mae: 1.9285 - val_loss: 9.2904 - val_mae: 2.7300\n",
      "Epoch 573/3000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 4.8481 - mae: 1.9281 - val_loss: 9.2835 - val_mae: 2.7291\n",
      "Epoch 574/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.8458 - mae: 1.9276 - val_loss: 9.2763 - val_mae: 2.7281\n",
      "Epoch 575/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.8436 - mae: 1.9272 - val_loss: 9.2693 - val_mae: 2.7272\n",
      "Epoch 576/3000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 4.8413 - mae: 1.9267 - val_loss: 9.2625 - val_mae: 2.7264\n",
      "Epoch 577/3000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 4.8390 - mae: 1.9263 - val_loss: 9.2554 - val_mae: 2.7254\n",
      "Epoch 578/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.8368 - mae: 1.9258 - val_loss: 9.2483 - val_mae: 2.7245\n",
      "Epoch 579/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.8345 - mae: 1.9254 - val_loss: 9.2412 - val_mae: 2.7236\n",
      "Epoch 580/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 4.8322 - mae: 1.9249 - val_loss: 9.2342 - val_mae: 2.7227\n",
      "Epoch 581/3000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 4.8299 - mae: 1.9245 - val_loss: 9.2273 - val_mae: 2.7218\n",
      "Epoch 582/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.8277 - mae: 1.9241 - val_loss: 9.2200 - val_mae: 2.7209\n",
      "Epoch 583/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.8254 - mae: 1.9236 - val_loss: 9.2131 - val_mae: 2.7200\n",
      "Epoch 584/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.8231 - mae: 1.9232 - val_loss: 9.2061 - val_mae: 2.7190\n",
      "Epoch 585/3000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 4.8209 - mae: 1.9227 - val_loss: 9.1993 - val_mae: 2.7182\n",
      "Epoch 586/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.8186 - mae: 1.9223 - val_loss: 9.1921 - val_mae: 2.7172\n",
      "Epoch 587/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.8163 - mae: 1.9218 - val_loss: 9.1850 - val_mae: 2.7163\n",
      "Epoch 588/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.8140 - mae: 1.9214 - val_loss: 9.1779 - val_mae: 2.7154\n",
      "Epoch 589/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 4.8118 - mae: 1.9209 - val_loss: 9.1711 - val_mae: 2.7145\n",
      "Epoch 590/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 4.8095 - mae: 1.9205 - val_loss: 9.1639 - val_mae: 2.7135\n",
      "Epoch 591/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.8072 - mae: 1.9200 - val_loss: 9.1566 - val_mae: 2.7126\n",
      "Epoch 592/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.8049 - mae: 1.9195 - val_loss: 9.1497 - val_mae: 2.7117\n",
      "Epoch 593/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.8026 - mae: 1.9191 - val_loss: 9.1430 - val_mae: 2.7108\n",
      "Epoch 594/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 4.8003 - mae: 1.9187 - val_loss: 9.1357 - val_mae: 2.7099\n",
      "Epoch 595/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.7981 - mae: 1.9182 - val_loss: 9.1285 - val_mae: 2.7089\n",
      "Epoch 596/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.7958 - mae: 1.9177 - val_loss: 9.1216 - val_mae: 2.7080\n",
      "Epoch 597/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.7935 - mae: 1.9173 - val_loss: 9.1146 - val_mae: 2.7071\n",
      "Epoch 598/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 4.7912 - mae: 1.9168 - val_loss: 9.1076 - val_mae: 2.7062\n",
      "Epoch 599/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 4.7889 - mae: 1.9164 - val_loss: 9.1003 - val_mae: 2.7052\n",
      "Epoch 600/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.7866 - mae: 1.9159 - val_loss: 9.0931 - val_mae: 2.7043\n",
      "Epoch 601/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.7843 - mae: 1.9155 - val_loss: 9.0862 - val_mae: 2.7034\n",
      "Epoch 602/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.7821 - mae: 1.9150 - val_loss: 9.0792 - val_mae: 2.7025\n",
      "Epoch 603/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7798 - mae: 1.9146 - val_loss: 9.0721 - val_mae: 2.7015\n",
      "Epoch 604/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.7775 - mae: 1.9141 - val_loss: 9.0648 - val_mae: 2.7006\n",
      "Epoch 605/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.7752 - mae: 1.9137 - val_loss: 9.0579 - val_mae: 2.6997\n",
      "Epoch 606/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.7729 - mae: 1.9132 - val_loss: 9.0509 - val_mae: 2.6988\n",
      "Epoch 607/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 4.7706 - mae: 1.9127 - val_loss: 9.0437 - val_mae: 2.6978\n",
      "Epoch 608/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.7683 - mae: 1.9123 - val_loss: 9.0365 - val_mae: 2.6969\n",
      "Epoch 609/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.7660 - mae: 1.9118 - val_loss: 9.0294 - val_mae: 2.6959\n",
      "Epoch 610/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.7637 - mae: 1.9114 - val_loss: 9.0225 - val_mae: 2.6950\n",
      "Epoch 611/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.7614 - mae: 1.9109 - val_loss: 9.0154 - val_mae: 2.6941\n",
      "Epoch 612/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.7592 - mae: 1.9105 - val_loss: 9.0081 - val_mae: 2.6931\n",
      "Epoch 613/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 4.7569 - mae: 1.9100 - val_loss: 9.0009 - val_mae: 2.6922\n",
      "Epoch 614/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.7545 - mae: 1.9095 - val_loss: 8.9939 - val_mae: 2.6913\n",
      "Epoch 615/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.7522 - mae: 1.9091 - val_loss: 8.9870 - val_mae: 2.6903\n",
      "Epoch 616/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.7499 - mae: 1.9086 - val_loss: 8.9799 - val_mae: 2.6894\n",
      "Epoch 617/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7477 - mae: 1.9082 - val_loss: 8.9726 - val_mae: 2.6884\n",
      "Epoch 618/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7454 - mae: 1.9077 - val_loss: 8.9654 - val_mae: 2.6875\n",
      "Epoch 619/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 4.7431 - mae: 1.9072 - val_loss: 8.9583 - val_mae: 2.6865\n",
      "Epoch 620/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.7408 - mae: 1.9068 - val_loss: 8.9513 - val_mae: 2.6856\n",
      "Epoch 621/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.7385 - mae: 1.9063 - val_loss: 8.9442 - val_mae: 2.6847\n",
      "Epoch 622/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.7361 - mae: 1.9058 - val_loss: 8.9369 - val_mae: 2.6837\n",
      "Epoch 623/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.7339 - mae: 1.9054 - val_loss: 8.9298 - val_mae: 2.6828\n",
      "Epoch 624/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.7315 - mae: 1.9049 - val_loss: 8.9228 - val_mae: 2.6818\n",
      "Epoch 625/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.7292 - mae: 1.9045 - val_loss: 8.9159 - val_mae: 2.6809\n",
      "Epoch 626/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7269 - mae: 1.9040 - val_loss: 8.9086 - val_mae: 2.6800\n",
      "Epoch 627/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.7246 - mae: 1.9035 - val_loss: 8.9014 - val_mae: 2.6790\n",
      "Epoch 628/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.7223 - mae: 1.9031 - val_loss: 8.8944 - val_mae: 2.6781\n",
      "Epoch 629/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.7200 - mae: 1.9026 - val_loss: 8.8875 - val_mae: 2.6772\n",
      "Epoch 630/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.7177 - mae: 1.9021 - val_loss: 8.8802 - val_mae: 2.6762\n",
      "Epoch 631/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.7154 - mae: 1.9017 - val_loss: 8.8731 - val_mae: 2.6753\n",
      "Epoch 632/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.7131 - mae: 1.9012 - val_loss: 8.8660 - val_mae: 2.6743\n",
      "Epoch 633/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.7108 - mae: 1.9007 - val_loss: 8.8589 - val_mae: 2.6734\n",
      "Epoch 634/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7084 - mae: 1.9003 - val_loss: 8.8517 - val_mae: 2.6724\n",
      "Epoch 635/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.7061 - mae: 1.8998 - val_loss: 8.8446 - val_mae: 2.6715\n",
      "Epoch 636/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.7038 - mae: 1.8993 - val_loss: 8.8376 - val_mae: 2.6705\n",
      "Epoch 637/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.7015 - mae: 1.8988 - val_loss: 8.8305 - val_mae: 2.6696\n",
      "Epoch 638/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.6992 - mae: 1.8984 - val_loss: 8.8234 - val_mae: 2.6686\n",
      "Epoch 639/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.6969 - mae: 1.8979 - val_loss: 8.8163 - val_mae: 2.6677\n",
      "Epoch 640/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.6946 - mae: 1.8975 - val_loss: 8.8091 - val_mae: 2.6667\n",
      "Epoch 641/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.6922 - mae: 1.8970 - val_loss: 8.8019 - val_mae: 2.6658\n",
      "Epoch 642/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.6899 - mae: 1.8965 - val_loss: 8.7947 - val_mae: 2.6648\n",
      "Epoch 643/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6876 - mae: 1.8960 - val_loss: 8.7876 - val_mae: 2.6639\n",
      "Epoch 644/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6853 - mae: 1.8956 - val_loss: 8.7805 - val_mae: 2.6629\n",
      "Epoch 645/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6830 - mae: 1.8951 - val_loss: 8.7734 - val_mae: 2.6620\n",
      "Epoch 646/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.6807 - mae: 1.8946 - val_loss: 8.7664 - val_mae: 2.6610\n",
      "Epoch 647/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.6784 - mae: 1.8942 - val_loss: 8.7592 - val_mae: 2.6601\n",
      "Epoch 648/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6761 - mae: 1.8937 - val_loss: 8.7520 - val_mae: 2.6591\n",
      "Epoch 649/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.6737 - mae: 1.8932 - val_loss: 8.7450 - val_mae: 2.6582\n",
      "Epoch 650/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.6714 - mae: 1.8928 - val_loss: 8.7380 - val_mae: 2.6572\n",
      "Epoch 651/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.6691 - mae: 1.8923 - val_loss: 8.7307 - val_mae: 2.6563\n",
      "Epoch 652/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.6668 - mae: 1.8918 - val_loss: 8.7237 - val_mae: 2.6553\n",
      "Epoch 653/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.6645 - mae: 1.8914 - val_loss: 8.7166 - val_mae: 2.6544\n",
      "Epoch 654/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.6621 - mae: 1.8909 - val_loss: 8.7095 - val_mae: 2.6534\n",
      "Epoch 655/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.6598 - mae: 1.8904 - val_loss: 8.7024 - val_mae: 2.6525\n",
      "Epoch 656/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 4.6575 - mae: 1.8900 - val_loss: 8.6953 - val_mae: 2.6515\n",
      "Epoch 657/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.6551 - mae: 1.8895 - val_loss: 8.6882 - val_mae: 2.6505\n",
      "Epoch 658/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.6529 - mae: 1.8890 - val_loss: 8.6813 - val_mae: 2.6496\n",
      "Epoch 659/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.6505 - mae: 1.8885 - val_loss: 8.6741 - val_mae: 2.6487\n",
      "Epoch 660/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.6482 - mae: 1.8881 - val_loss: 8.6671 - val_mae: 2.6477\n",
      "Epoch 661/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6459 - mae: 1.8876 - val_loss: 8.6600 - val_mae: 2.6467\n",
      "Epoch 662/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.6436 - mae: 1.8871 - val_loss: 8.6530 - val_mae: 2.6458\n",
      "Epoch 663/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.6412 - mae: 1.8867 - val_loss: 8.6459 - val_mae: 2.6448\n",
      "Epoch 664/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.6389 - mae: 1.8862 - val_loss: 8.6387 - val_mae: 2.6439\n",
      "Epoch 665/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.6366 - mae: 1.8857 - val_loss: 8.6318 - val_mae: 2.6429\n",
      "Epoch 666/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6342 - mae: 1.8852 - val_loss: 8.6246 - val_mae: 2.6420\n",
      "Epoch 667/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.6320 - mae: 1.8848 - val_loss: 8.6175 - val_mae: 2.6410\n",
      "Epoch 668/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.6296 - mae: 1.8843 - val_loss: 8.6105 - val_mae: 2.6401\n",
      "Epoch 669/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.6273 - mae: 1.8838 - val_loss: 8.6035 - val_mae: 2.6391\n",
      "Epoch 670/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.6250 - mae: 1.8833 - val_loss: 8.5964 - val_mae: 2.6382\n",
      "Epoch 671/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.6227 - mae: 1.8829 - val_loss: 8.5894 - val_mae: 2.6372\n",
      "Epoch 672/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.6203 - mae: 1.8824 - val_loss: 8.5823 - val_mae: 2.6362\n",
      "Epoch 673/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.6180 - mae: 1.8819 - val_loss: 8.5752 - val_mae: 2.6353\n",
      "Epoch 674/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.6156 - mae: 1.8814 - val_loss: 8.5681 - val_mae: 2.6343\n",
      "Epoch 675/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.6133 - mae: 1.8810 - val_loss: 8.5610 - val_mae: 2.6334\n",
      "Epoch 676/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.6110 - mae: 1.8805 - val_loss: 8.5541 - val_mae: 2.6324\n",
      "Epoch 677/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.6086 - mae: 1.8800 - val_loss: 8.5470 - val_mae: 2.6315\n",
      "Epoch 678/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.6063 - mae: 1.8795 - val_loss: 8.5398 - val_mae: 2.6305\n",
      "Epoch 679/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.6040 - mae: 1.8791 - val_loss: 8.5327 - val_mae: 2.6295\n",
      "Epoch 680/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.6017 - mae: 1.8786 - val_loss: 8.5257 - val_mae: 2.6286\n",
      "Epoch 681/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5993 - mae: 1.8781 - val_loss: 8.5188 - val_mae: 2.6276\n",
      "Epoch 682/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.5970 - mae: 1.8776 - val_loss: 8.5117 - val_mae: 2.6267\n",
      "Epoch 683/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.5946 - mae: 1.8771 - val_loss: 8.5045 - val_mae: 2.6257\n",
      "Epoch 684/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.5923 - mae: 1.8767 - val_loss: 8.4975 - val_mae: 2.6247\n",
      "Epoch 685/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.5900 - mae: 1.8762 - val_loss: 8.4905 - val_mae: 2.6238\n",
      "Epoch 686/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.5877 - mae: 1.8757 - val_loss: 8.4834 - val_mae: 2.6228\n",
      "Epoch 687/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.5853 - mae: 1.8752 - val_loss: 8.4761 - val_mae: 2.6218\n",
      "Epoch 688/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.5830 - mae: 1.8747 - val_loss: 8.4692 - val_mae: 2.6209\n",
      "Epoch 689/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5807 - mae: 1.8743 - val_loss: 8.4622 - val_mae: 2.6199\n",
      "Epoch 690/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.5783 - mae: 1.8738 - val_loss: 8.4550 - val_mae: 2.6189\n",
      "Epoch 691/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.5760 - mae: 1.8733 - val_loss: 8.4480 - val_mae: 2.6180\n",
      "Epoch 692/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.5736 - mae: 1.8728 - val_loss: 8.4408 - val_mae: 2.6170\n",
      "Epoch 693/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.5713 - mae: 1.8723 - val_loss: 8.4339 - val_mae: 2.6160\n",
      "Epoch 694/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.5690 - mae: 1.8719 - val_loss: 8.4268 - val_mae: 2.6151\n",
      "Epoch 695/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.5666 - mae: 1.8714 - val_loss: 8.4195 - val_mae: 2.6141\n",
      "Epoch 696/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.5643 - mae: 1.8709 - val_loss: 8.4124 - val_mae: 2.6131\n",
      "Epoch 697/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5620 - mae: 1.8704 - val_loss: 8.4057 - val_mae: 2.6122\n",
      "Epoch 698/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.5596 - mae: 1.8699 - val_loss: 8.3986 - val_mae: 2.6112\n",
      "Epoch 699/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.5573 - mae: 1.8694 - val_loss: 8.3913 - val_mae: 2.6102\n",
      "Epoch 700/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.5549 - mae: 1.8690 - val_loss: 8.3842 - val_mae: 2.6092\n",
      "Epoch 701/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5526 - mae: 1.8685 - val_loss: 8.3774 - val_mae: 2.6083\n",
      "Epoch 702/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.5502 - mae: 1.8680 - val_loss: 8.3700 - val_mae: 2.6073\n",
      "Epoch 703/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.5479 - mae: 1.8675 - val_loss: 8.3628 - val_mae: 2.6063\n",
      "Epoch 704/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.5456 - mae: 1.8670 - val_loss: 8.3560 - val_mae: 2.6053\n",
      "Epoch 705/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.5432 - mae: 1.8665 - val_loss: 8.3491 - val_mae: 2.6044\n",
      "Epoch 706/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.5409 - mae: 1.8661 - val_loss: 8.3417 - val_mae: 2.6034\n",
      "Epoch 707/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.5385 - mae: 1.8656 - val_loss: 8.3346 - val_mae: 2.6024\n",
      "Epoch 708/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.5362 - mae: 1.8651 - val_loss: 8.3277 - val_mae: 2.6014\n",
      "Epoch 709/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.5339 - mae: 1.8646 - val_loss: 8.3207 - val_mae: 2.6005\n",
      "Epoch 710/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.5315 - mae: 1.8641 - val_loss: 8.3133 - val_mae: 2.5995\n",
      "Epoch 711/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.5292 - mae: 1.8636 - val_loss: 8.3062 - val_mae: 2.5985\n",
      "Epoch 712/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5268 - mae: 1.8631 - val_loss: 8.2994 - val_mae: 2.5975\n",
      "Epoch 713/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5245 - mae: 1.8627 - val_loss: 8.2923 - val_mae: 2.5966\n",
      "Epoch 714/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.5221 - mae: 1.8622 - val_loss: 8.2851 - val_mae: 2.5955\n",
      "Epoch 715/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.5198 - mae: 1.8617 - val_loss: 8.2780 - val_mae: 2.5946\n",
      "Epoch 716/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.5174 - mae: 1.8612 - val_loss: 8.2709 - val_mae: 2.5936\n",
      "Epoch 717/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.5151 - mae: 1.8607 - val_loss: 8.2640 - val_mae: 2.5926\n",
      "Epoch 718/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.5127 - mae: 1.8602 - val_loss: 8.2567 - val_mae: 2.5916\n",
      "Epoch 719/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.5104 - mae: 1.8597 - val_loss: 8.2496 - val_mae: 2.5906\n",
      "Epoch 720/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.5081 - mae: 1.8592 - val_loss: 8.2426 - val_mae: 2.5897\n",
      "Epoch 721/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.5057 - mae: 1.8587 - val_loss: 8.2355 - val_mae: 2.5887\n",
      "Epoch 722/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.5033 - mae: 1.8582 - val_loss: 8.2284 - val_mae: 2.5877\n",
      "Epoch 723/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.5010 - mae: 1.8577 - val_loss: 8.2212 - val_mae: 2.5867\n",
      "Epoch 724/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.4986 - mae: 1.8573 - val_loss: 8.2142 - val_mae: 2.5857\n",
      "Epoch 725/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4963 - mae: 1.8568 - val_loss: 8.2072 - val_mae: 2.5847\n",
      "Epoch 726/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4940 - mae: 1.8563 - val_loss: 8.2000 - val_mae: 2.5837\n",
      "Epoch 727/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4916 - mae: 1.8558 - val_loss: 8.1928 - val_mae: 2.5827\n",
      "Epoch 728/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.4893 - mae: 1.8553 - val_loss: 8.1858 - val_mae: 2.5818\n",
      "Epoch 729/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4869 - mae: 1.8548 - val_loss: 8.1788 - val_mae: 2.5808\n",
      "Epoch 730/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.4845 - mae: 1.8543 - val_loss: 8.1716 - val_mae: 2.5798\n",
      "Epoch 731/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.4822 - mae: 1.8538 - val_loss: 8.1644 - val_mae: 2.5788\n",
      "Epoch 732/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.4799 - mae: 1.8533 - val_loss: 8.1573 - val_mae: 2.5778\n",
      "Epoch 733/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.4775 - mae: 1.8528 - val_loss: 8.1504 - val_mae: 2.5768\n",
      "Epoch 734/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.4751 - mae: 1.8523 - val_loss: 8.1434 - val_mae: 2.5758\n",
      "Epoch 735/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.4728 - mae: 1.8518 - val_loss: 8.1361 - val_mae: 2.5748\n",
      "Epoch 736/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.4704 - mae: 1.8513 - val_loss: 8.1290 - val_mae: 2.5738\n",
      "Epoch 737/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.4681 - mae: 1.8508 - val_loss: 8.1220 - val_mae: 2.5728\n",
      "Epoch 738/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.4657 - mae: 1.8503 - val_loss: 8.1149 - val_mae: 2.5718\n",
      "Epoch 739/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4634 - mae: 1.8499 - val_loss: 8.1077 - val_mae: 2.5708\n",
      "Epoch 740/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.4610 - mae: 1.8494 - val_loss: 8.1006 - val_mae: 2.5698\n",
      "Epoch 741/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.4587 - mae: 1.8489 - val_loss: 8.0937 - val_mae: 2.5689\n",
      "Epoch 742/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.4563 - mae: 1.8484 - val_loss: 8.0866 - val_mae: 2.5679\n",
      "Epoch 743/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.4540 - mae: 1.8479 - val_loss: 8.0792 - val_mae: 2.5668\n",
      "Epoch 744/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.4516 - mae: 1.8474 - val_loss: 8.0722 - val_mae: 2.5659\n",
      "Epoch 745/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4493 - mae: 1.8469 - val_loss: 8.0654 - val_mae: 2.5649\n",
      "Epoch 746/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.4469 - mae: 1.8464 - val_loss: 8.0581 - val_mae: 2.5639\n",
      "Epoch 747/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.4445 - mae: 1.8459 - val_loss: 8.0507 - val_mae: 2.5628\n",
      "Epoch 748/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4422 - mae: 1.8454 - val_loss: 8.0439 - val_mae: 2.5619\n",
      "Epoch 749/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.4398 - mae: 1.8449 - val_loss: 8.0368 - val_mae: 2.5609\n",
      "Epoch 750/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4375 - mae: 1.8444 - val_loss: 8.0296 - val_mae: 2.5599\n",
      "Epoch 751/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.4351 - mae: 1.8439 - val_loss: 8.0224 - val_mae: 2.5588\n",
      "Epoch 752/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.4328 - mae: 1.8434 - val_loss: 8.0155 - val_mae: 2.5579\n",
      "Epoch 753/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.4304 - mae: 1.8429 - val_loss: 8.0085 - val_mae: 2.5569\n",
      "Epoch 754/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.4280 - mae: 1.8424 - val_loss: 8.0014 - val_mae: 2.5559\n",
      "Epoch 755/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4257 - mae: 1.8419 - val_loss: 7.9941 - val_mae: 2.5548\n",
      "Epoch 756/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.4234 - mae: 1.8414 - val_loss: 7.9869 - val_mae: 2.5538\n",
      "Epoch 757/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4210 - mae: 1.8409 - val_loss: 7.9800 - val_mae: 2.5528\n",
      "Epoch 758/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.4186 - mae: 1.8404 - val_loss: 7.9729 - val_mae: 2.5518\n",
      "Epoch 759/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4163 - mae: 1.8399 - val_loss: 7.9656 - val_mae: 2.5508\n",
      "Epoch 760/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.4139 - mae: 1.8394 - val_loss: 7.9586 - val_mae: 2.5498\n",
      "Epoch 761/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4116 - mae: 1.8389 - val_loss: 7.9516 - val_mae: 2.5488\n",
      "Epoch 762/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.4092 - mae: 1.8384 - val_loss: 7.9446 - val_mae: 2.5478\n",
      "Epoch 763/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.4068 - mae: 1.8379 - val_loss: 7.9373 - val_mae: 2.5468\n",
      "Epoch 764/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.4045 - mae: 1.8374 - val_loss: 7.9302 - val_mae: 2.5458\n",
      "Epoch 765/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 4.4021 - mae: 1.8369 - val_loss: 7.9233 - val_mae: 2.5448\n",
      "Epoch 766/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.3998 - mae: 1.8364 - val_loss: 7.9160 - val_mae: 2.5438\n",
      "Epoch 767/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3974 - mae: 1.8359 - val_loss: 7.9089 - val_mae: 2.5427\n",
      "Epoch 768/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3951 - mae: 1.8353 - val_loss: 7.9019 - val_mae: 2.5417\n",
      "Epoch 769/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.3927 - mae: 1.8348 - val_loss: 7.8948 - val_mae: 2.5407\n",
      "Epoch 770/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.3903 - mae: 1.8343 - val_loss: 7.8876 - val_mae: 2.5397\n",
      "Epoch 771/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3880 - mae: 1.8338 - val_loss: 7.8805 - val_mae: 2.5387\n",
      "Epoch 772/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.3856 - mae: 1.8333 - val_loss: 7.8734 - val_mae: 2.5377\n",
      "Epoch 773/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.3833 - mae: 1.8328 - val_loss: 7.8662 - val_mae: 2.5367\n",
      "Epoch 774/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.3809 - mae: 1.8323 - val_loss: 7.8591 - val_mae: 2.5356\n",
      "Epoch 775/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.3786 - mae: 1.8318 - val_loss: 7.8520 - val_mae: 2.5346\n",
      "Epoch 776/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.3762 - mae: 1.8313 - val_loss: 7.8450 - val_mae: 2.5336\n",
      "Epoch 777/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.3738 - mae: 1.8308 - val_loss: 7.8379 - val_mae: 2.5326\n",
      "Epoch 778/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3715 - mae: 1.8303 - val_loss: 7.8307 - val_mae: 2.5316\n",
      "Epoch 779/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.3691 - mae: 1.8298 - val_loss: 7.8238 - val_mae: 2.5306\n",
      "Epoch 780/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3667 - mae: 1.8293 - val_loss: 7.8166 - val_mae: 2.5296\n",
      "Epoch 781/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.3644 - mae: 1.8288 - val_loss: 7.8095 - val_mae: 2.5286\n",
      "Epoch 782/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.3620 - mae: 1.8283 - val_loss: 7.8023 - val_mae: 2.5275\n",
      "Epoch 783/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.3597 - mae: 1.8277 - val_loss: 7.7954 - val_mae: 2.5265\n",
      "Epoch 784/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3573 - mae: 1.8272 - val_loss: 7.7882 - val_mae: 2.5255\n",
      "Epoch 785/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3550 - mae: 1.8267 - val_loss: 7.7811 - val_mae: 2.5245\n",
      "Epoch 786/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.3526 - mae: 1.8262 - val_loss: 7.7739 - val_mae: 2.5234\n",
      "Epoch 787/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3502 - mae: 1.8257 - val_loss: 7.7669 - val_mae: 2.5224\n",
      "Epoch 788/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.3479 - mae: 1.8252 - val_loss: 7.7598 - val_mae: 2.5214\n",
      "Epoch 789/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3455 - mae: 1.8247 - val_loss: 7.7526 - val_mae: 2.5204\n",
      "Epoch 790/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.3432 - mae: 1.8242 - val_loss: 7.7456 - val_mae: 2.5193\n",
      "Epoch 791/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.3408 - mae: 1.8237 - val_loss: 7.7385 - val_mae: 2.5183\n",
      "Epoch 792/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3384 - mae: 1.8231 - val_loss: 7.7314 - val_mae: 2.5173\n",
      "Epoch 793/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.3361 - mae: 1.8226 - val_loss: 7.7242 - val_mae: 2.5163\n",
      "Epoch 794/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.3337 - mae: 1.8221 - val_loss: 7.7171 - val_mae: 2.5153\n",
      "Epoch 795/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3314 - mae: 1.8216 - val_loss: 7.7101 - val_mae: 2.5142\n",
      "Epoch 796/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.3290 - mae: 1.8211 - val_loss: 7.7029 - val_mae: 2.5132\n",
      "Epoch 797/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.3266 - mae: 1.8206 - val_loss: 7.6959 - val_mae: 2.5122\n",
      "Epoch 798/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.3242 - mae: 1.8201 - val_loss: 7.6887 - val_mae: 2.5111\n",
      "Epoch 799/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.3219 - mae: 1.8196 - val_loss: 7.6816 - val_mae: 2.5101\n",
      "Epoch 800/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.3195 - mae: 1.8190 - val_loss: 7.6746 - val_mae: 2.5091\n",
      "Epoch 801/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.3172 - mae: 1.8185 - val_loss: 7.6673 - val_mae: 2.5080\n",
      "Epoch 802/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3148 - mae: 1.8180 - val_loss: 7.6603 - val_mae: 2.5070\n",
      "Epoch 803/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.3124 - mae: 1.8175 - val_loss: 7.6534 - val_mae: 2.5060\n",
      "Epoch 804/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.3101 - mae: 1.8170 - val_loss: 7.6461 - val_mae: 2.5050\n",
      "Epoch 805/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.3077 - mae: 1.8165 - val_loss: 7.6388 - val_mae: 2.5039\n",
      "Epoch 806/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.3053 - mae: 1.8160 - val_loss: 7.6322 - val_mae: 2.5029\n",
      "Epoch 807/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.3030 - mae: 1.8155 - val_loss: 7.6249 - val_mae: 2.5019\n",
      "Epoch 808/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.3007 - mae: 1.8149 - val_loss: 7.6176 - val_mae: 2.5008\n",
      "Epoch 809/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.2983 - mae: 1.8144 - val_loss: 7.6105 - val_mae: 2.4998\n",
      "Epoch 810/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.2959 - mae: 1.8139 - val_loss: 7.6036 - val_mae: 2.4988\n",
      "Epoch 811/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.2935 - mae: 1.8134 - val_loss: 7.5965 - val_mae: 2.4977\n",
      "Epoch 812/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.2912 - mae: 1.8129 - val_loss: 7.5891 - val_mae: 2.4967\n",
      "Epoch 813/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.2888 - mae: 1.8123 - val_loss: 7.5821 - val_mae: 2.4956\n",
      "Epoch 814/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.2864 - mae: 1.8118 - val_loss: 7.5753 - val_mae: 2.4947\n",
      "Epoch 815/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.2841 - mae: 1.8113 - val_loss: 7.5680 - val_mae: 2.4936\n",
      "Epoch 816/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.2817 - mae: 1.8108 - val_loss: 7.5608 - val_mae: 2.4925\n",
      "Epoch 817/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.2794 - mae: 1.8103 - val_loss: 7.5540 - val_mae: 2.4915\n",
      "Epoch 818/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.2770 - mae: 1.8098 - val_loss: 7.5468 - val_mae: 2.4905\n",
      "Epoch 819/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.2746 - mae: 1.8092 - val_loss: 7.5394 - val_mae: 2.4894\n",
      "Epoch 820/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.2723 - mae: 1.8087 - val_loss: 7.5327 - val_mae: 2.4884\n",
      "Epoch 821/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.2700 - mae: 1.8082 - val_loss: 7.5255 - val_mae: 2.4874\n",
      "Epoch 822/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.2676 - mae: 1.8077 - val_loss: 7.5182 - val_mae: 2.4863\n",
      "Epoch 823/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.2652 - mae: 1.8072 - val_loss: 7.5112 - val_mae: 2.4853\n",
      "Epoch 824/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.2628 - mae: 1.8066 - val_loss: 7.5043 - val_mae: 2.4842\n",
      "Epoch 825/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.2605 - mae: 1.8061 - val_loss: 7.4970 - val_mae: 2.4832\n",
      "Epoch 826/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.2581 - mae: 1.8056 - val_loss: 7.4899 - val_mae: 2.4821\n",
      "Epoch 827/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2558 - mae: 1.8051 - val_loss: 7.4830 - val_mae: 2.4811\n",
      "Epoch 828/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.2534 - mae: 1.8046 - val_loss: 7.4758 - val_mae: 2.4801\n",
      "Epoch 829/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.2511 - mae: 1.8040 - val_loss: 7.4686 - val_mae: 2.4790\n",
      "Epoch 830/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.2487 - mae: 1.8035 - val_loss: 7.4616 - val_mae: 2.4780\n",
      "Epoch 831/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.2463 - mae: 1.8030 - val_loss: 7.4546 - val_mae: 2.4769\n",
      "Epoch 832/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.2440 - mae: 1.8025 - val_loss: 7.4473 - val_mae: 2.4759\n",
      "Epoch 833/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.2416 - mae: 1.8019 - val_loss: 7.4403 - val_mae: 2.4748\n",
      "Epoch 834/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 4.2392 - mae: 1.8014 - val_loss: 7.4334 - val_mae: 2.4738\n",
      "Epoch 835/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.2369 - mae: 1.8009 - val_loss: 7.4262 - val_mae: 2.4727\n",
      "Epoch 836/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.2345 - mae: 1.8004 - val_loss: 7.4188 - val_mae: 2.4716\n",
      "Epoch 837/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.2321 - mae: 1.7999 - val_loss: 7.4121 - val_mae: 2.4706\n",
      "Epoch 838/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.2298 - mae: 1.7993 - val_loss: 7.4050 - val_mae: 2.4696\n",
      "Epoch 839/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.2274 - mae: 1.7988 - val_loss: 7.3977 - val_mae: 2.4685\n",
      "Epoch 840/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.2251 - mae: 1.7983 - val_loss: 7.3904 - val_mae: 2.4674\n",
      "Epoch 841/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.2227 - mae: 1.7977 - val_loss: 7.3836 - val_mae: 2.4664\n",
      "Epoch 842/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.2203 - mae: 1.7972 - val_loss: 7.3766 - val_mae: 2.4654\n",
      "Epoch 843/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2180 - mae: 1.7967 - val_loss: 7.3693 - val_mae: 2.4643\n",
      "Epoch 844/3000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 4.2156 - mae: 1.7962 - val_loss: 7.3622 - val_mae: 2.4632\n",
      "Epoch 845/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 4.2133 - mae: 1.7956 - val_loss: 7.3554 - val_mae: 2.4622\n",
      "Epoch 846/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.2109 - mae: 1.7951 - val_loss: 7.3483 - val_mae: 2.4612\n",
      "Epoch 847/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.2085 - mae: 1.7946 - val_loss: 7.3410 - val_mae: 2.4601\n",
      "Epoch 848/3000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 4.2062 - mae: 1.7941 - val_loss: 7.3340 - val_mae: 2.4591\n",
      "Epoch 849/3000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 4.2038 - mae: 1.7935 - val_loss: 7.3272 - val_mae: 2.4580\n",
      "Epoch 850/3000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.2015 - mae: 1.7930 - val_loss: 7.3200 - val_mae: 2.4570\n",
      "Epoch 851/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.1991 - mae: 1.7925 - val_loss: 7.3126 - val_mae: 2.4559\n",
      "Epoch 852/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.1968 - mae: 1.7920 - val_loss: 7.3057 - val_mae: 2.4548\n",
      "Epoch 853/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.1944 - mae: 1.7914 - val_loss: 7.2988 - val_mae: 2.4538\n",
      "Epoch 854/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.1920 - mae: 1.7909 - val_loss: 7.2916 - val_mae: 2.4527\n",
      "Epoch 855/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1897 - mae: 1.7904 - val_loss: 7.2843 - val_mae: 2.4516\n",
      "Epoch 856/3000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.1873 - mae: 1.7899 - val_loss: 7.2773 - val_mae: 2.4506\n",
      "Epoch 857/3000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 4.1849 - mae: 1.7893 - val_loss: 7.2705 - val_mae: 2.4496\n",
      "Epoch 858/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.1826 - mae: 1.7888 - val_loss: 7.2633 - val_mae: 2.4485\n",
      "Epoch 859/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.1802 - mae: 1.7883 - val_loss: 7.2560 - val_mae: 2.4474\n",
      "Epoch 860/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.1779 - mae: 1.7877 - val_loss: 7.2492 - val_mae: 2.4464\n",
      "Epoch 861/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.1755 - mae: 1.7872 - val_loss: 7.2423 - val_mae: 2.4453\n",
      "Epoch 862/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.1732 - mae: 1.7867 - val_loss: 7.2349 - val_mae: 2.4442\n",
      "Epoch 863/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.1708 - mae: 1.7861 - val_loss: 7.2278 - val_mae: 2.4432\n",
      "Epoch 864/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.1685 - mae: 1.7856 - val_loss: 7.2209 - val_mae: 2.4421\n",
      "Epoch 865/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.1661 - mae: 1.7851 - val_loss: 7.2137 - val_mae: 2.4410\n",
      "Epoch 866/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.1637 - mae: 1.7845 - val_loss: 7.2066 - val_mae: 2.4400\n",
      "Epoch 867/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.1613 - mae: 1.7840 - val_loss: 7.1997 - val_mae: 2.4389\n",
      "Epoch 868/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.1590 - mae: 1.7835 - val_loss: 7.1926 - val_mae: 2.4379\n",
      "Epoch 869/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.1567 - mae: 1.7829 - val_loss: 7.1855 - val_mae: 2.4368\n",
      "Epoch 870/3000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 4.1543 - mae: 1.7824 - val_loss: 7.1784 - val_mae: 2.4357\n",
      "Epoch 871/3000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 4.1519 - mae: 1.7819 - val_loss: 7.1714 - val_mae: 2.4347\n",
      "Epoch 872/3000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4.1496 - mae: 1.7814 - val_loss: 7.1644 - val_mae: 2.4336\n",
      "Epoch 873/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.1472 - mae: 1.7808 - val_loss: 7.1572 - val_mae: 2.4325\n",
      "Epoch 874/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.1449 - mae: 1.7803 - val_loss: 7.1503 - val_mae: 2.4315\n",
      "Epoch 875/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.1425 - mae: 1.7798 - val_loss: 7.1432 - val_mae: 2.4304\n",
      "Epoch 876/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.1402 - mae: 1.7792 - val_loss: 7.1361 - val_mae: 2.4293\n",
      "Epoch 877/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.1378 - mae: 1.7787 - val_loss: 7.1289 - val_mae: 2.4282\n",
      "Epoch 878/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.1355 - mae: 1.7781 - val_loss: 7.1220 - val_mae: 2.4272\n",
      "Epoch 879/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.1331 - mae: 1.7776 - val_loss: 7.1149 - val_mae: 2.4261\n",
      "Epoch 880/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.1307 - mae: 1.7771 - val_loss: 7.1078 - val_mae: 2.4250\n",
      "Epoch 881/3000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 4.1284 - mae: 1.7765 - val_loss: 7.1007 - val_mae: 2.4239\n",
      "Epoch 882/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 4.1260 - mae: 1.7760 - val_loss: 7.0938 - val_mae: 2.4229\n",
      "Epoch 883/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.1236 - mae: 1.7755 - val_loss: 7.0868 - val_mae: 2.4218\n",
      "Epoch 884/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.1213 - mae: 1.7749 - val_loss: 7.0796 - val_mae: 2.4207\n",
      "Epoch 885/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.1189 - mae: 1.7744 - val_loss: 7.0725 - val_mae: 2.4197\n",
      "Epoch 886/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.1166 - mae: 1.7738 - val_loss: 7.0655 - val_mae: 2.4186\n",
      "Epoch 887/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.1142 - mae: 1.7733 - val_loss: 7.0586 - val_mae: 2.4175\n",
      "Epoch 888/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.1119 - mae: 1.7728 - val_loss: 7.0514 - val_mae: 2.4164\n",
      "Epoch 889/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.1095 - mae: 1.7722 - val_loss: 7.0444 - val_mae: 2.4154\n",
      "Epoch 890/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.1072 - mae: 1.7717 - val_loss: 7.0373 - val_mae: 2.4143\n",
      "Epoch 891/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.1048 - mae: 1.7712 - val_loss: 7.0303 - val_mae: 2.4132\n",
      "Epoch 892/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.1025 - mae: 1.7706 - val_loss: 7.0233 - val_mae: 2.4121\n",
      "Epoch 893/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.1001 - mae: 1.7701 - val_loss: 7.0162 - val_mae: 2.4110\n",
      "Epoch 894/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.0978 - mae: 1.7695 - val_loss: 7.0091 - val_mae: 2.4100\n",
      "Epoch 895/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.0954 - mae: 1.7690 - val_loss: 7.0021 - val_mae: 2.4089\n",
      "Epoch 896/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.0931 - mae: 1.7685 - val_loss: 6.9953 - val_mae: 2.4079\n",
      "Epoch 897/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.0907 - mae: 1.7679 - val_loss: 6.9880 - val_mae: 2.4067\n",
      "Epoch 898/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.0884 - mae: 1.7674 - val_loss: 6.9807 - val_mae: 2.4056\n",
      "Epoch 899/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.0860 - mae: 1.7668 - val_loss: 6.9740 - val_mae: 2.4046\n",
      "Epoch 900/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.0836 - mae: 1.7663 - val_loss: 6.9672 - val_mae: 2.4035\n",
      "Epoch 901/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.0813 - mae: 1.7658 - val_loss: 6.9596 - val_mae: 2.4024\n",
      "Epoch 902/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.0790 - mae: 1.7652 - val_loss: 6.9526 - val_mae: 2.4013\n",
      "Epoch 903/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.0766 - mae: 1.7647 - val_loss: 6.9460 - val_mae: 2.4003\n",
      "Epoch 904/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.0743 - mae: 1.7641 - val_loss: 6.9388 - val_mae: 2.3992\n",
      "Epoch 905/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.0719 - mae: 1.7636 - val_loss: 6.9316 - val_mae: 2.3981\n",
      "Epoch 906/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.0695 - mae: 1.7630 - val_loss: 6.9248 - val_mae: 2.3970\n",
      "Epoch 907/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.0672 - mae: 1.7625 - val_loss: 6.9177 - val_mae: 2.3959\n",
      "Epoch 908/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.0649 - mae: 1.7620 - val_loss: 6.9105 - val_mae: 2.3948\n",
      "Epoch 909/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.0625 - mae: 1.7614 - val_loss: 6.9036 - val_mae: 2.3937\n",
      "Epoch 910/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.0602 - mae: 1.7609 - val_loss: 6.8967 - val_mae: 2.3927\n",
      "Epoch 911/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.0578 - mae: 1.7603 - val_loss: 6.8895 - val_mae: 2.3916\n",
      "Epoch 912/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.0555 - mae: 1.7598 - val_loss: 6.8825 - val_mae: 2.3905\n",
      "Epoch 913/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.0531 - mae: 1.7592 - val_loss: 6.8756 - val_mae: 2.3894\n",
      "Epoch 914/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.0508 - mae: 1.7587 - val_loss: 6.8685 - val_mae: 2.3883\n",
      "Epoch 915/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.0484 - mae: 1.7582 - val_loss: 6.8615 - val_mae: 2.3872\n",
      "Epoch 916/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.0461 - mae: 1.7576 - val_loss: 6.8544 - val_mae: 2.3861\n",
      "Epoch 917/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.0437 - mae: 1.7571 - val_loss: 6.8475 - val_mae: 2.3850\n",
      "Epoch 918/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.0414 - mae: 1.7565 - val_loss: 6.8404 - val_mae: 2.3839\n",
      "Epoch 919/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.0391 - mae: 1.7560 - val_loss: 6.8333 - val_mae: 2.3828\n",
      "Epoch 920/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.0367 - mae: 1.7554 - val_loss: 6.8264 - val_mae: 2.3818\n",
      "Epoch 921/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.0343 - mae: 1.7549 - val_loss: 6.8195 - val_mae: 2.3807\n",
      "Epoch 922/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.0320 - mae: 1.7543 - val_loss: 6.8124 - val_mae: 2.3796\n",
      "Epoch 923/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.0297 - mae: 1.7538 - val_loss: 6.8053 - val_mae: 2.3785\n",
      "Epoch 924/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.0273 - mae: 1.7532 - val_loss: 6.7984 - val_mae: 2.3774\n",
      "Epoch 925/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.0250 - mae: 1.7527 - val_loss: 6.7914 - val_mae: 2.3763\n",
      "Epoch 926/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 4.0227 - mae: 1.7522 - val_loss: 6.7844 - val_mae: 2.3752\n",
      "Epoch 927/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.0203 - mae: 1.7517 - val_loss: 6.7773 - val_mae: 2.3741\n",
      "Epoch 928/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.0180 - mae: 1.7512 - val_loss: 6.7704 - val_mae: 2.3730\n",
      "Epoch 929/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.0156 - mae: 1.7508 - val_loss: 6.7635 - val_mae: 2.3719\n",
      "Epoch 930/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 4.0133 - mae: 1.7503 - val_loss: 6.7563 - val_mae: 2.3708\n",
      "Epoch 931/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.0109 - mae: 1.7498 - val_loss: 6.7492 - val_mae: 2.3697\n",
      "Epoch 932/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.0086 - mae: 1.7494 - val_loss: 6.7424 - val_mae: 2.3686\n",
      "Epoch 933/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.0062 - mae: 1.7489 - val_loss: 6.7354 - val_mae: 2.3675\n",
      "Epoch 934/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.0039 - mae: 1.7485 - val_loss: 6.7283 - val_mae: 2.3664\n",
      "Epoch 935/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.0015 - mae: 1.7480 - val_loss: 6.7213 - val_mae: 2.3653\n",
      "Epoch 936/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.9992 - mae: 1.7475 - val_loss: 6.7144 - val_mae: 2.3642\n",
      "Epoch 937/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.9969 - mae: 1.7471 - val_loss: 6.7074 - val_mae: 2.3631\n",
      "Epoch 938/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.9946 - mae: 1.7466 - val_loss: 6.7004 - val_mae: 2.3620\n",
      "Epoch 939/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.9922 - mae: 1.7461 - val_loss: 6.6933 - val_mae: 2.3609\n",
      "Epoch 940/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.9899 - mae: 1.7457 - val_loss: 6.6864 - val_mae: 2.3598\n",
      "Epoch 941/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.9876 - mae: 1.7452 - val_loss: 6.6795 - val_mae: 2.3587\n",
      "Epoch 942/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.9852 - mae: 1.7447 - val_loss: 6.6724 - val_mae: 2.3576\n",
      "Epoch 943/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.9828 - mae: 1.7443 - val_loss: 6.6653 - val_mae: 2.3565\n",
      "Epoch 944/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9805 - mae: 1.7438 - val_loss: 6.6585 - val_mae: 2.3554\n",
      "Epoch 945/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.9782 - mae: 1.7433 - val_loss: 6.6515 - val_mae: 2.3543\n",
      "Epoch 946/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.9759 - mae: 1.7429 - val_loss: 6.6444 - val_mae: 2.3532\n",
      "Epoch 947/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.9735 - mae: 1.7424 - val_loss: 6.6375 - val_mae: 2.3521\n",
      "Epoch 948/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.9712 - mae: 1.7419 - val_loss: 6.6307 - val_mae: 2.3510\n",
      "Epoch 949/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.9689 - mae: 1.7415 - val_loss: 6.6235 - val_mae: 2.3499\n",
      "Epoch 950/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.9665 - mae: 1.7410 - val_loss: 6.6164 - val_mae: 2.3488\n",
      "Epoch 951/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.9642 - mae: 1.7405 - val_loss: 6.6098 - val_mae: 2.3477\n",
      "Epoch 952/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.9619 - mae: 1.7401 - val_loss: 6.6026 - val_mae: 2.3465\n",
      "Epoch 953/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.9595 - mae: 1.7396 - val_loss: 6.5954 - val_mae: 2.3454\n",
      "Epoch 954/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3.9572 - mae: 1.7391 - val_loss: 6.5889 - val_mae: 2.3444\n",
      "Epoch 955/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.9549 - mae: 1.7387 - val_loss: 6.5818 - val_mae: 2.3432\n",
      "Epoch 956/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.9525 - mae: 1.7382 - val_loss: 6.5745 - val_mae: 2.3421\n",
      "Epoch 957/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.9502 - mae: 1.7377 - val_loss: 6.5679 - val_mae: 2.3410\n",
      "Epoch 958/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.9478 - mae: 1.7372 - val_loss: 6.5611 - val_mae: 2.3399\n",
      "Epoch 959/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.9455 - mae: 1.7368 - val_loss: 6.5538 - val_mae: 2.3388\n",
      "Epoch 960/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.9432 - mae: 1.7363 - val_loss: 6.5468 - val_mae: 2.3377\n",
      "Epoch 961/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.9409 - mae: 1.7358 - val_loss: 6.5400 - val_mae: 2.3366\n",
      "Epoch 962/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.9386 - mae: 1.7354 - val_loss: 6.5330 - val_mae: 2.3354\n",
      "Epoch 963/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.9362 - mae: 1.7349 - val_loss: 6.5258 - val_mae: 2.3343\n",
      "Epoch 964/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.9339 - mae: 1.7344 - val_loss: 6.5193 - val_mae: 2.3333\n",
      "Epoch 965/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.9316 - mae: 1.7340 - val_loss: 6.5121 - val_mae: 2.3321\n",
      "Epoch 966/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.9292 - mae: 1.7335 - val_loss: 6.5050 - val_mae: 2.3310\n",
      "Epoch 967/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.9269 - mae: 1.7330 - val_loss: 6.4983 - val_mae: 2.3299\n",
      "Epoch 968/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.9246 - mae: 1.7325 - val_loss: 6.4914 - val_mae: 2.3288\n",
      "Epoch 969/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.9222 - mae: 1.7321 - val_loss: 6.4842 - val_mae: 2.3276\n",
      "Epoch 970/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.9199 - mae: 1.7316 - val_loss: 6.4775 - val_mae: 2.3265\n",
      "Epoch 971/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.9176 - mae: 1.7311 - val_loss: 6.4707 - val_mae: 2.3254\n",
      "Epoch 972/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.9152 - mae: 1.7307 - val_loss: 6.4633 - val_mae: 2.3243\n",
      "Epoch 973/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.9129 - mae: 1.7302 - val_loss: 6.4565 - val_mae: 2.3232\n",
      "Epoch 974/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.9106 - mae: 1.7297 - val_loss: 6.4498 - val_mae: 2.3221\n",
      "Epoch 975/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.9083 - mae: 1.7292 - val_loss: 6.4427 - val_mae: 2.3209\n",
      "Epoch 976/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.9060 - mae: 1.7288 - val_loss: 6.4356 - val_mae: 2.3198\n",
      "Epoch 977/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.9036 - mae: 1.7283 - val_loss: 6.4290 - val_mae: 2.3187\n",
      "Epoch 978/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.9013 - mae: 1.7278 - val_loss: 6.4219 - val_mae: 2.3176\n",
      "Epoch 979/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8990 - mae: 1.7273 - val_loss: 6.4149 - val_mae: 2.3164\n",
      "Epoch 980/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.8967 - mae: 1.7269 - val_loss: 6.4081 - val_mae: 2.3153\n",
      "Epoch 981/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.8944 - mae: 1.7264 - val_loss: 6.4012 - val_mae: 2.3142\n",
      "Epoch 982/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.8921 - mae: 1.7259 - val_loss: 6.3942 - val_mae: 2.3131\n",
      "Epoch 983/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.8897 - mae: 1.7254 - val_loss: 6.3873 - val_mae: 2.3120\n",
      "Epoch 984/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.8874 - mae: 1.7250 - val_loss: 6.3805 - val_mae: 2.3109\n",
      "Epoch 985/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.8851 - mae: 1.7245 - val_loss: 6.3736 - val_mae: 2.3097\n",
      "Epoch 986/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.8828 - mae: 1.7240 - val_loss: 6.3663 - val_mae: 2.3086\n",
      "Epoch 987/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.8805 - mae: 1.7235 - val_loss: 6.3596 - val_mae: 2.3075\n",
      "Epoch 988/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.8781 - mae: 1.7231 - val_loss: 6.3527 - val_mae: 2.3063\n",
      "Epoch 989/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.8758 - mae: 1.7226 - val_loss: 6.3456 - val_mae: 2.3052\n",
      "Epoch 990/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.8735 - mae: 1.7221 - val_loss: 6.3389 - val_mae: 2.3041\n",
      "Epoch 991/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.8712 - mae: 1.7216 - val_loss: 6.3319 - val_mae: 2.3029\n",
      "Epoch 992/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.8689 - mae: 1.7212 - val_loss: 6.3250 - val_mae: 2.3018\n",
      "Epoch 993/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.8666 - mae: 1.7207 - val_loss: 6.3182 - val_mae: 2.3007\n",
      "Epoch 994/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.8642 - mae: 1.7202 - val_loss: 6.3112 - val_mae: 2.2996\n",
      "Epoch 995/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.8619 - mae: 1.7197 - val_loss: 6.3044 - val_mae: 2.2984\n",
      "Epoch 996/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.8596 - mae: 1.7193 - val_loss: 6.2977 - val_mae: 2.2974\n",
      "Epoch 997/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.8573 - mae: 1.7188 - val_loss: 6.2905 - val_mae: 2.2962\n",
      "Epoch 998/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.8550 - mae: 1.7183 - val_loss: 6.2836 - val_mae: 2.2951\n",
      "Epoch 999/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.8527 - mae: 1.7178 - val_loss: 6.2770 - val_mae: 2.2940\n",
      "Epoch 1000/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.8503 - mae: 1.7173 - val_loss: 6.2699 - val_mae: 2.2928\n",
      "Epoch 1001/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.8481 - mae: 1.7169 - val_loss: 6.2629 - val_mae: 2.2917\n",
      "Epoch 1002/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.8457 - mae: 1.7164 - val_loss: 6.2562 - val_mae: 2.2905\n",
      "Epoch 1003/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.8435 - mae: 1.7159 - val_loss: 6.2493 - val_mae: 2.2894\n",
      "Epoch 1004/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.8411 - mae: 1.7154 - val_loss: 6.2422 - val_mae: 2.2882\n",
      "Epoch 1005/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.8388 - mae: 1.7149 - val_loss: 6.2354 - val_mae: 2.2871\n",
      "Epoch 1006/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.8365 - mae: 1.7145 - val_loss: 6.2287 - val_mae: 2.2860\n",
      "Epoch 1007/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.8342 - mae: 1.7140 - val_loss: 6.2215 - val_mae: 2.2848\n",
      "Epoch 1008/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8319 - mae: 1.7135 - val_loss: 6.2147 - val_mae: 2.2837\n",
      "Epoch 1009/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.8296 - mae: 1.7130 - val_loss: 6.2081 - val_mae: 2.2826\n",
      "Epoch 1010/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.8273 - mae: 1.7126 - val_loss: 6.2011 - val_mae: 2.2815\n",
      "Epoch 1011/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.8250 - mae: 1.7121 - val_loss: 6.1941 - val_mae: 2.2803\n",
      "Epoch 1012/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.8226 - mae: 1.7116 - val_loss: 6.1873 - val_mae: 2.2792\n",
      "Epoch 1013/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.8204 - mae: 1.7111 - val_loss: 6.1806 - val_mae: 2.2781\n",
      "Epoch 1014/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.8181 - mae: 1.7106 - val_loss: 6.1736 - val_mae: 2.2769\n",
      "Epoch 1015/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.8158 - mae: 1.7102 - val_loss: 6.1666 - val_mae: 2.2758\n",
      "Epoch 1016/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.8135 - mae: 1.7097 - val_loss: 6.1600 - val_mae: 2.2746\n",
      "Epoch 1017/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.8112 - mae: 1.7092 - val_loss: 6.1531 - val_mae: 2.2735\n",
      "Epoch 1018/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.8089 - mae: 1.7087 - val_loss: 6.1461 - val_mae: 2.2724\n",
      "Epoch 1019/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.8066 - mae: 1.7082 - val_loss: 6.1394 - val_mae: 2.2712\n",
      "Epoch 1020/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.8043 - mae: 1.7077 - val_loss: 6.1325 - val_mae: 2.2701\n",
      "Epoch 1021/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.8020 - mae: 1.7073 - val_loss: 6.1257 - val_mae: 2.2689\n",
      "Epoch 1022/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7996 - mae: 1.7068 - val_loss: 6.1188 - val_mae: 2.2678\n",
      "Epoch 1023/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.7974 - mae: 1.7063 - val_loss: 6.1120 - val_mae: 2.2667\n",
      "Epoch 1024/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.7951 - mae: 1.7058 - val_loss: 6.1051 - val_mae: 2.2655\n",
      "Epoch 1025/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.7927 - mae: 1.7053 - val_loss: 6.0982 - val_mae: 2.2644\n",
      "Epoch 1026/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.7905 - mae: 1.7048 - val_loss: 6.0914 - val_mae: 2.2632\n",
      "Epoch 1027/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7882 - mae: 1.7044 - val_loss: 6.0846 - val_mae: 2.2621\n",
      "Epoch 1028/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.7859 - mae: 1.7039 - val_loss: 6.0777 - val_mae: 2.2609\n",
      "Epoch 1029/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.7836 - mae: 1.7034 - val_loss: 6.0708 - val_mae: 2.2598\n",
      "Epoch 1030/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.7813 - mae: 1.7029 - val_loss: 6.0640 - val_mae: 2.2586\n",
      "Epoch 1031/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.7790 - mae: 1.7024 - val_loss: 6.0572 - val_mae: 2.2575\n",
      "Epoch 1032/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.7767 - mae: 1.7019 - val_loss: 6.0504 - val_mae: 2.2563\n",
      "Epoch 1033/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.7744 - mae: 1.7015 - val_loss: 6.0434 - val_mae: 2.2552\n",
      "Epoch 1034/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.7721 - mae: 1.7010 - val_loss: 6.0368 - val_mae: 2.2541\n",
      "Epoch 1035/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.7699 - mae: 1.7005 - val_loss: 6.0301 - val_mae: 2.2529\n",
      "Epoch 1036/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.7676 - mae: 1.7000 - val_loss: 6.0229 - val_mae: 2.2517\n",
      "Epoch 1037/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.7653 - mae: 1.6995 - val_loss: 6.0162 - val_mae: 2.2506\n",
      "Epoch 1038/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.7630 - mae: 1.6990 - val_loss: 6.0095 - val_mae: 2.2495\n",
      "Epoch 1039/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.7607 - mae: 1.6986 - val_loss: 6.0024 - val_mae: 2.2483\n",
      "Epoch 1040/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.7584 - mae: 1.6980 - val_loss: 5.9958 - val_mae: 2.2471\n",
      "Epoch 1041/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.7561 - mae: 1.6976 - val_loss: 5.9892 - val_mae: 2.2460\n",
      "Epoch 1042/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.7539 - mae: 1.6971 - val_loss: 5.9820 - val_mae: 2.2448\n",
      "Epoch 1043/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.7515 - mae: 1.6966 - val_loss: 5.9755 - val_mae: 2.2437\n",
      "Epoch 1044/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.7493 - mae: 1.6961 - val_loss: 5.9687 - val_mae: 2.2426\n",
      "Epoch 1045/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.7470 - mae: 1.6956 - val_loss: 5.9617 - val_mae: 2.2414\n",
      "Epoch 1046/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.7447 - mae: 1.6951 - val_loss: 5.9551 - val_mae: 2.2402\n",
      "Epoch 1047/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.7424 - mae: 1.6947 - val_loss: 5.9484 - val_mae: 2.2391\n",
      "Epoch 1048/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.7401 - mae: 1.6942 - val_loss: 5.9414 - val_mae: 2.2379\n",
      "Epoch 1049/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.7379 - mae: 1.6937 - val_loss: 5.9346 - val_mae: 2.2368\n",
      "Epoch 1050/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7356 - mae: 1.6932 - val_loss: 5.9279 - val_mae: 2.2356\n",
      "Epoch 1051/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.7333 - mae: 1.6927 - val_loss: 5.9211 - val_mae: 2.2345\n",
      "Epoch 1052/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.7310 - mae: 1.6922 - val_loss: 5.9143 - val_mae: 2.2333\n",
      "Epoch 1053/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.7287 - mae: 1.6917 - val_loss: 5.9075 - val_mae: 2.2322\n",
      "Epoch 1054/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.7265 - mae: 1.6912 - val_loss: 5.9008 - val_mae: 2.2310\n",
      "Epoch 1055/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.7242 - mae: 1.6908 - val_loss: 5.8941 - val_mae: 2.2299\n",
      "Epoch 1056/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.7219 - mae: 1.6903 - val_loss: 5.8873 - val_mae: 2.2287\n",
      "Epoch 1057/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.7196 - mae: 1.6898 - val_loss: 5.8804 - val_mae: 2.2275\n",
      "Epoch 1058/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.7173 - mae: 1.6893 - val_loss: 5.8738 - val_mae: 2.2264\n",
      "Epoch 1059/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.7151 - mae: 1.6888 - val_loss: 5.8669 - val_mae: 2.2252\n",
      "Epoch 1060/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7128 - mae: 1.6883 - val_loss: 5.8602 - val_mae: 2.2241\n",
      "Epoch 1061/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.7105 - mae: 1.6878 - val_loss: 5.8535 - val_mae: 2.2229\n",
      "Epoch 1062/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7083 - mae: 1.6873 - val_loss: 5.8466 - val_mae: 2.2217\n",
      "Epoch 1063/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.7060 - mae: 1.6868 - val_loss: 5.8400 - val_mae: 2.2206\n",
      "Epoch 1064/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.7037 - mae: 1.6863 - val_loss: 5.8332 - val_mae: 2.2194\n",
      "Epoch 1065/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.7014 - mae: 1.6858 - val_loss: 5.8263 - val_mae: 2.2182\n",
      "Epoch 1066/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.6992 - mae: 1.6854 - val_loss: 5.8198 - val_mae: 2.2171\n",
      "Epoch 1067/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6969 - mae: 1.6849 - val_loss: 5.8128 - val_mae: 2.2159\n",
      "Epoch 1068/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.6946 - mae: 1.6844 - val_loss: 5.8060 - val_mae: 2.2147\n",
      "Epoch 1069/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6924 - mae: 1.6839 - val_loss: 5.7997 - val_mae: 2.2136\n",
      "Epoch 1070/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6901 - mae: 1.6834 - val_loss: 5.7927 - val_mae: 2.2124\n",
      "Epoch 1071/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6878 - mae: 1.6829 - val_loss: 5.7857 - val_mae: 2.2112\n",
      "Epoch 1072/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.6856 - mae: 1.6824 - val_loss: 5.7791 - val_mae: 2.2101\n",
      "Epoch 1073/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6833 - mae: 1.6819 - val_loss: 5.7726 - val_mae: 2.2090\n",
      "Epoch 1074/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6811 - mae: 1.6814 - val_loss: 5.7656 - val_mae: 2.2078\n",
      "Epoch 1075/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.6788 - mae: 1.6809 - val_loss: 5.7589 - val_mae: 2.2066\n",
      "Epoch 1076/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.6765 - mae: 1.6804 - val_loss: 5.7525 - val_mae: 2.2055\n",
      "Epoch 1077/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.6743 - mae: 1.6799 - val_loss: 5.7455 - val_mae: 2.2043\n",
      "Epoch 1078/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6720 - mae: 1.6794 - val_loss: 5.7386 - val_mae: 2.2031\n",
      "Epoch 1079/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.6698 - mae: 1.6789 - val_loss: 5.7323 - val_mae: 2.2020\n",
      "Epoch 1080/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6675 - mae: 1.6785 - val_loss: 5.7254 - val_mae: 2.2008\n",
      "Epoch 1081/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6653 - mae: 1.6780 - val_loss: 5.7184 - val_mae: 2.1996\n",
      "Epoch 1082/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.6630 - mae: 1.6775 - val_loss: 5.7120 - val_mae: 2.1984\n",
      "Epoch 1083/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6607 - mae: 1.6770 - val_loss: 5.7054 - val_mae: 2.1973\n",
      "Epoch 1084/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.6585 - mae: 1.6765 - val_loss: 5.6983 - val_mae: 2.1961\n",
      "Epoch 1085/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.6562 - mae: 1.6760 - val_loss: 5.6917 - val_mae: 2.1949\n",
      "Epoch 1086/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.6540 - mae: 1.6755 - val_loss: 5.6853 - val_mae: 2.1938\n",
      "Epoch 1087/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.6517 - mae: 1.6750 - val_loss: 5.6783 - val_mae: 2.1926\n",
      "Epoch 1088/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6495 - mae: 1.6745 - val_loss: 5.6715 - val_mae: 2.1914\n",
      "Epoch 1089/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.6472 - mae: 1.6740 - val_loss: 5.6650 - val_mae: 2.1902\n",
      "Epoch 1090/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6449 - mae: 1.6735 - val_loss: 5.6581 - val_mae: 2.1890\n",
      "Epoch 1091/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.6427 - mae: 1.6730 - val_loss: 5.6511 - val_mae: 2.1878\n",
      "Epoch 1092/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.6404 - mae: 1.6725 - val_loss: 5.6444 - val_mae: 2.1866\n",
      "Epoch 1093/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.6381 - mae: 1.6720 - val_loss: 5.6376 - val_mae: 2.1854\n",
      "Epoch 1094/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6358 - mae: 1.6715 - val_loss: 5.6305 - val_mae: 2.1842\n",
      "Epoch 1095/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6335 - mae: 1.6709 - val_loss: 5.6237 - val_mae: 2.1830\n",
      "Epoch 1096/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.6312 - mae: 1.6704 - val_loss: 5.6170 - val_mae: 2.1818\n",
      "Epoch 1097/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6289 - mae: 1.6699 - val_loss: 5.6099 - val_mae: 2.1806\n",
      "Epoch 1098/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.6266 - mae: 1.6694 - val_loss: 5.6029 - val_mae: 2.1793\n",
      "Epoch 1099/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6243 - mae: 1.6689 - val_loss: 5.5962 - val_mae: 2.1782\n",
      "Epoch 1100/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.6219 - mae: 1.6684 - val_loss: 5.5891 - val_mae: 2.1769\n",
      "Epoch 1101/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6196 - mae: 1.6678 - val_loss: 5.5820 - val_mae: 2.1757\n",
      "Epoch 1102/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.6174 - mae: 1.6673 - val_loss: 5.5753 - val_mae: 2.1745\n",
      "Epoch 1103/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6150 - mae: 1.6668 - val_loss: 5.5683 - val_mae: 2.1732\n",
      "Epoch 1104/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6126 - mae: 1.6662 - val_loss: 5.5608 - val_mae: 2.1719\n",
      "Epoch 1105/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.6103 - mae: 1.6657 - val_loss: 5.5539 - val_mae: 2.1707\n",
      "Epoch 1106/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.6080 - mae: 1.6651 - val_loss: 5.5469 - val_mae: 2.1695\n",
      "Epoch 1107/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6056 - mae: 1.6646 - val_loss: 5.5395 - val_mae: 2.1682\n",
      "Epoch 1108/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6033 - mae: 1.6641 - val_loss: 5.5325 - val_mae: 2.1669\n",
      "Epoch 1109/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.6011 - mae: 1.6636 - val_loss: 5.5255 - val_mae: 2.1657\n",
      "Epoch 1110/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.5989 - mae: 1.6631 - val_loss: 5.5184 - val_mae: 2.1644\n",
      "Epoch 1111/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5967 - mae: 1.6625 - val_loss: 5.5117 - val_mae: 2.1632\n",
      "Epoch 1112/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.5944 - mae: 1.6620 - val_loss: 5.5048 - val_mae: 2.1620\n",
      "Epoch 1113/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.5922 - mae: 1.6615 - val_loss: 5.4978 - val_mae: 2.1607\n",
      "Epoch 1114/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5900 - mae: 1.6610 - val_loss: 5.4914 - val_mae: 2.1596\n",
      "Epoch 1115/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.5877 - mae: 1.6605 - val_loss: 5.4842 - val_mae: 2.1583\n",
      "Epoch 1116/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5855 - mae: 1.6600 - val_loss: 5.4778 - val_mae: 2.1571\n",
      "Epoch 1117/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5833 - mae: 1.6595 - val_loss: 5.4713 - val_mae: 2.1560\n",
      "Epoch 1118/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5811 - mae: 1.6590 - val_loss: 5.4643 - val_mae: 2.1547\n",
      "Epoch 1119/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.5788 - mae: 1.6585 - val_loss: 5.4579 - val_mae: 2.1535\n",
      "Epoch 1120/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5766 - mae: 1.6580 - val_loss: 5.4513 - val_mae: 2.1524\n",
      "Epoch 1121/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.5744 - mae: 1.6575 - val_loss: 5.4446 - val_mae: 2.1511\n",
      "Epoch 1122/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.5721 - mae: 1.6570 - val_loss: 5.4383 - val_mae: 2.1500\n",
      "Epoch 1123/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.5699 - mae: 1.6565 - val_loss: 5.4317 - val_mae: 2.1488\n",
      "Epoch 1124/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.5677 - mae: 1.6560 - val_loss: 5.4250 - val_mae: 2.1476\n",
      "Epoch 1125/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.5655 - mae: 1.6555 - val_loss: 5.4187 - val_mae: 2.1464\n",
      "Epoch 1126/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5632 - mae: 1.6550 - val_loss: 5.4123 - val_mae: 2.1453\n",
      "Epoch 1127/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.5610 - mae: 1.6545 - val_loss: 5.4056 - val_mae: 2.1441\n",
      "Epoch 1128/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5587 - mae: 1.6540 - val_loss: 5.3992 - val_mae: 2.1429\n",
      "Epoch 1129/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5565 - mae: 1.6535 - val_loss: 5.3930 - val_mae: 2.1417\n",
      "Epoch 1130/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5543 - mae: 1.6530 - val_loss: 5.3861 - val_mae: 2.1405\n",
      "Epoch 1131/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5521 - mae: 1.6525 - val_loss: 5.3798 - val_mae: 2.1393\n",
      "Epoch 1132/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.5498 - mae: 1.6520 - val_loss: 5.3736 - val_mae: 2.1382\n",
      "Epoch 1133/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.5476 - mae: 1.6515 - val_loss: 5.3669 - val_mae: 2.1370\n",
      "Epoch 1134/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5454 - mae: 1.6510 - val_loss: 5.3606 - val_mae: 2.1358\n",
      "Epoch 1135/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5432 - mae: 1.6505 - val_loss: 5.3543 - val_mae: 2.1347\n",
      "Epoch 1136/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5409 - mae: 1.6500 - val_loss: 5.3478 - val_mae: 2.1335\n",
      "Epoch 1137/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.5387 - mae: 1.6495 - val_loss: 5.3413 - val_mae: 2.1323\n",
      "Epoch 1138/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.5365 - mae: 1.6490 - val_loss: 5.3351 - val_mae: 2.1311\n",
      "Epoch 1139/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5343 - mae: 1.6485 - val_loss: 5.3286 - val_mae: 2.1299\n",
      "Epoch 1140/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.5321 - mae: 1.6480 - val_loss: 5.3220 - val_mae: 2.1287\n",
      "Epoch 1141/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.5299 - mae: 1.6475 - val_loss: 5.3159 - val_mae: 2.1276\n",
      "Epoch 1142/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5276 - mae: 1.6470 - val_loss: 5.3094 - val_mae: 2.1264\n",
      "Epoch 1143/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5254 - mae: 1.6465 - val_loss: 5.3028 - val_mae: 2.1252\n",
      "Epoch 1144/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.5232 - mae: 1.6460 - val_loss: 5.2966 - val_mae: 2.1240\n",
      "Epoch 1145/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5210 - mae: 1.6455 - val_loss: 5.2902 - val_mae: 2.1229\n",
      "Epoch 1146/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.5188 - mae: 1.6450 - val_loss: 5.2836 - val_mae: 2.1217\n",
      "Epoch 1147/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.5166 - mae: 1.6445 - val_loss: 5.2773 - val_mae: 2.1205\n",
      "Epoch 1148/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5144 - mae: 1.6440 - val_loss: 5.2710 - val_mae: 2.1193\n",
      "Epoch 1149/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5122 - mae: 1.6435 - val_loss: 5.2644 - val_mae: 2.1181\n",
      "Epoch 1150/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.5100 - mae: 1.6429 - val_loss: 5.2581 - val_mae: 2.1169\n",
      "Epoch 1151/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.5077 - mae: 1.6424 - val_loss: 5.2519 - val_mae: 2.1158\n",
      "Epoch 1152/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.5056 - mae: 1.6419 - val_loss: 5.2452 - val_mae: 2.1145\n",
      "Epoch 1153/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.5033 - mae: 1.6414 - val_loss: 5.2389 - val_mae: 2.1134\n",
      "Epoch 1154/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.5011 - mae: 1.6409 - val_loss: 5.2326 - val_mae: 2.1122\n",
      "Epoch 1155/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4989 - mae: 1.6404 - val_loss: 5.2261 - val_mae: 2.1110\n",
      "Epoch 1156/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.4967 - mae: 1.6399 - val_loss: 5.2196 - val_mae: 2.1098\n",
      "Epoch 1157/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.4945 - mae: 1.6394 - val_loss: 5.2134 - val_mae: 2.1086\n",
      "Epoch 1158/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.4923 - mae: 1.6389 - val_loss: 5.2069 - val_mae: 2.1074\n",
      "Epoch 1159/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.4901 - mae: 1.6384 - val_loss: 5.2004 - val_mae: 2.1062\n",
      "Epoch 1160/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.4879 - mae: 1.6379 - val_loss: 5.1942 - val_mae: 2.1051\n",
      "Epoch 1161/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4858 - mae: 1.6374 - val_loss: 5.1877 - val_mae: 2.1039\n",
      "Epoch 1162/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4835 - mae: 1.6369 - val_loss: 5.1811 - val_mae: 2.1026\n",
      "Epoch 1163/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4813 - mae: 1.6364 - val_loss: 5.1750 - val_mae: 2.1015\n",
      "Epoch 1164/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.4792 - mae: 1.6359 - val_loss: 5.1685 - val_mae: 2.1003\n",
      "Epoch 1165/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4770 - mae: 1.6354 - val_loss: 5.1618 - val_mae: 2.0991\n",
      "Epoch 1166/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.4748 - mae: 1.6348 - val_loss: 5.1558 - val_mae: 2.0979\n",
      "Epoch 1167/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.4726 - mae: 1.6343 - val_loss: 5.1493 - val_mae: 2.0967\n",
      "Epoch 1168/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4704 - mae: 1.6338 - val_loss: 5.1426 - val_mae: 2.0955\n",
      "Epoch 1169/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4682 - mae: 1.6333 - val_loss: 5.1366 - val_mae: 2.0943\n",
      "Epoch 1170/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.4660 - mae: 1.6328 - val_loss: 5.1301 - val_mae: 2.0931\n",
      "Epoch 1171/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4638 - mae: 1.6323 - val_loss: 5.1233 - val_mae: 2.0918\n",
      "Epoch 1172/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.4617 - mae: 1.6318 - val_loss: 5.1175 - val_mae: 2.0907\n",
      "Epoch 1173/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4594 - mae: 1.6313 - val_loss: 5.1106 - val_mae: 2.0895\n",
      "Epoch 1174/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4573 - mae: 1.6308 - val_loss: 5.1041 - val_mae: 2.0882\n",
      "Epoch 1175/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.4551 - mae: 1.6303 - val_loss: 5.0979 - val_mae: 2.0871\n",
      "Epoch 1176/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.4529 - mae: 1.6298 - val_loss: 5.0913 - val_mae: 2.0858\n",
      "Epoch 1177/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4507 - mae: 1.6292 - val_loss: 5.0848 - val_mae: 2.0846\n",
      "Epoch 1178/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.4486 - mae: 1.6287 - val_loss: 5.0786 - val_mae: 2.0834\n",
      "Epoch 1179/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.4464 - mae: 1.6282 - val_loss: 5.0720 - val_mae: 2.0822\n",
      "Epoch 1180/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.4442 - mae: 1.6277 - val_loss: 5.0652 - val_mae: 2.0809\n",
      "Epoch 1181/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.4421 - mae: 1.6272 - val_loss: 5.0592 - val_mae: 2.0798\n",
      "Epoch 1182/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.4399 - mae: 1.6267 - val_loss: 5.0524 - val_mae: 2.0785\n",
      "Epoch 1183/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.4377 - mae: 1.6262 - val_loss: 5.0458 - val_mae: 2.0773\n",
      "Epoch 1184/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4355 - mae: 1.6256 - val_loss: 5.0398 - val_mae: 2.0761\n",
      "Epoch 1185/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4334 - mae: 1.6251 - val_loss: 5.0332 - val_mae: 2.0749\n",
      "Epoch 1186/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.4312 - mae: 1.6246 - val_loss: 5.0266 - val_mae: 2.0736\n",
      "Epoch 1187/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.4290 - mae: 1.6241 - val_loss: 5.0204 - val_mae: 2.0724\n",
      "Epoch 1188/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.4269 - mae: 1.6236 - val_loss: 5.0139 - val_mae: 2.0712\n",
      "Epoch 1189/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.4247 - mae: 1.6231 - val_loss: 5.0073 - val_mae: 2.0700\n",
      "Epoch 1190/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4225 - mae: 1.6225 - val_loss: 5.0012 - val_mae: 2.0688\n",
      "Epoch 1191/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.4203 - mae: 1.6220 - val_loss: 4.9947 - val_mae: 2.0676\n",
      "Epoch 1192/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.4182 - mae: 1.6215 - val_loss: 4.9881 - val_mae: 2.0663\n",
      "Epoch 1193/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.4160 - mae: 1.6210 - val_loss: 4.9819 - val_mae: 2.0651\n",
      "Epoch 1194/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.4139 - mae: 1.6205 - val_loss: 4.9755 - val_mae: 2.0639\n",
      "Epoch 1195/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.4117 - mae: 1.6200 - val_loss: 4.9690 - val_mae: 2.0627\n",
      "Epoch 1196/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.4096 - mae: 1.6195 - val_loss: 4.9628 - val_mae: 2.0615\n",
      "Epoch 1197/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.4074 - mae: 1.6189 - val_loss: 4.9564 - val_mae: 2.0603\n",
      "Epoch 1198/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4052 - mae: 1.6184 - val_loss: 4.9500 - val_mae: 2.0590\n",
      "Epoch 1199/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.4031 - mae: 1.6179 - val_loss: 4.9438 - val_mae: 2.0578\n",
      "Epoch 1200/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.4009 - mae: 1.6175 - val_loss: 4.9373 - val_mae: 2.0566\n",
      "Epoch 1201/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.3988 - mae: 1.6170 - val_loss: 4.9308 - val_mae: 2.0553\n",
      "Epoch 1202/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.3966 - mae: 1.6165 - val_loss: 4.9247 - val_mae: 2.0542\n",
      "Epoch 1203/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.3945 - mae: 1.6161 - val_loss: 4.9183 - val_mae: 2.0529\n",
      "Epoch 1204/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.3923 - mae: 1.6156 - val_loss: 4.9117 - val_mae: 2.0517\n",
      "Epoch 1205/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.3902 - mae: 1.6151 - val_loss: 4.9057 - val_mae: 2.0505\n",
      "Epoch 1206/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.3880 - mae: 1.6147 - val_loss: 4.8992 - val_mae: 2.0493\n",
      "Epoch 1207/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.3859 - mae: 1.6142 - val_loss: 4.8928 - val_mae: 2.0480\n",
      "Epoch 1208/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3837 - mae: 1.6138 - val_loss: 4.8867 - val_mae: 2.0468\n",
      "Epoch 1209/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.3816 - mae: 1.6133 - val_loss: 4.8802 - val_mae: 2.0456\n",
      "Epoch 1210/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.3794 - mae: 1.6128 - val_loss: 4.8738 - val_mae: 2.0444\n",
      "Epoch 1211/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3773 - mae: 1.6124 - val_loss: 4.8676 - val_mae: 2.0431\n",
      "Epoch 1212/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.3752 - mae: 1.6119 - val_loss: 4.8613 - val_mae: 2.0419\n",
      "Epoch 1213/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3730 - mae: 1.6115 - val_loss: 4.8548 - val_mae: 2.0407\n",
      "Epoch 1214/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.3709 - mae: 1.6110 - val_loss: 4.8487 - val_mae: 2.0395\n",
      "Epoch 1215/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3687 - mae: 1.6105 - val_loss: 4.8423 - val_mae: 2.0382\n",
      "Epoch 1216/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3666 - mae: 1.6101 - val_loss: 4.8360 - val_mae: 2.0370\n",
      "Epoch 1217/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.3645 - mae: 1.6096 - val_loss: 4.8298 - val_mae: 2.0358\n",
      "Epoch 1218/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.3623 - mae: 1.6092 - val_loss: 4.8233 - val_mae: 2.0345\n",
      "Epoch 1219/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3602 - mae: 1.6087 - val_loss: 4.8171 - val_mae: 2.0333\n",
      "Epoch 1220/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.3581 - mae: 1.6082 - val_loss: 4.8108 - val_mae: 2.0321\n",
      "Epoch 1221/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.3559 - mae: 1.6078 - val_loss: 4.8045 - val_mae: 2.0308\n",
      "Epoch 1222/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.3538 - mae: 1.6073 - val_loss: 4.7982 - val_mae: 2.0296\n",
      "Epoch 1223/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.3517 - mae: 1.6068 - val_loss: 4.7920 - val_mae: 2.0284\n",
      "Epoch 1224/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3495 - mae: 1.6064 - val_loss: 4.7856 - val_mae: 2.0272\n",
      "Epoch 1225/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.3474 - mae: 1.6059 - val_loss: 4.7794 - val_mae: 2.0259\n",
      "Epoch 1226/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.3453 - mae: 1.6054 - val_loss: 4.7732 - val_mae: 2.0247\n",
      "Epoch 1227/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.3432 - mae: 1.6050 - val_loss: 4.7666 - val_mae: 2.0234\n",
      "Epoch 1228/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.3411 - mae: 1.6045 - val_loss: 4.7605 - val_mae: 2.0222\n",
      "Epoch 1229/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.3389 - mae: 1.6041 - val_loss: 4.7543 - val_mae: 2.0210\n",
      "Epoch 1230/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3368 - mae: 1.6036 - val_loss: 4.7478 - val_mae: 2.0197\n",
      "Epoch 1231/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.3347 - mae: 1.6031 - val_loss: 4.7418 - val_mae: 2.0185\n",
      "Epoch 1232/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.3326 - mae: 1.6027 - val_loss: 4.7355 - val_mae: 2.0173\n",
      "Epoch 1233/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3305 - mae: 1.6022 - val_loss: 4.7291 - val_mae: 2.0160\n",
      "Epoch 1234/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.3283 - mae: 1.6017 - val_loss: 4.7229 - val_mae: 2.0148\n",
      "Epoch 1235/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.3262 - mae: 1.6013 - val_loss: 4.7167 - val_mae: 2.0136\n",
      "Epoch 1236/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.3241 - mae: 1.6008 - val_loss: 4.7104 - val_mae: 2.0123\n",
      "Epoch 1237/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.3220 - mae: 1.6003 - val_loss: 4.7042 - val_mae: 2.0111\n",
      "Epoch 1238/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.3199 - mae: 1.5999 - val_loss: 4.6979 - val_mae: 2.0098\n",
      "Epoch 1239/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3178 - mae: 1.5994 - val_loss: 4.6915 - val_mae: 2.0086\n",
      "Epoch 1240/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.3157 - mae: 1.5989 - val_loss: 4.6854 - val_mae: 2.0073\n",
      "Epoch 1241/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.3136 - mae: 1.5985 - val_loss: 4.6792 - val_mae: 2.0061\n",
      "Epoch 1242/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.3115 - mae: 1.5980 - val_loss: 4.6728 - val_mae: 2.0048\n",
      "Epoch 1243/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.3093 - mae: 1.5975 - val_loss: 4.6668 - val_mae: 2.0036\n",
      "Epoch 1244/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.3073 - mae: 1.5971 - val_loss: 4.6603 - val_mae: 2.0023\n",
      "Epoch 1245/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.3052 - mae: 1.5966 - val_loss: 4.6542 - val_mae: 2.0011\n",
      "Epoch 1246/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3030 - mae: 1.5961 - val_loss: 4.6481 - val_mae: 1.9999\n",
      "Epoch 1247/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.3010 - mae: 1.5957 - val_loss: 4.6416 - val_mae: 1.9986\n",
      "Epoch 1248/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2988 - mae: 1.5952 - val_loss: 4.6355 - val_mae: 1.9974\n",
      "Epoch 1249/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2967 - mae: 1.5947 - val_loss: 4.6294 - val_mae: 1.9961\n",
      "Epoch 1250/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2947 - mae: 1.5943 - val_loss: 4.6230 - val_mae: 1.9949\n",
      "Epoch 1251/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2926 - mae: 1.5938 - val_loss: 4.6167 - val_mae: 1.9936\n",
      "Epoch 1252/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2905 - mae: 1.5933 - val_loss: 4.6108 - val_mae: 1.9924\n",
      "Epoch 1253/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2884 - mae: 1.5929 - val_loss: 4.6043 - val_mae: 1.9911\n",
      "Epoch 1254/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2863 - mae: 1.5924 - val_loss: 4.5983 - val_mae: 1.9899\n",
      "Epoch 1255/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2842 - mae: 1.5919 - val_loss: 4.5921 - val_mae: 1.9886\n",
      "Epoch 1256/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2821 - mae: 1.5915 - val_loss: 4.5857 - val_mae: 1.9873\n",
      "Epoch 1257/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.2800 - mae: 1.5910 - val_loss: 4.5796 - val_mae: 1.9861\n",
      "Epoch 1258/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2779 - mae: 1.5905 - val_loss: 4.5736 - val_mae: 1.9849\n",
      "Epoch 1259/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2758 - mae: 1.5900 - val_loss: 4.5670 - val_mae: 1.9836\n",
      "Epoch 1260/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2737 - mae: 1.5896 - val_loss: 4.5613 - val_mae: 1.9824\n",
      "Epoch 1261/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2717 - mae: 1.5891 - val_loss: 4.5548 - val_mae: 1.9811\n",
      "Epoch 1262/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2696 - mae: 1.5886 - val_loss: 4.5485 - val_mae: 1.9798\n",
      "Epoch 1263/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2675 - mae: 1.5881 - val_loss: 4.5428 - val_mae: 1.9786\n",
      "Epoch 1264/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2654 - mae: 1.5877 - val_loss: 4.5361 - val_mae: 1.9773\n",
      "Epoch 1265/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2633 - mae: 1.5872 - val_loss: 4.5301 - val_mae: 1.9761\n",
      "Epoch 1266/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2612 - mae: 1.5867 - val_loss: 4.5242 - val_mae: 1.9748\n",
      "Epoch 1267/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2592 - mae: 1.5863 - val_loss: 4.5176 - val_mae: 1.9735\n",
      "Epoch 1268/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2571 - mae: 1.5858 - val_loss: 4.5117 - val_mae: 1.9723\n",
      "Epoch 1269/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2550 - mae: 1.5853 - val_loss: 4.5056 - val_mae: 1.9711\n",
      "Epoch 1270/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2529 - mae: 1.5849 - val_loss: 4.4991 - val_mae: 1.9697\n",
      "Epoch 1271/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.2509 - mae: 1.5844 - val_loss: 4.4933 - val_mae: 1.9685\n",
      "Epoch 1272/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.2488 - mae: 1.5839 - val_loss: 4.4869 - val_mae: 1.9672\n",
      "Epoch 1273/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2467 - mae: 1.5834 - val_loss: 4.4810 - val_mae: 1.9660\n",
      "Epoch 1274/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.2447 - mae: 1.5830 - val_loss: 4.4747 - val_mae: 1.9647\n",
      "Epoch 1275/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.2426 - mae: 1.5825 - val_loss: 4.4686 - val_mae: 1.9635\n",
      "Epoch 1276/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2405 - mae: 1.5820 - val_loss: 4.4625 - val_mae: 1.9622\n",
      "Epoch 1277/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.2385 - mae: 1.5816 - val_loss: 4.4562 - val_mae: 1.9609\n",
      "Epoch 1278/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2364 - mae: 1.5811 - val_loss: 4.4502 - val_mae: 1.9596\n",
      "Epoch 1279/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2343 - mae: 1.5806 - val_loss: 4.4441 - val_mae: 1.9584\n",
      "Epoch 1280/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2323 - mae: 1.5801 - val_loss: 4.4378 - val_mae: 1.9571\n",
      "Epoch 1281/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2302 - mae: 1.5797 - val_loss: 4.4319 - val_mae: 1.9559\n",
      "Epoch 1282/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2281 - mae: 1.5792 - val_loss: 4.4257 - val_mae: 1.9546\n",
      "Epoch 1283/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.2261 - mae: 1.5787 - val_loss: 4.4196 - val_mae: 1.9533\n",
      "Epoch 1284/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2240 - mae: 1.5782 - val_loss: 4.4135 - val_mae: 1.9520\n",
      "Epoch 1285/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.2220 - mae: 1.5778 - val_loss: 4.4073 - val_mae: 1.9507\n",
      "Epoch 1286/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2199 - mae: 1.5773 - val_loss: 4.4013 - val_mae: 1.9495\n",
      "Epoch 1287/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2179 - mae: 1.5768 - val_loss: 4.3951 - val_mae: 1.9482\n",
      "Epoch 1288/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2158 - mae: 1.5763 - val_loss: 4.3890 - val_mae: 1.9469\n",
      "Epoch 1289/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2138 - mae: 1.5759 - val_loss: 4.3830 - val_mae: 1.9457\n",
      "Epoch 1290/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.2118 - mae: 1.5754 - val_loss: 4.3770 - val_mae: 1.9444\n",
      "Epoch 1291/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.2097 - mae: 1.5749 - val_loss: 4.3710 - val_mae: 1.9432\n",
      "Epoch 1292/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2076 - mae: 1.5745 - val_loss: 4.3652 - val_mae: 1.9419\n",
      "Epoch 1293/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2056 - mae: 1.5740 - val_loss: 4.3593 - val_mae: 1.9407\n",
      "Epoch 1294/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2036 - mae: 1.5735 - val_loss: 4.3535 - val_mae: 1.9395\n",
      "Epoch 1295/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2015 - mae: 1.5730 - val_loss: 4.3477 - val_mae: 1.9383\n",
      "Epoch 1296/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1995 - mae: 1.5726 - val_loss: 4.3417 - val_mae: 1.9370\n",
      "Epoch 1297/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.1974 - mae: 1.5721 - val_loss: 4.3357 - val_mae: 1.9357\n",
      "Epoch 1298/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.1954 - mae: 1.5716 - val_loss: 4.3299 - val_mae: 1.9345\n",
      "Epoch 1299/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1934 - mae: 1.5712 - val_loss: 4.3239 - val_mae: 1.9332\n",
      "Epoch 1300/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1913 - mae: 1.5707 - val_loss: 4.3178 - val_mae: 1.9320\n",
      "Epoch 1301/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1893 - mae: 1.5702 - val_loss: 4.3120 - val_mae: 1.9307\n",
      "Epoch 1302/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1873 - mae: 1.5697 - val_loss: 4.3060 - val_mae: 1.9295\n",
      "Epoch 1303/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1853 - mae: 1.5692 - val_loss: 4.2999 - val_mae: 1.9282\n",
      "Epoch 1304/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1832 - mae: 1.5688 - val_loss: 4.2941 - val_mae: 1.9269\n",
      "Epoch 1305/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.1812 - mae: 1.5683 - val_loss: 4.2880 - val_mae: 1.9256\n",
      "Epoch 1306/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1792 - mae: 1.5678 - val_loss: 4.2819 - val_mae: 1.9243\n",
      "Epoch 1307/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1771 - mae: 1.5673 - val_loss: 4.2761 - val_mae: 1.9231\n",
      "Epoch 1308/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.1751 - mae: 1.5669 - val_loss: 4.2704 - val_mae: 1.9219\n",
      "Epoch 1309/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.1731 - mae: 1.5664 - val_loss: 4.2644 - val_mae: 1.9206\n",
      "Epoch 1310/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1711 - mae: 1.5659 - val_loss: 4.2585 - val_mae: 1.9193\n",
      "Epoch 1311/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1690 - mae: 1.5654 - val_loss: 4.2527 - val_mae: 1.9181\n",
      "Epoch 1312/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1670 - mae: 1.5650 - val_loss: 4.2467 - val_mae: 1.9168\n",
      "Epoch 1313/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1650 - mae: 1.5645 - val_loss: 4.2406 - val_mae: 1.9155\n",
      "Epoch 1314/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1630 - mae: 1.5640 - val_loss: 4.2350 - val_mae: 1.9143\n",
      "Epoch 1315/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1610 - mae: 1.5635 - val_loss: 4.2289 - val_mae: 1.9130\n",
      "Epoch 1316/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.1590 - mae: 1.5631 - val_loss: 4.2230 - val_mae: 1.9118\n",
      "Epoch 1317/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.1570 - mae: 1.5626 - val_loss: 4.2174 - val_mae: 1.9105\n",
      "Epoch 1318/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1550 - mae: 1.5621 - val_loss: 4.2114 - val_mae: 1.9093\n",
      "Epoch 1319/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1530 - mae: 1.5616 - val_loss: 4.2056 - val_mae: 1.9080\n",
      "Epoch 1320/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1509 - mae: 1.5612 - val_loss: 4.1998 - val_mae: 1.9068\n",
      "Epoch 1321/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.1490 - mae: 1.5607 - val_loss: 4.1938 - val_mae: 1.9055\n",
      "Epoch 1322/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1469 - mae: 1.5602 - val_loss: 4.1881 - val_mae: 1.9042\n",
      "Epoch 1323/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1449 - mae: 1.5597 - val_loss: 4.1820 - val_mae: 1.9029\n",
      "Epoch 1324/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1429 - mae: 1.5593 - val_loss: 4.1762 - val_mae: 1.9017\n",
      "Epoch 1325/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1410 - mae: 1.5588 - val_loss: 4.1702 - val_mae: 1.9004\n",
      "Epoch 1326/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1389 - mae: 1.5583 - val_loss: 4.1644 - val_mae: 1.8991\n",
      "Epoch 1327/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1369 - mae: 1.5578 - val_loss: 4.1587 - val_mae: 1.8979\n",
      "Epoch 1328/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.1349 - mae: 1.5573 - val_loss: 4.1530 - val_mae: 1.8966\n",
      "Epoch 1329/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1330 - mae: 1.5569 - val_loss: 4.1469 - val_mae: 1.8953\n",
      "Epoch 1330/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1310 - mae: 1.5564 - val_loss: 4.1414 - val_mae: 1.8941\n",
      "Epoch 1331/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.1290 - mae: 1.5559 - val_loss: 4.1355 - val_mae: 1.8928\n",
      "Epoch 1332/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.1270 - mae: 1.5554 - val_loss: 4.1292 - val_mae: 1.8915\n",
      "Epoch 1333/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1250 - mae: 1.5549 - val_loss: 4.1240 - val_mae: 1.8903\n",
      "Epoch 1334/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.1230 - mae: 1.5545 - val_loss: 4.1180 - val_mae: 1.8890\n",
      "Epoch 1335/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1210 - mae: 1.5540 - val_loss: 4.1121 - val_mae: 1.8877\n",
      "Epoch 1336/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1191 - mae: 1.5535 - val_loss: 4.1065 - val_mae: 1.8865\n",
      "Epoch 1337/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.1171 - mae: 1.5531 - val_loss: 4.1005 - val_mae: 1.8852\n",
      "Epoch 1338/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1151 - mae: 1.5526 - val_loss: 4.0946 - val_mae: 1.8839\n",
      "Epoch 1339/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1131 - mae: 1.5521 - val_loss: 4.0892 - val_mae: 1.8827\n",
      "Epoch 1340/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.1111 - mae: 1.5516 - val_loss: 4.0831 - val_mae: 1.8814\n",
      "Epoch 1341/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.1092 - mae: 1.5511 - val_loss: 4.0776 - val_mae: 1.8801\n",
      "Epoch 1342/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.1072 - mae: 1.5507 - val_loss: 4.0719 - val_mae: 1.8789\n",
      "Epoch 1343/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.1052 - mae: 1.5502 - val_loss: 4.0658 - val_mae: 1.8775\n",
      "Epoch 1344/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.1033 - mae: 1.5497 - val_loss: 4.0603 - val_mae: 1.8763\n",
      "Epoch 1345/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1013 - mae: 1.5492 - val_loss: 4.0543 - val_mae: 1.8750\n",
      "Epoch 1346/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.0993 - mae: 1.5487 - val_loss: 4.0483 - val_mae: 1.8737\n",
      "Epoch 1347/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.0973 - mae: 1.5483 - val_loss: 4.0429 - val_mae: 1.8725\n",
      "Epoch 1348/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0954 - mae: 1.5478 - val_loss: 4.0371 - val_mae: 1.8712\n",
      "Epoch 1349/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0934 - mae: 1.5473 - val_loss: 4.0313 - val_mae: 1.8699\n",
      "Epoch 1350/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0915 - mae: 1.5468 - val_loss: 4.0261 - val_mae: 1.8687\n",
      "Epoch 1351/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0895 - mae: 1.5464 - val_loss: 4.0200 - val_mae: 1.8674\n",
      "Epoch 1352/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0875 - mae: 1.5459 - val_loss: 4.0141 - val_mae: 1.8661\n",
      "Epoch 1353/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0856 - mae: 1.5454 - val_loss: 4.0088 - val_mae: 1.8649\n",
      "Epoch 1354/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0836 - mae: 1.5449 - val_loss: 4.0028 - val_mae: 1.8636\n",
      "Epoch 1355/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0817 - mae: 1.5444 - val_loss: 3.9967 - val_mae: 1.8622\n",
      "Epoch 1356/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.0797 - mae: 1.5439 - val_loss: 3.9913 - val_mae: 1.8610\n",
      "Epoch 1357/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.0778 - mae: 1.5435 - val_loss: 3.9855 - val_mae: 1.8597\n",
      "Epoch 1358/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.0758 - mae: 1.5430 - val_loss: 3.9797 - val_mae: 1.8584\n",
      "Epoch 1359/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.0739 - mae: 1.5425 - val_loss: 3.9744 - val_mae: 1.8572\n",
      "Epoch 1360/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.0719 - mae: 1.5420 - val_loss: 3.9686 - val_mae: 1.8559\n",
      "Epoch 1361/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0700 - mae: 1.5415 - val_loss: 3.9629 - val_mae: 1.8546\n",
      "Epoch 1362/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0681 - mae: 1.5411 - val_loss: 3.9575 - val_mae: 1.8534\n",
      "Epoch 1363/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.0661 - mae: 1.5406 - val_loss: 3.9515 - val_mae: 1.8521\n",
      "Epoch 1364/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0642 - mae: 1.5401 - val_loss: 3.9459 - val_mae: 1.8508\n",
      "Epoch 1365/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.0622 - mae: 1.5396 - val_loss: 3.9404 - val_mae: 1.8496\n",
      "Epoch 1366/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0603 - mae: 1.5392 - val_loss: 3.9342 - val_mae: 1.8482\n",
      "Epoch 1367/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0584 - mae: 1.5387 - val_loss: 3.9288 - val_mae: 1.8469\n",
      "Epoch 1368/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0564 - mae: 1.5382 - val_loss: 3.9232 - val_mae: 1.8457\n",
      "Epoch 1369/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0545 - mae: 1.5377 - val_loss: 3.9170 - val_mae: 1.8443\n",
      "Epoch 1370/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0526 - mae: 1.5372 - val_loss: 3.9121 - val_mae: 1.8432\n",
      "Epoch 1371/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0506 - mae: 1.5367 - val_loss: 3.9063 - val_mae: 1.8419\n",
      "Epoch 1372/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.0487 - mae: 1.5363 - val_loss: 3.9004 - val_mae: 1.8405\n",
      "Epoch 1373/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 3.0468 - mae: 1.5358 - val_loss: 3.8956 - val_mae: 1.8394\n",
      "Epoch 1374/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0449 - mae: 1.5353 - val_loss: 3.8895 - val_mae: 1.8380\n",
      "Epoch 1375/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0429 - mae: 1.5348 - val_loss: 3.8837 - val_mae: 1.8367\n",
      "Epoch 1376/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.0410 - mae: 1.5343 - val_loss: 3.8787 - val_mae: 1.8356\n",
      "Epoch 1377/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0391 - mae: 1.5339 - val_loss: 3.8723 - val_mae: 1.8341\n",
      "Epoch 1378/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0372 - mae: 1.5334 - val_loss: 3.8669 - val_mae: 1.8329\n",
      "Epoch 1379/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0353 - mae: 1.5329 - val_loss: 3.8614 - val_mae: 1.8316\n",
      "Epoch 1380/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.0333 - mae: 1.5324 - val_loss: 3.8553 - val_mae: 1.8302\n",
      "Epoch 1381/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0315 - mae: 1.5319 - val_loss: 3.8503 - val_mae: 1.8291\n",
      "Epoch 1382/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.0295 - mae: 1.5315 - val_loss: 3.8444 - val_mae: 1.8277\n",
      "Epoch 1383/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.0276 - mae: 1.5310 - val_loss: 3.8389 - val_mae: 1.8265\n",
      "Epoch 1384/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.0257 - mae: 1.5305 - val_loss: 3.8337 - val_mae: 1.8253\n",
      "Epoch 1385/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0238 - mae: 1.5300 - val_loss: 3.8279 - val_mae: 1.8239\n",
      "Epoch 1386/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0219 - mae: 1.5295 - val_loss: 3.8227 - val_mae: 1.8227\n",
      "Epoch 1387/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.0200 - mae: 1.5290 - val_loss: 3.8170 - val_mae: 1.8214\n",
      "Epoch 1388/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.0181 - mae: 1.5286 - val_loss: 3.8114 - val_mae: 1.8201\n",
      "Epoch 1389/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.0162 - mae: 1.5281 - val_loss: 3.8061 - val_mae: 1.8189\n",
      "Epoch 1390/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0143 - mae: 1.5276 - val_loss: 3.8001 - val_mae: 1.8175\n",
      "Epoch 1391/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0124 - mae: 1.5271 - val_loss: 3.7947 - val_mae: 1.8163\n",
      "Epoch 1392/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0105 - mae: 1.5266 - val_loss: 3.7890 - val_mae: 1.8149\n",
      "Epoch 1393/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0086 - mae: 1.5261 - val_loss: 3.7834 - val_mae: 1.8136\n",
      "Epoch 1394/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0067 - mae: 1.5257 - val_loss: 3.7780 - val_mae: 1.8124\n",
      "Epoch 1395/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0048 - mae: 1.5252 - val_loss: 3.7723 - val_mae: 1.8111\n",
      "Epoch 1396/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0029 - mae: 1.5247 - val_loss: 3.7672 - val_mae: 1.8098\n",
      "Epoch 1397/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.0010 - mae: 1.5242 - val_loss: 3.7614 - val_mae: 1.8085\n",
      "Epoch 1398/3000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.9992 - mae: 1.5237 - val_loss: 3.7563 - val_mae: 1.8073\n",
      "Epoch 1399/3000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.9973 - mae: 1.5232 - val_loss: 3.7508 - val_mae: 1.8060\n",
      "Epoch 1400/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9954 - mae: 1.5227 - val_loss: 3.7453 - val_mae: 1.8047\n",
      "Epoch 1401/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.9935 - mae: 1.5223 - val_loss: 3.7400 - val_mae: 1.8035\n",
      "Epoch 1402/3000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 2.9916 - mae: 1.5218 - val_loss: 3.7344 - val_mae: 1.8022\n",
      "Epoch 1403/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9897 - mae: 1.5213 - val_loss: 3.7289 - val_mae: 1.8009\n",
      "Epoch 1404/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.9879 - mae: 1.5208 - val_loss: 3.7235 - val_mae: 1.7996\n",
      "Epoch 1405/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.9860 - mae: 1.5203 - val_loss: 3.7179 - val_mae: 1.7983\n",
      "Epoch 1406/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.9841 - mae: 1.5198 - val_loss: 3.7124 - val_mae: 1.7970\n",
      "Epoch 1407/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.9823 - mae: 1.5194 - val_loss: 3.7072 - val_mae: 1.7958\n",
      "Epoch 1408/3000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.9804 - mae: 1.5189 - val_loss: 3.7015 - val_mae: 1.7944\n",
      "Epoch 1409/3000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.9785 - mae: 1.5184 - val_loss: 3.6966 - val_mae: 1.7933\n",
      "Epoch 1410/3000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.9766 - mae: 1.5179 - val_loss: 3.6906 - val_mae: 1.7919\n",
      "Epoch 1411/3000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.9748 - mae: 1.5174 - val_loss: 3.6852 - val_mae: 1.7906\n",
      "Epoch 1412/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.9729 - mae: 1.5169 - val_loss: 3.6803 - val_mae: 1.7894\n",
      "Epoch 1413/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.9711 - mae: 1.5165 - val_loss: 3.6742 - val_mae: 1.7880\n",
      "Epoch 1414/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.9692 - mae: 1.5160 - val_loss: 3.6695 - val_mae: 1.7868\n",
      "Epoch 1415/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9674 - mae: 1.5155 - val_loss: 3.6636 - val_mae: 1.7854\n",
      "Epoch 1416/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9655 - mae: 1.5150 - val_loss: 3.6583 - val_mae: 1.7842\n",
      "Epoch 1417/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9637 - mae: 1.5145 - val_loss: 3.6530 - val_mae: 1.7829\n",
      "Epoch 1418/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9618 - mae: 1.5140 - val_loss: 3.6475 - val_mae: 1.7816\n",
      "Epoch 1419/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.9600 - mae: 1.5135 - val_loss: 3.6422 - val_mae: 1.7803\n",
      "Epoch 1420/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9581 - mae: 1.5131 - val_loss: 3.6368 - val_mae: 1.7790\n",
      "Epoch 1421/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.9563 - mae: 1.5126 - val_loss: 3.6316 - val_mae: 1.7778\n",
      "Epoch 1422/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9544 - mae: 1.5121 - val_loss: 3.6261 - val_mae: 1.7765\n",
      "Epoch 1423/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9526 - mae: 1.5116 - val_loss: 3.6207 - val_mae: 1.7752\n",
      "Epoch 1424/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.9508 - mae: 1.5111 - val_loss: 3.6155 - val_mae: 1.7739\n",
      "Epoch 1425/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.9489 - mae: 1.5106 - val_loss: 3.6099 - val_mae: 1.7726\n",
      "Epoch 1426/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.9471 - mae: 1.5101 - val_loss: 3.6049 - val_mae: 1.7714\n",
      "Epoch 1427/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.9452 - mae: 1.5097 - val_loss: 3.5995 - val_mae: 1.7701\n",
      "Epoch 1428/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.9434 - mae: 1.5092 - val_loss: 3.5938 - val_mae: 1.7687\n",
      "Epoch 1429/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9415 - mae: 1.5087 - val_loss: 3.5889 - val_mae: 1.7675\n",
      "Epoch 1430/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.9397 - mae: 1.5082 - val_loss: 3.5832 - val_mae: 1.7661\n",
      "Epoch 1431/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.9379 - mae: 1.5077 - val_loss: 3.5780 - val_mae: 1.7649\n",
      "Epoch 1432/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.9361 - mae: 1.5072 - val_loss: 3.5729 - val_mae: 1.7636\n",
      "Epoch 1433/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9342 - mae: 1.5067 - val_loss: 3.5673 - val_mae: 1.7623\n",
      "Epoch 1434/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9324 - mae: 1.5063 - val_loss: 3.5622 - val_mae: 1.7610\n",
      "Epoch 1435/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9306 - mae: 1.5058 - val_loss: 3.5571 - val_mae: 1.7598\n",
      "Epoch 1436/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9288 - mae: 1.5053 - val_loss: 3.5514 - val_mae: 1.7584\n",
      "Epoch 1437/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9270 - mae: 1.5048 - val_loss: 3.5467 - val_mae: 1.7572\n",
      "Epoch 1438/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.9251 - mae: 1.5043 - val_loss: 3.5408 - val_mae: 1.7558\n",
      "Epoch 1439/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9233 - mae: 1.5038 - val_loss: 3.5357 - val_mae: 1.7546\n",
      "Epoch 1440/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9215 - mae: 1.5033 - val_loss: 3.5308 - val_mae: 1.7533\n",
      "Epoch 1441/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9197 - mae: 1.5029 - val_loss: 3.5250 - val_mae: 1.7519\n",
      "Epoch 1442/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.9179 - mae: 1.5024 - val_loss: 3.5202 - val_mae: 1.7507\n",
      "Epoch 1443/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.9161 - mae: 1.5019 - val_loss: 3.5150 - val_mae: 1.7495\n",
      "Epoch 1444/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.9143 - mae: 1.5014 - val_loss: 3.5093 - val_mae: 1.7481\n",
      "Epoch 1445/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.9125 - mae: 1.5009 - val_loss: 3.5043 - val_mae: 1.7468\n",
      "Epoch 1446/3000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.9107 - mae: 1.5004 - val_loss: 3.4990 - val_mae: 1.7455\n",
      "Epoch 1447/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.9089 - mae: 1.4999 - val_loss: 3.4936 - val_mae: 1.7442\n",
      "Epoch 1448/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.9071 - mae: 1.4994 - val_loss: 3.4888 - val_mae: 1.7430\n",
      "Epoch 1449/3000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 2.9053 - mae: 1.4990 - val_loss: 3.4831 - val_mae: 1.7416\n",
      "Epoch 1450/3000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.9035 - mae: 1.4985 - val_loss: 3.4781 - val_mae: 1.7404\n",
      "Epoch 1451/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.9017 - mae: 1.4980 - val_loss: 3.4732 - val_mae: 1.7391\n",
      "Epoch 1452/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8999 - mae: 1.4975 - val_loss: 3.4676 - val_mae: 1.7378\n",
      "Epoch 1453/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8981 - mae: 1.4970 - val_loss: 3.4629 - val_mae: 1.7366\n",
      "Epoch 1454/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.8963 - mae: 1.4965 - val_loss: 3.4576 - val_mae: 1.7353\n",
      "Epoch 1455/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8945 - mae: 1.4960 - val_loss: 3.4521 - val_mae: 1.7339\n",
      "Epoch 1456/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8927 - mae: 1.4955 - val_loss: 3.4472 - val_mae: 1.7327\n",
      "Epoch 1457/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8910 - mae: 1.4951 - val_loss: 3.4418 - val_mae: 1.7313\n",
      "Epoch 1458/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.8892 - mae: 1.4946 - val_loss: 3.4366 - val_mae: 1.7300\n",
      "Epoch 1459/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8874 - mae: 1.4941 - val_loss: 3.4315 - val_mae: 1.7287\n",
      "Epoch 1460/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8857 - mae: 1.4936 - val_loss: 3.4263 - val_mae: 1.7274\n",
      "Epoch 1461/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.8839 - mae: 1.4931 - val_loss: 3.4211 - val_mae: 1.7261\n",
      "Epoch 1462/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8821 - mae: 1.4926 - val_loss: 3.4162 - val_mae: 1.7249\n",
      "Epoch 1463/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8803 - mae: 1.4921 - val_loss: 3.4108 - val_mae: 1.7235\n",
      "Epoch 1464/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8785 - mae: 1.4916 - val_loss: 3.4060 - val_mae: 1.7223\n",
      "Epoch 1465/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8768 - mae: 1.4912 - val_loss: 3.4009 - val_mae: 1.7210\n",
      "Epoch 1466/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8750 - mae: 1.4907 - val_loss: 3.3957 - val_mae: 1.7197\n",
      "Epoch 1467/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.8732 - mae: 1.4902 - val_loss: 3.3908 - val_mae: 1.7185\n",
      "Epoch 1468/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.8715 - mae: 1.4897 - val_loss: 3.3853 - val_mae: 1.7171\n",
      "Epoch 1469/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.8697 - mae: 1.4892 - val_loss: 3.3802 - val_mae: 1.7158\n",
      "Epoch 1470/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8680 - mae: 1.4887 - val_loss: 3.3753 - val_mae: 1.7145\n",
      "Epoch 1471/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.8662 - mae: 1.4882 - val_loss: 3.3698 - val_mae: 1.7132\n",
      "Epoch 1472/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8645 - mae: 1.4878 - val_loss: 3.3650 - val_mae: 1.7119\n",
      "Epoch 1473/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.8627 - mae: 1.4873 - val_loss: 3.3598 - val_mae: 1.7106\n",
      "Epoch 1474/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.8610 - mae: 1.4869 - val_loss: 3.3546 - val_mae: 1.7093\n",
      "Epoch 1475/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8592 - mae: 1.4864 - val_loss: 3.3497 - val_mae: 1.7080\n",
      "Epoch 1476/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8575 - mae: 1.4860 - val_loss: 3.3446 - val_mae: 1.7067\n",
      "Epoch 1477/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8557 - mae: 1.4855 - val_loss: 3.3395 - val_mae: 1.7054\n",
      "Epoch 1478/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8540 - mae: 1.4851 - val_loss: 3.3346 - val_mae: 1.7042\n",
      "Epoch 1479/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8522 - mae: 1.4846 - val_loss: 3.3295 - val_mae: 1.7029\n",
      "Epoch 1480/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8505 - mae: 1.4841 - val_loss: 3.3243 - val_mae: 1.7015\n",
      "Epoch 1481/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.8488 - mae: 1.4837 - val_loss: 3.3196 - val_mae: 1.7003\n",
      "Epoch 1482/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.8470 - mae: 1.4832 - val_loss: 3.3144 - val_mae: 1.6990\n",
      "Epoch 1483/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8453 - mae: 1.4828 - val_loss: 3.3094 - val_mae: 1.6977\n",
      "Epoch 1484/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8436 - mae: 1.4823 - val_loss: 3.3046 - val_mae: 1.6964\n",
      "Epoch 1485/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8418 - mae: 1.4819 - val_loss: 3.2993 - val_mae: 1.6951\n",
      "Epoch 1486/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.8401 - mae: 1.4814 - val_loss: 3.2947 - val_mae: 1.6939\n",
      "Epoch 1487/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.8384 - mae: 1.4809 - val_loss: 3.2895 - val_mae: 1.6925\n",
      "Epoch 1488/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.8366 - mae: 1.4805 - val_loss: 3.2847 - val_mae: 1.6913\n",
      "Epoch 1489/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8349 - mae: 1.4800 - val_loss: 3.2796 - val_mae: 1.6899\n",
      "Epoch 1490/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8332 - mae: 1.4796 - val_loss: 3.2748 - val_mae: 1.6887\n",
      "Epoch 1491/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.8315 - mae: 1.4791 - val_loss: 3.2698 - val_mae: 1.6874\n",
      "Epoch 1492/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.8298 - mae: 1.4787 - val_loss: 3.2648 - val_mae: 1.6861\n",
      "Epoch 1493/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.8280 - mae: 1.4782 - val_loss: 3.2599 - val_mae: 1.6848\n",
      "Epoch 1494/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8264 - mae: 1.4777 - val_loss: 3.2549 - val_mae: 1.6835\n",
      "Epoch 1495/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.8246 - mae: 1.4773 - val_loss: 3.2497 - val_mae: 1.6821\n",
      "Epoch 1496/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8229 - mae: 1.4768 - val_loss: 3.2451 - val_mae: 1.6809\n",
      "Epoch 1497/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.8212 - mae: 1.4764 - val_loss: 3.2398 - val_mae: 1.6795\n",
      "Epoch 1498/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.8195 - mae: 1.4759 - val_loss: 3.2349 - val_mae: 1.6782\n",
      "Epoch 1499/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8178 - mae: 1.4755 - val_loss: 3.2301 - val_mae: 1.6770\n",
      "Epoch 1500/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8161 - mae: 1.4750 - val_loss: 3.2248 - val_mae: 1.6756\n",
      "Epoch 1501/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.8144 - mae: 1.4746 - val_loss: 3.2202 - val_mae: 1.6744\n",
      "Epoch 1502/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8127 - mae: 1.4741 - val_loss: 3.2150 - val_mae: 1.6730\n",
      "Epoch 1503/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8110 - mae: 1.4737 - val_loss: 3.2102 - val_mae: 1.6717\n",
      "Epoch 1504/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8093 - mae: 1.4732 - val_loss: 3.2052 - val_mae: 1.6704\n",
      "Epoch 1505/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8076 - mae: 1.4727 - val_loss: 3.2003 - val_mae: 1.6691\n",
      "Epoch 1506/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.8059 - mae: 1.4723 - val_loss: 3.1954 - val_mae: 1.6678\n",
      "Epoch 1507/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8042 - mae: 1.4718 - val_loss: 3.1904 - val_mae: 1.6665\n",
      "Epoch 1508/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8025 - mae: 1.4714 - val_loss: 3.1857 - val_mae: 1.6652\n",
      "Epoch 1509/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8008 - mae: 1.4709 - val_loss: 3.1805 - val_mae: 1.6639\n",
      "Epoch 1510/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7991 - mae: 1.4705 - val_loss: 3.1758 - val_mae: 1.6626\n",
      "Epoch 1511/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7975 - mae: 1.4700 - val_loss: 3.1708 - val_mae: 1.6612\n",
      "Epoch 1512/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7958 - mae: 1.4696 - val_loss: 3.1661 - val_mae: 1.6600\n",
      "Epoch 1513/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7941 - mae: 1.4691 - val_loss: 3.1611 - val_mae: 1.6587\n",
      "Epoch 1514/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7924 - mae: 1.4687 - val_loss: 3.1561 - val_mae: 1.6573\n",
      "Epoch 1515/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7908 - mae: 1.4682 - val_loss: 3.1515 - val_mae: 1.6561\n",
      "Epoch 1516/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7891 - mae: 1.4678 - val_loss: 3.1458 - val_mae: 1.6546\n",
      "Epoch 1517/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7874 - mae: 1.4673 - val_loss: 3.1411 - val_mae: 1.6533\n",
      "Epoch 1518/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7856 - mae: 1.4668 - val_loss: 3.1354 - val_mae: 1.6518\n",
      "Epoch 1519/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.7839 - mae: 1.4664 - val_loss: 3.1300 - val_mae: 1.6503\n",
      "Epoch 1520/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.7821 - mae: 1.4659 - val_loss: 3.1248 - val_mae: 1.6489\n",
      "Epoch 1521/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7803 - mae: 1.4655 - val_loss: 3.1188 - val_mae: 1.6473\n",
      "Epoch 1522/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.7785 - mae: 1.4650 - val_loss: 3.1136 - val_mae: 1.6459\n",
      "Epoch 1523/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7767 - mae: 1.4646 - val_loss: 3.1077 - val_mae: 1.6443\n",
      "Epoch 1524/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7749 - mae: 1.4641 - val_loss: 3.1018 - val_mae: 1.6428\n",
      "Epoch 1525/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7731 - mae: 1.4637 - val_loss: 3.0963 - val_mae: 1.6413\n",
      "Epoch 1526/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7713 - mae: 1.4633 - val_loss: 3.0900 - val_mae: 1.6396\n",
      "Epoch 1527/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7695 - mae: 1.4629 - val_loss: 3.0846 - val_mae: 1.6381\n",
      "Epoch 1528/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7677 - mae: 1.4625 - val_loss: 3.0785 - val_mae: 1.6365\n",
      "Epoch 1529/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7658 - mae: 1.4620 - val_loss: 3.0725 - val_mae: 1.6348\n",
      "Epoch 1530/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.7639 - mae: 1.4616 - val_loss: 3.0657 - val_mae: 1.6330\n",
      "Epoch 1531/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7621 - mae: 1.4612 - val_loss: 3.0603 - val_mae: 1.6315\n",
      "Epoch 1532/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7603 - mae: 1.4608 - val_loss: 3.0536 - val_mae: 1.6297\n",
      "Epoch 1533/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7584 - mae: 1.4604 - val_loss: 3.0476 - val_mae: 1.6281\n",
      "Epoch 1534/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.7564 - mae: 1.4599 - val_loss: 3.0408 - val_mae: 1.6262\n",
      "Epoch 1535/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7543 - mae: 1.4594 - val_loss: 3.0336 - val_mae: 1.6243\n",
      "Epoch 1536/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.7522 - mae: 1.4588 - val_loss: 3.0270 - val_mae: 1.6224\n",
      "Epoch 1537/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.7500 - mae: 1.4582 - val_loss: 3.0189 - val_mae: 1.6202\n",
      "Epoch 1538/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7478 - mae: 1.4576 - val_loss: 3.0123 - val_mae: 1.6184\n",
      "Epoch 1539/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7456 - mae: 1.4570 - val_loss: 3.0042 - val_mae: 1.6162\n",
      "Epoch 1540/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.7437 - mae: 1.4564 - val_loss: 2.9972 - val_mae: 1.6143\n",
      "Epoch 1541/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7417 - mae: 1.4558 - val_loss: 2.9893 - val_mae: 1.6121\n",
      "Epoch 1542/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.7396 - mae: 1.4552 - val_loss: 2.9817 - val_mae: 1.6100\n",
      "Epoch 1543/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.7373 - mae: 1.4545 - val_loss: 2.9739 - val_mae: 1.6078\n",
      "Epoch 1544/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7347 - mae: 1.4538 - val_loss: 2.9647 - val_mae: 1.6053\n",
      "Epoch 1545/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7321 - mae: 1.4530 - val_loss: 2.9566 - val_mae: 1.6030\n",
      "Epoch 1546/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7295 - mae: 1.4524 - val_loss: 2.9466 - val_mae: 1.6002\n",
      "Epoch 1547/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7269 - mae: 1.4517 - val_loss: 2.9381 - val_mae: 1.5978\n",
      "Epoch 1548/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.7242 - mae: 1.4510 - val_loss: 2.9284 - val_mae: 1.5951\n",
      "Epoch 1549/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.7215 - mae: 1.4503 - val_loss: 2.9186 - val_mae: 1.5924\n",
      "Epoch 1550/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.7188 - mae: 1.4495 - val_loss: 2.9099 - val_mae: 1.5899\n",
      "Epoch 1551/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7160 - mae: 1.4488 - val_loss: 2.8988 - val_mae: 1.5868\n",
      "Epoch 1552/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7132 - mae: 1.4481 - val_loss: 2.8906 - val_mae: 1.5844\n",
      "Epoch 1553/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.7104 - mae: 1.4473 - val_loss: 2.8796 - val_mae: 1.5813\n",
      "Epoch 1554/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.7077 - mae: 1.4467 - val_loss: 2.8695 - val_mae: 1.5784\n",
      "Epoch 1555/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.7057 - mae: 1.4462 - val_loss: 2.8596 - val_mae: 1.5755\n",
      "Epoch 1556/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7037 - mae: 1.4457 - val_loss: 2.8497 - val_mae: 1.5727\n",
      "Epoch 1557/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.7015 - mae: 1.4451 - val_loss: 2.8401 - val_mae: 1.5699\n",
      "Epoch 1558/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6992 - mae: 1.4445 - val_loss: 2.8300 - val_mae: 1.5669\n",
      "Epoch 1559/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6968 - mae: 1.4438 - val_loss: 2.8208 - val_mae: 1.5642\n",
      "Epoch 1560/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6945 - mae: 1.4432 - val_loss: 2.8106 - val_mae: 1.5612\n",
      "Epoch 1561/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6921 - mae: 1.4426 - val_loss: 2.8019 - val_mae: 1.5586\n",
      "Epoch 1562/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6897 - mae: 1.4420 - val_loss: 2.7917 - val_mae: 1.5556\n",
      "Epoch 1563/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.6874 - mae: 1.4413 - val_loss: 2.7832 - val_mae: 1.5530\n",
      "Epoch 1564/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6851 - mae: 1.4407 - val_loss: 2.7732 - val_mae: 1.5500\n",
      "Epoch 1565/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6827 - mae: 1.4401 - val_loss: 2.7647 - val_mae: 1.5474\n",
      "Epoch 1566/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6804 - mae: 1.4395 - val_loss: 2.7550 - val_mae: 1.5445\n",
      "Epoch 1567/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6780 - mae: 1.4388 - val_loss: 2.7462 - val_mae: 1.5418\n",
      "Epoch 1568/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6757 - mae: 1.4382 - val_loss: 2.7371 - val_mae: 1.5390\n",
      "Epoch 1569/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.6733 - mae: 1.4375 - val_loss: 2.7279 - val_mae: 1.5362\n",
      "Epoch 1570/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6710 - mae: 1.4369 - val_loss: 2.7193 - val_mae: 1.5335\n",
      "Epoch 1571/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6687 - mae: 1.4363 - val_loss: 2.7099 - val_mae: 1.5306\n",
      "Epoch 1572/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.6663 - mae: 1.4356 - val_loss: 2.7016 - val_mae: 1.5281\n",
      "Epoch 1573/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.6640 - mae: 1.4350 - val_loss: 2.6921 - val_mae: 1.5251\n",
      "Epoch 1574/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6622 - mae: 1.4344 - val_loss: 2.6845 - val_mae: 1.5227\n",
      "Epoch 1575/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6604 - mae: 1.4339 - val_loss: 2.6764 - val_mae: 1.5201\n",
      "Epoch 1576/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6585 - mae: 1.4334 - val_loss: 2.6690 - val_mae: 1.5178\n",
      "Epoch 1577/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6567 - mae: 1.4328 - val_loss: 2.6620 - val_mae: 1.5155\n",
      "Epoch 1578/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6549 - mae: 1.4323 - val_loss: 2.6549 - val_mae: 1.5132\n",
      "Epoch 1579/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6531 - mae: 1.4318 - val_loss: 2.6487 - val_mae: 1.5112\n",
      "Epoch 1580/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6513 - mae: 1.4313 - val_loss: 2.6420 - val_mae: 1.5091\n",
      "Epoch 1581/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6495 - mae: 1.4307 - val_loss: 2.6361 - val_mae: 1.5071\n",
      "Epoch 1582/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6477 - mae: 1.4302 - val_loss: 2.6299 - val_mae: 1.5051\n",
      "Epoch 1583/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6458 - mae: 1.4297 - val_loss: 2.6244 - val_mae: 1.5032\n",
      "Epoch 1584/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6440 - mae: 1.4292 - val_loss: 2.6185 - val_mae: 1.5013\n",
      "Epoch 1585/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6423 - mae: 1.4287 - val_loss: 2.6131 - val_mae: 1.4995\n",
      "Epoch 1586/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6405 - mae: 1.4282 - val_loss: 2.6076 - val_mae: 1.4977\n",
      "Epoch 1587/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6387 - mae: 1.4277 - val_loss: 2.6021 - val_mae: 1.4958\n",
      "Epoch 1588/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6369 - mae: 1.4271 - val_loss: 2.5971 - val_mae: 1.4941\n",
      "Epoch 1589/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6351 - mae: 1.4267 - val_loss: 2.5916 - val_mae: 1.4923\n",
      "Epoch 1590/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6333 - mae: 1.4261 - val_loss: 2.5868 - val_mae: 1.4907\n",
      "Epoch 1591/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.6315 - mae: 1.4256 - val_loss: 2.5813 - val_mae: 1.4888\n",
      "Epoch 1592/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6298 - mae: 1.4251 - val_loss: 2.5763 - val_mae: 1.4872\n",
      "Epoch 1593/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6280 - mae: 1.4246 - val_loss: 2.5714 - val_mae: 1.4855\n",
      "Epoch 1594/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.6263 - mae: 1.4241 - val_loss: 2.5661 - val_mae: 1.4837\n",
      "Epoch 1595/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6245 - mae: 1.4236 - val_loss: 2.5615 - val_mae: 1.4821\n",
      "Epoch 1596/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.6228 - mae: 1.4231 - val_loss: 2.5558 - val_mae: 1.4802\n",
      "Epoch 1597/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.6210 - mae: 1.4226 - val_loss: 2.5515 - val_mae: 1.4788\n",
      "Epoch 1598/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.6193 - mae: 1.4222 - val_loss: 2.5457 - val_mae: 1.4768\n",
      "Epoch 1599/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.6175 - mae: 1.4216 - val_loss: 2.5414 - val_mae: 1.4754\n",
      "Epoch 1600/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.6158 - mae: 1.4212 - val_loss: 2.5359 - val_mae: 1.4735\n",
      "Epoch 1601/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.6140 - mae: 1.4207 - val_loss: 2.5311 - val_mae: 1.4719\n",
      "Epoch 1602/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.6123 - mae: 1.4202 - val_loss: 2.5260 - val_mae: 1.4702\n",
      "Epoch 1603/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.6106 - mae: 1.4197 - val_loss: 2.5207 - val_mae: 1.4684\n",
      "Epoch 1604/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.6089 - mae: 1.4192 - val_loss: 2.5160 - val_mae: 1.4668\n",
      "Epoch 1605/3000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.6071 - mae: 1.4187 - val_loss: 2.5103 - val_mae: 1.4649\n",
      "Epoch 1606/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.6054 - mae: 1.4182 - val_loss: 2.5059 - val_mae: 1.4634\n",
      "Epoch 1607/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6037 - mae: 1.4177 - val_loss: 2.4999 - val_mae: 1.4614\n",
      "Epoch 1608/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6020 - mae: 1.4172 - val_loss: 2.4958 - val_mae: 1.4600\n",
      "Epoch 1609/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6003 - mae: 1.4168 - val_loss: 2.4893 - val_mae: 1.4578\n",
      "Epoch 1610/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5985 - mae: 1.4163 - val_loss: 2.4855 - val_mae: 1.4565\n",
      "Epoch 1611/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5968 - mae: 1.4158 - val_loss: 2.4788 - val_mae: 1.4543\n",
      "Epoch 1612/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5951 - mae: 1.4153 - val_loss: 2.4751 - val_mae: 1.4530\n",
      "Epoch 1613/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5934 - mae: 1.4149 - val_loss: 2.4683 - val_mae: 1.4508\n",
      "Epoch 1614/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5917 - mae: 1.4143 - val_loss: 2.4644 - val_mae: 1.4494\n",
      "Epoch 1615/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5900 - mae: 1.4139 - val_loss: 2.4579 - val_mae: 1.4473\n",
      "Epoch 1616/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5883 - mae: 1.4134 - val_loss: 2.4537 - val_mae: 1.4458\n",
      "Epoch 1617/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5866 - mae: 1.4129 - val_loss: 2.4473 - val_mae: 1.4437\n",
      "Epoch 1618/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5849 - mae: 1.4124 - val_loss: 2.4431 - val_mae: 1.4422\n",
      "Epoch 1619/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5832 - mae: 1.4120 - val_loss: 2.4366 - val_mae: 1.4401\n",
      "Epoch 1620/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5815 - mae: 1.4115 - val_loss: 2.4324 - val_mae: 1.4386\n",
      "Epoch 1621/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.5798 - mae: 1.4110 - val_loss: 2.4257 - val_mae: 1.4364\n",
      "Epoch 1622/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.5781 - mae: 1.4105 - val_loss: 2.4218 - val_mae: 1.4350\n",
      "Epoch 1623/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5764 - mae: 1.4101 - val_loss: 2.4148 - val_mae: 1.4327\n",
      "Epoch 1624/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5747 - mae: 1.4095 - val_loss: 2.4111 - val_mae: 1.4314\n",
      "Epoch 1625/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5730 - mae: 1.4091 - val_loss: 2.4040 - val_mae: 1.4290\n",
      "Epoch 1626/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5714 - mae: 1.4086 - val_loss: 2.4004 - val_mae: 1.4277\n",
      "Epoch 1627/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5697 - mae: 1.4082 - val_loss: 2.3931 - val_mae: 1.4253\n",
      "Epoch 1628/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5680 - mae: 1.4076 - val_loss: 2.3896 - val_mae: 1.4241\n",
      "Epoch 1629/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5663 - mae: 1.4072 - val_loss: 2.3822 - val_mae: 1.4216\n",
      "Epoch 1630/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5646 - mae: 1.4067 - val_loss: 2.3790 - val_mae: 1.4204\n",
      "Epoch 1631/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5630 - mae: 1.4063 - val_loss: 2.3712 - val_mae: 1.4178\n",
      "Epoch 1632/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.5613 - mae: 1.4057 - val_loss: 2.3684 - val_mae: 1.4168\n",
      "Epoch 1633/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5596 - mae: 1.4053 - val_loss: 2.3602 - val_mae: 1.4140\n",
      "Epoch 1634/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5579 - mae: 1.4047 - val_loss: 2.3578 - val_mae: 1.4131\n",
      "Epoch 1635/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5563 - mae: 1.4044 - val_loss: 2.3492 - val_mae: 1.4102\n",
      "Epoch 1636/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5546 - mae: 1.4038 - val_loss: 2.3473 - val_mae: 1.4095\n",
      "Epoch 1637/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5529 - mae: 1.4034 - val_loss: 2.3381 - val_mae: 1.4064\n",
      "Epoch 1638/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.5513 - mae: 1.4028 - val_loss: 2.3370 - val_mae: 1.4059\n",
      "Epoch 1639/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5496 - mae: 1.4025 - val_loss: 2.3269 - val_mae: 1.4024\n",
      "Epoch 1640/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5480 - mae: 1.4019 - val_loss: 2.3268 - val_mae: 1.4023\n",
      "Epoch 1641/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5463 - mae: 1.4016 - val_loss: 2.3154 - val_mae: 1.3984\n",
      "Epoch 1642/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5446 - mae: 1.4009 - val_loss: 2.3170 - val_mae: 1.3988\n",
      "Epoch 1643/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5430 - mae: 1.4006 - val_loss: 2.3037 - val_mae: 1.3943\n",
      "Epoch 1644/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5413 - mae: 1.3999 - val_loss: 2.3077 - val_mae: 1.3956\n",
      "Epoch 1645/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5396 - mae: 1.3997 - val_loss: 2.2914 - val_mae: 1.3900\n",
      "Epoch 1646/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5380 - mae: 1.3988 - val_loss: 2.2990 - val_mae: 1.3924\n",
      "Epoch 1647/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5364 - mae: 1.3989 - val_loss: 2.2785 - val_mae: 1.3854\n",
      "Epoch 1648/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5347 - mae: 1.3978 - val_loss: 2.2914 - val_mae: 1.3897\n",
      "Epoch 1649/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5331 - mae: 1.3980 - val_loss: 2.2642 - val_mae: 1.3804\n",
      "Epoch 1650/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5314 - mae: 1.3967 - val_loss: 2.2855 - val_mae: 1.3875\n",
      "Epoch 1651/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5298 - mae: 1.3973 - val_loss: 2.2478 - val_mae: 1.3746\n",
      "Epoch 1652/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.5282 - mae: 1.3955 - val_loss: 2.2826 - val_mae: 1.3864\n",
      "Epoch 1653/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5266 - mae: 1.3966 - val_loss: 2.2279 - val_mae: 1.3675\n",
      "Epoch 1654/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5251 - mae: 1.3941 - val_loss: 2.2846 - val_mae: 1.3868\n",
      "Epoch 1655/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5236 - mae: 1.3961 - val_loss: 2.2024 - val_mae: 1.3584\n",
      "Epoch 1656/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5223 - mae: 1.3926 - val_loss: 2.2946 - val_mae: 1.3899\n",
      "Epoch 1657/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5210 - mae: 1.3960 - val_loss: 2.1677 - val_mae: 1.3457\n",
      "Epoch 1658/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5201 - mae: 1.3906 - val_loss: 2.3191 - val_mae: 1.3977\n",
      "Epoch 1659/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5196 - mae: 1.3963 - val_loss: 2.1175 - val_mae: 1.3269\n",
      "Epoch 1660/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5198 - mae: 1.3879 - val_loss: 2.3696 - val_mae: 1.4136\n",
      "Epoch 1661/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.5214 - mae: 1.3994 - val_loss: 2.0429 - val_mae: 1.2974\n",
      "Epoch 1662/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5251 - mae: 1.3853 - val_loss: 2.4698 - val_mae: 1.4437\n",
      "Epoch 1663/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5327 - mae: 1.4062 - val_loss: 1.9316 - val_mae: 1.2488\n",
      "Epoch 1664/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5470 - mae: 1.3841 - val_loss: 2.6741 - val_mae: 1.5004\n",
      "Epoch 1665/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.5729 - mae: 1.4249 - val_loss: 1.7769 - val_mae: 1.1667\n",
      "Epoch 1666/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6198 - mae: 1.3967 - val_loss: 3.1030 - val_mae: 1.6043\n",
      "Epoch 1667/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7037 - mae: 1.4599 - val_loss: 1.6089 - val_mae: 1.0467\n",
      "Epoch 1668/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.8540 - mae: 1.4433 - val_loss: 4.0625 - val_mae: 1.7933\n",
      "Epoch 1669/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.1245 - mae: 1.5431 - val_loss: 1.6469 - val_mae: 1.0170\n",
      "Epoch 1670/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6140 - mae: 1.5633 - val_loss: 6.4323 - val_mae: 2.2072\n",
      "Epoch 1671/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.5046 - mae: 1.7426 - val_loss: 2.8585 - val_mae: 1.2651\n",
      "Epoch 1672/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.1362 - mae: 1.9839 - val_loss: 12.9246 - val_mae: 3.3701\n",
      "Epoch 1673/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 9.1423 - mae: 2.5764 - val_loss: 9.0404 - val_mae: 2.7343\n",
      "Epoch 1674/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 14.7199 - mae: 3.5006 - val_loss: 32.4443 - val_mae: 5.5566\n",
      "Epoch 1675/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 25.0878 - mae: 4.7497 - val_loss: 34.3385 - val_mae: 5.7251\n",
      "Epoch 1676/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 44.4213 - mae: 6.4792 - val_loss: 94.6965 - val_mae: 9.6495\n",
      "Epoch 1677/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 80.2537 - mae: 8.8146 - val_loss: 128.0690 - val_mae: 11.2479\n",
      "Epoch 1678/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 146.0074 - mae: 11.9837 - val_loss: 291.4550 - val_mae: 17.0246\n",
      "Epoch 1679/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 262.8740 - mae: 16.1326 - val_loss: 429.0797 - val_mae: 20.6772\n",
      "Epoch 1680/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 459.5864 - mae: 21.3836 - val_loss: 808.9097 - val_mae: 28.4114\n",
      "Epoch 1681/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 754.7483 - mae: 27.4232 - val_loss: 1066.3370 - val_mae: 32.6321\n",
      "Epoch 1682/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1110.8936 - mae: 33.2963 - val_loss: 1433.4581 - val_mae: 37.8371\n",
      "Epoch 1683/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1354.2605 - mae: 36.7621 - val_loss: 1168.0688 - val_mae: 34.1546\n",
      "Epoch 1684/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1215.7817 - mae: 34.8356 - val_loss: 692.5930 - val_mae: 26.2835\n",
      "Epoch 1685/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 640.6269 - mae: 25.2568 - val_loss: 75.2170 - val_mae: 8.5773\n",
      "Epoch 1686/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 91.3495 - mae: 9.4283 - val_loss: 50.2626 - val_mae: 6.9714\n",
      "Epoch 1687/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 64.4072 - mae: 7.8693 - val_loss: 470.1266 - val_mae: 21.6413\n",
      "Epoch 1688/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 424.4473 - mae: 20.5360 - val_loss: 535.4141 - val_mae: 23.1042\n",
      "Epoch 1689/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 576.8361 - mae: 23.9678 - val_loss: 595.3167 - val_mae: 24.3630\n",
      "Epoch 1690/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 544.3434 - mae: 23.2718 - val_loss: 907.4410 - val_mae: 30.0989\n",
      "Epoch 1691/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 969.6459 - mae: 31.1004 - val_loss: 1743.7296 - val_mae: 41.7357\n",
      "Epoch 1692/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1622.4973 - mae: 40.2426 - val_loss: 987.3312 - val_mae: 31.3977\n",
      "Epoch 1693/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1055.4954 - mae: 32.4512 - val_loss: 91.8816 - val_mae: 9.4946\n",
      "Epoch 1694/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 69.1820 - mae: 8.1493 - val_loss: 385.6585 - val_mae: 19.5904\n",
      "Epoch 1695/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 336.6624 - mae: 18.2717 - val_loss: 797.8772 - val_mae: 28.2175\n",
      "Epoch 1696/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 859.5220 - mae: 29.2763 - val_loss: 322.1192 - val_mae: 17.8948\n",
      "Epoch 1697/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 275.9214 - mae: 16.5257 - val_loss: 92.5430 - val_mae: 9.5226\n",
      "Epoch 1698/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 69.6537 - mae: 8.1785 - val_loss: 498.3552 - val_mae: 22.2856\n",
      "Epoch 1699/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 553.0115 - mae: 23.4626 - val_loss: 338.5034 - val_mae: 18.3458\n",
      "Epoch 1700/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 288.5153 - mae: 16.9008 - val_loss: 30.4383 - val_mae: 5.3446\n",
      "Epoch 1701/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 18.4446 - mae: 3.9582 - val_loss: 317.7032 - val_mae: 17.7749\n",
      "Epoch 1702/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 365.0901 - mae: 19.0393 - val_loss: 266.9453 - val_mae: 16.2784\n",
      "Epoch 1703/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 221.6758 - mae: 14.7911 - val_loss: 22.1159 - val_mae: 4.4960\n",
      "Epoch 1704/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 12.2142 - mae: 3.0670 - val_loss: 220.4655 - val_mae: 14.7873\n",
      "Epoch 1705/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 262.1843 - mae: 16.1101 - val_loss: 182.1904 - val_mae: 13.4244\n",
      "Epoch 1706/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 144.9665 - mae: 11.9190 - val_loss: 28.9849 - val_mae: 5.2007\n",
      "Epoch 1707/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 16.7978 - mae: 3.7364 - val_loss: 161.6719 - val_mae: 12.6425\n",
      "Epoch 1708/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 198.8359 - mae: 14.0052 - val_loss: 109.2503 - val_mae: 10.3566\n",
      "Epoch 1709/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 81.1551 - mae: 8.8464 - val_loss: 43.2672 - val_mae: 6.4259\n",
      "Epoch 1710/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 27.2238 - mae: 4.9353 - val_loss: 117.7946 - val_mae: 10.7665\n",
      "Epoch 1711/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 150.4552 - mae: 12.1546 - val_loss: 55.2555 - val_mae: 7.2977\n",
      "Epoch 1712/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 36.4702 - mae: 5.7955 - val_loss: 59.3380 - val_mae: 7.5717\n",
      "Epoch 1713/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 39.6837 - mae: 6.0660 - val_loss: 79.8909 - val_mae: 8.8308\n",
      "Epoch 1714/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 107.5356 - mae: 10.2366 - val_loss: 21.6072 - val_mae: 4.4279\n",
      "Epoch 1715/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 11.5066 - mae: 2.9398 - val_loss: 70.9555 - val_mae: 8.3019\n",
      "Epoch 1716/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 49.0128 - mae: 6.7907 - val_loss: 47.3177 - val_mae: 6.7363\n",
      "Epoch 1717/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 69.2546 - mae: 8.1539 - val_loss: 5.6837 - val_mae: 2.1356\n",
      "Epoch 1718/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.0464 - mae: 1.5940 - val_loss: 73.7107 - val_mae: 8.4651\n",
      "Epoch 1719/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 51.3248 - mae: 6.9587 - val_loss: 22.6056 - val_mae: 4.5426\n",
      "Epoch 1720/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 38.3795 - mae: 5.9660 - val_loss: 2.0130 - val_mae: 1.0976\n",
      "Epoch 1721/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.1757 - mae: 1.7724 - val_loss: 67.0116 - val_mae: 8.0589\n",
      "Epoch 1722/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 46.0036 - mae: 6.5657 - val_loss: 7.6960 - val_mae: 2.3867\n",
      "Epoch 1723/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 17.2899 - mae: 3.8067 - val_loss: 4.2946 - val_mae: 1.5922\n",
      "Epoch 1724/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 11.3689 - mae: 2.9265 - val_loss: 53.4138 - val_mae: 7.1651\n",
      "Epoch 1725/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 35.4374 - mae: 5.7059 - val_loss: 2.2161 - val_mae: 1.0916\n",
      "Epoch 1726/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.1996 - mae: 1.9441 - val_loss: 7.3930 - val_mae: 2.3184\n",
      "Epoch 1727/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 16.5483 - mae: 3.7086 - val_loss: 37.7257 - val_mae: 5.9706\n",
      "Epoch 1728/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 23.4368 - mae: 4.5356 - val_loss: 3.4714 - val_mae: 1.7484\n",
      "Epoch 1729/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8641 - mae: 1.4749 - val_loss: 8.5740 - val_mae: 2.5589\n",
      "Epoch 1730/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 18.2449 - mae: 3.9318 - val_loss: 23.6505 - val_mae: 4.6446\n",
      "Epoch 1731/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 13.3036 - mae: 3.2337 - val_loss: 7.8415 - val_mae: 2.4569\n",
      "Epoch 1732/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.8477 - mae: 1.7298 - val_loss: 7.5640 - val_mae: 2.3514\n",
      "Epoch 1733/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 16.5384 - mae: 3.7092 - val_loss: 13.2970 - val_mae: 3.3497\n",
      "Epoch 1734/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.6802 - mae: 2.1174 - val_loss: 12.1889 - val_mae: 3.1798\n",
      "Epoch 1735/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.0609 - mae: 2.0236 - val_loss: 5.4125 - val_mae: 1.8472\n",
      "Epoch 1736/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 12.8867 - mae: 3.1798 - val_loss: 6.9530 - val_mae: 2.3210\n",
      "Epoch 1737/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.5219 - mae: 1.6833 - val_loss: 14.7444 - val_mae: 3.5580\n",
      "Epoch 1738/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.6201 - mae: 2.2660 - val_loss: 3.3779 - val_mae: 1.3211\n",
      "Epoch 1739/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.9368 - mae: 2.4831 - val_loss: 3.7495 - val_mae: 1.8129\n",
      "Epoch 1740/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7909 - mae: 1.4777 - val_loss: 15.1186 - val_mae: 3.6100\n",
      "Epoch 1741/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.9120 - mae: 2.3189 - val_loss: 2.2336 - val_mae: 1.0906\n",
      "Epoch 1742/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.7930 - mae: 1.8804 - val_loss: 2.4732 - val_mae: 1.4464\n",
      "Epoch 1743/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2380 - mae: 1.4970 - val_loss: 13.8040 - val_mae: 3.4236\n",
      "Epoch 1744/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.1631 - mae: 2.1861 - val_loss: 2.1322 - val_mae: 1.2391\n",
      "Epoch 1745/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.8444 - mae: 1.5753 - val_loss: 2.1108 - val_mae: 1.2163\n",
      "Epoch 1746/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.9136 - mae: 1.5851 - val_loss: 11.6084 - val_mae: 3.0874\n",
      "Epoch 1747/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.9233 - mae: 1.9892 - val_loss: 2.7851 - val_mae: 1.5628\n",
      "Epoch 1748/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.9560 - mae: 1.4666 - val_loss: 2.0540 - val_mae: 1.1351\n",
      "Epoch 1749/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.3274 - mae: 1.6525 - val_loss: 9.2564 - val_mae: 2.6809\n",
      "Epoch 1750/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.6864 - mae: 1.8219 - val_loss: 3.7584 - val_mae: 1.8135\n",
      "Epoch 1751/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7562 - mae: 1.4746 - val_loss: 2.0484 - val_mae: 1.1227\n",
      "Epoch 1752/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.3668 - mae: 1.6595 - val_loss: 7.1929 - val_mae: 2.3490\n",
      "Epoch 1753/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.7312 - mae: 1.7021 - val_loss: 4.6825 - val_mae: 1.9886\n",
      "Epoch 1754/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.8744 - mae: 1.5408 - val_loss: 2.0513 - val_mae: 1.1497\n",
      "Epoch 1755/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.1259 - mae: 1.6238 - val_loss: 5.5984 - val_mae: 2.1336\n",
      "Epoch 1756/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1329 - mae: 1.6070 - val_loss: 5.3388 - val_mae: 2.0943\n",
      "Epoch 1757/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0539 - mae: 1.5897 - val_loss: 2.0953 - val_mae: 1.2130\n",
      "Epoch 1758/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.7588 - mae: 1.5672 - val_loss: 4.4693 - val_mae: 1.9501\n",
      "Epoch 1759/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8351 - mae: 1.5256 - val_loss: 5.6588 - val_mae: 2.1412\n",
      "Epoch 1760/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1681 - mae: 1.6120 - val_loss: 2.2110 - val_mae: 1.3143\n",
      "Epoch 1761/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.3927 - mae: 1.5177 - val_loss: 3.7218 - val_mae: 1.8035\n",
      "Epoch 1762/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7352 - mae: 1.4746 - val_loss: 5.6802 - val_mae: 2.1431\n",
      "Epoch 1763/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.1876 - mae: 1.6143 - val_loss: 2.3992 - val_mae: 1.4175\n",
      "Epoch 1764/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0996 - mae: 1.4790 - val_loss: 3.2523 - val_mae: 1.6941\n",
      "Epoch 1765/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7365 - mae: 1.4531 - val_loss: 5.4879 - val_mae: 2.1133\n",
      "Epoch 1766/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1336 - mae: 1.6028 - val_loss: 2.6354 - val_mae: 1.5124\n",
      "Epoch 1767/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.9001 - mae: 1.4541 - val_loss: 2.9722 - val_mae: 1.6188\n",
      "Epoch 1768/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.7703 - mae: 1.4477 - val_loss: 5.1776 - val_mae: 2.0645\n",
      "Epoch 1769/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0418 - mae: 1.5828 - val_loss: 2.8865 - val_mae: 1.5936\n",
      "Epoch 1770/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.7835 - mae: 1.4465 - val_loss: 2.8183 - val_mae: 1.5727\n",
      "Epoch 1771/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.7995 - mae: 1.4458 - val_loss: 4.8267 - val_mae: 2.0067\n",
      "Epoch 1772/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9430 - mae: 1.5584 - val_loss: 3.1204 - val_mae: 1.6586\n",
      "Epoch 1773/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7257 - mae: 1.4459 - val_loss: 2.7443 - val_mae: 1.5490\n",
      "Epoch 1774/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8109 - mae: 1.4441 - val_loss: 4.4819 - val_mae: 1.9464\n",
      "Epoch 1775/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8559 - mae: 1.5327 - val_loss: 3.3133 - val_mae: 1.7067\n",
      "Epoch 1776/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.7032 - mae: 1.4508 - val_loss: 2.7219 - val_mae: 1.5415\n",
      "Epoch 1777/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.8046 - mae: 1.4424 - val_loss: 4.1712 - val_mae: 1.8885\n",
      "Epoch 1778/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7885 - mae: 1.5091 - val_loss: 3.4545 - val_mae: 1.7394\n",
      "Epoch 1779/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.6978 - mae: 1.4589 - val_loss: 2.7328 - val_mae: 1.5448\n",
      "Epoch 1780/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.7864 - mae: 1.4407 - val_loss: 3.9065 - val_mae: 1.8359\n",
      "Epoch 1781/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7410 - mae: 1.4922 - val_loss: 3.5435 - val_mae: 1.7587\n",
      "Epoch 1782/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.6982 - mae: 1.4663 - val_loss: 2.7643 - val_mae: 1.5546\n",
      "Epoch 1783/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7627 - mae: 1.4391 - val_loss: 3.6894 - val_mae: 1.7899\n",
      "Epoch 1784/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.7098 - mae: 1.4774 - val_loss: 3.5860 - val_mae: 1.7671\n",
      "Epoch 1785/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6982 - mae: 1.4700 - val_loss: 2.8067 - val_mae: 1.5675\n",
      "Epoch 1786/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7384 - mae: 1.4375 - val_loss: 3.5163 - val_mae: 1.7510\n",
      "Epoch 1787/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6903 - mae: 1.4650 - val_loss: 3.5911 - val_mae: 1.7673\n",
      "Epoch 1788/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6959 - mae: 1.4708 - val_loss: 2.8529 - val_mae: 1.5810\n",
      "Epoch 1789/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.7163 - mae: 1.4359 - val_loss: 3.3805 - val_mae: 1.7190\n",
      "Epoch 1790/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6780 - mae: 1.4549 - val_loss: 3.5688 - val_mae: 1.7614\n",
      "Epoch 1791/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6910 - mae: 1.4695 - val_loss: 2.8975 - val_mae: 1.5935\n",
      "Epoch 1792/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6976 - mae: 1.4343 - val_loss: 3.2754 - val_mae: 1.6930\n",
      "Epoch 1793/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.6699 - mae: 1.4469 - val_loss: 3.5280 - val_mae: 1.7513\n",
      "Epoch 1794/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6841 - mae: 1.4668 - val_loss: 2.9369 - val_mae: 1.6042\n",
      "Epoch 1795/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.6823 - mae: 1.4326 - val_loss: 3.1943 - val_mae: 1.6721\n",
      "Epoch 1796/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6637 - mae: 1.4420 - val_loss: 3.4759 - val_mae: 1.7386\n",
      "Epoch 1797/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6761 - mae: 1.4633 - val_loss: 2.9688 - val_mae: 1.6124\n",
      "Epoch 1798/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.6700 - mae: 1.4310 - val_loss: 3.1318 - val_mae: 1.6554\n",
      "Epoch 1799/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6584 - mae: 1.4380 - val_loss: 3.4181 - val_mae: 1.7244\n",
      "Epoch 1800/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.6679 - mae: 1.4592 - val_loss: 2.9924 - val_mae: 1.6182\n",
      "Epoch 1801/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6604 - mae: 1.4300 - val_loss: 3.0839 - val_mae: 1.6422\n",
      "Epoch 1802/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6536 - mae: 1.4348 - val_loss: 3.3599 - val_mae: 1.7099\n",
      "Epoch 1803/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6602 - mae: 1.4551 - val_loss: 3.0084 - val_mae: 1.6217\n",
      "Epoch 1804/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.6527 - mae: 1.4302 - val_loss: 3.0473 - val_mae: 1.6318\n",
      "Epoch 1805/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6491 - mae: 1.4325 - val_loss: 3.3039 - val_mae: 1.6957\n",
      "Epoch 1806/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6532 - mae: 1.4511 - val_loss: 3.0178 - val_mae: 1.6235\n",
      "Epoch 1807/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6466 - mae: 1.4306 - val_loss: 3.0197 - val_mae: 1.6238\n",
      "Epoch 1808/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6447 - mae: 1.4307 - val_loss: 3.2527 - val_mae: 1.6825\n",
      "Epoch 1809/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6468 - mae: 1.4474 - val_loss: 3.0222 - val_mae: 1.6241\n",
      "Epoch 1810/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6411 - mae: 1.4307 - val_loss: 2.9993 - val_mae: 1.6178\n",
      "Epoch 1811/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6401 - mae: 1.4292 - val_loss: 3.2066 - val_mae: 1.6706\n",
      "Epoch 1812/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6408 - mae: 1.4438 - val_loss: 3.0225 - val_mae: 1.6236\n",
      "Epoch 1813/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6361 - mae: 1.4304 - val_loss: 2.9834 - val_mae: 1.6130\n",
      "Epoch 1814/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6355 - mae: 1.4279 - val_loss: 3.1653 - val_mae: 1.6598\n",
      "Epoch 1815/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.6353 - mae: 1.4406 - val_loss: 3.0187 - val_mae: 1.6221\n",
      "Epoch 1816/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.6314 - mae: 1.4298 - val_loss: 2.9705 - val_mae: 1.6091\n",
      "Epoch 1817/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6309 - mae: 1.4267 - val_loss: 3.1282 - val_mae: 1.6499\n",
      "Epoch 1818/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.6301 - mae: 1.4375 - val_loss: 3.0117 - val_mae: 1.6197\n",
      "Epoch 1819/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6268 - mae: 1.4290 - val_loss: 2.9592 - val_mae: 1.6055\n",
      "Epoch 1820/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6262 - mae: 1.4256 - val_loss: 3.0947 - val_mae: 1.6409\n",
      "Epoch 1821/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6250 - mae: 1.4347 - val_loss: 3.0022 - val_mae: 1.6167\n",
      "Epoch 1822/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6223 - mae: 1.4280 - val_loss: 2.9487 - val_mae: 1.6022\n",
      "Epoch 1823/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6215 - mae: 1.4246 - val_loss: 3.0645 - val_mae: 1.6326\n",
      "Epoch 1824/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6202 - mae: 1.4321 - val_loss: 2.9906 - val_mae: 1.6131\n",
      "Epoch 1825/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6178 - mae: 1.4268 - val_loss: 2.9387 - val_mae: 1.5991\n",
      "Epoch 1826/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.6169 - mae: 1.4235 - val_loss: 3.0369 - val_mae: 1.6250\n",
      "Epoch 1827/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6155 - mae: 1.4297 - val_loss: 2.9775 - val_mae: 1.6092\n",
      "Epoch 1828/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6134 - mae: 1.4256 - val_loss: 2.9286 - val_mae: 1.5959\n",
      "Epoch 1829/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6123 - mae: 1.4224 - val_loss: 3.0116 - val_mae: 1.6179\n",
      "Epoch 1830/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6109 - mae: 1.4275 - val_loss: 2.9634 - val_mae: 1.6049\n",
      "Epoch 1831/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6089 - mae: 1.4243 - val_loss: 2.9183 - val_mae: 1.5926\n",
      "Epoch 1832/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6078 - mae: 1.4213 - val_loss: 2.9882 - val_mae: 1.6112\n",
      "Epoch 1833/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6063 - mae: 1.4254 - val_loss: 2.9483 - val_mae: 1.6004\n",
      "Epoch 1834/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.6046 - mae: 1.4229 - val_loss: 2.9074 - val_mae: 1.5892\n",
      "Epoch 1835/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6033 - mae: 1.4202 - val_loss: 2.9664 - val_mae: 1.6049\n",
      "Epoch 1836/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6018 - mae: 1.4237 - val_loss: 2.9328 - val_mae: 1.5958\n",
      "Epoch 1837/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6001 - mae: 1.4215 - val_loss: 2.8961 - val_mae: 1.5857\n",
      "Epoch 1838/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5989 - mae: 1.4191 - val_loss: 2.9458 - val_mae: 1.5989\n",
      "Epoch 1839/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5974 - mae: 1.4220 - val_loss: 2.9169 - val_mae: 1.5910\n",
      "Epoch 1840/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5958 - mae: 1.4201 - val_loss: 2.8845 - val_mae: 1.5820\n",
      "Epoch 1841/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5944 - mae: 1.4179 - val_loss: 2.9261 - val_mae: 1.5932\n",
      "Epoch 1842/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5930 - mae: 1.4203 - val_loss: 2.9008 - val_mae: 1.5862\n",
      "Epoch 1843/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5914 - mae: 1.4186 - val_loss: 2.8725 - val_mae: 1.5783\n",
      "Epoch 1844/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5900 - mae: 1.4167 - val_loss: 2.9071 - val_mae: 1.5876\n",
      "Epoch 1845/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5886 - mae: 1.4187 - val_loss: 2.8846 - val_mae: 1.5813\n",
      "Epoch 1846/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5870 - mae: 1.4172 - val_loss: 2.8600 - val_mae: 1.5744\n",
      "Epoch 1847/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.5857 - mae: 1.4155 - val_loss: 2.8889 - val_mae: 1.5822\n",
      "Epoch 1848/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5842 - mae: 1.4171 - val_loss: 2.8683 - val_mae: 1.5764\n",
      "Epoch 1849/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5827 - mae: 1.4157 - val_loss: 2.8473 - val_mae: 1.5705\n",
      "Epoch 1850/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5813 - mae: 1.4142 - val_loss: 2.8711 - val_mae: 1.5769\n",
      "Epoch 1851/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.5799 - mae: 1.4156 - val_loss: 2.8521 - val_mae: 1.5715\n",
      "Epoch 1852/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5784 - mae: 1.4142 - val_loss: 2.8341 - val_mae: 1.5664\n",
      "Epoch 1853/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5770 - mae: 1.4130 - val_loss: 2.8537 - val_mae: 1.5717\n",
      "Epoch 1854/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5755 - mae: 1.4140 - val_loss: 2.8360 - val_mae: 1.5666\n",
      "Epoch 1855/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5740 - mae: 1.4128 - val_loss: 2.8207 - val_mae: 1.5622\n",
      "Epoch 1856/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5726 - mae: 1.4117 - val_loss: 2.8366 - val_mae: 1.5665\n",
      "Epoch 1857/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5712 - mae: 1.4125 - val_loss: 2.8200 - val_mae: 1.5617\n",
      "Epoch 1858/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5698 - mae: 1.4113 - val_loss: 2.8071 - val_mae: 1.5580\n",
      "Epoch 1859/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5683 - mae: 1.4104 - val_loss: 2.8198 - val_mae: 1.5614\n",
      "Epoch 1860/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5669 - mae: 1.4110 - val_loss: 2.8041 - val_mae: 1.5569\n",
      "Epoch 1861/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5654 - mae: 1.4099 - val_loss: 2.7933 - val_mae: 1.5537\n",
      "Epoch 1862/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5640 - mae: 1.4093 - val_loss: 2.8033 - val_mae: 1.5563\n",
      "Epoch 1863/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5626 - mae: 1.4096 - val_loss: 2.7883 - val_mae: 1.5520\n",
      "Epoch 1864/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5612 - mae: 1.4086 - val_loss: 2.7792 - val_mae: 1.5493\n",
      "Epoch 1865/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5598 - mae: 1.4081 - val_loss: 2.7869 - val_mae: 1.5513\n",
      "Epoch 1866/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5583 - mae: 1.4081 - val_loss: 2.7727 - val_mae: 1.5472\n",
      "Epoch 1867/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.5569 - mae: 1.4074 - val_loss: 2.7652 - val_mae: 1.5449\n",
      "Epoch 1868/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5555 - mae: 1.4069 - val_loss: 2.7705 - val_mae: 1.5463\n",
      "Epoch 1869/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5541 - mae: 1.4069 - val_loss: 2.7574 - val_mae: 1.5424\n",
      "Epoch 1870/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5526 - mae: 1.4062 - val_loss: 2.7509 - val_mae: 1.5404\n",
      "Epoch 1871/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5513 - mae: 1.4058 - val_loss: 2.7545 - val_mae: 1.5413\n",
      "Epoch 1872/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5498 - mae: 1.4057 - val_loss: 2.7419 - val_mae: 1.5376\n",
      "Epoch 1873/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5484 - mae: 1.4050 - val_loss: 2.7366 - val_mae: 1.5359\n",
      "Epoch 1874/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5470 - mae: 1.4046 - val_loss: 2.7385 - val_mae: 1.5363\n",
      "Epoch 1875/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5456 - mae: 1.4044 - val_loss: 2.7267 - val_mae: 1.5328\n",
      "Epoch 1876/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5442 - mae: 1.4038 - val_loss: 2.7223 - val_mae: 1.5314\n",
      "Epoch 1877/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5428 - mae: 1.4034 - val_loss: 2.7227 - val_mae: 1.5314\n",
      "Epoch 1878/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5414 - mae: 1.4032 - val_loss: 2.7117 - val_mae: 1.5280\n",
      "Epoch 1879/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5400 - mae: 1.4026 - val_loss: 2.7078 - val_mae: 1.5268\n",
      "Epoch 1880/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5386 - mae: 1.4022 - val_loss: 2.7070 - val_mae: 1.5264\n",
      "Epoch 1881/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5372 - mae: 1.4020 - val_loss: 2.6968 - val_mae: 1.5233\n",
      "Epoch 1882/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5358 - mae: 1.4014 - val_loss: 2.6933 - val_mae: 1.5222\n",
      "Epoch 1883/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.5344 - mae: 1.4011 - val_loss: 2.6915 - val_mae: 1.5215\n",
      "Epoch 1884/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5330 - mae: 1.4008 - val_loss: 2.6819 - val_mae: 1.5186\n",
      "Epoch 1885/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5316 - mae: 1.4002 - val_loss: 2.6789 - val_mae: 1.5176\n",
      "Epoch 1886/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5302 - mae: 1.3999 - val_loss: 2.6760 - val_mae: 1.5166\n",
      "Epoch 1887/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5288 - mae: 1.3995 - val_loss: 2.6672 - val_mae: 1.5138\n",
      "Epoch 1888/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.5274 - mae: 1.3990 - val_loss: 2.6644 - val_mae: 1.5129\n",
      "Epoch 1889/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5260 - mae: 1.3987 - val_loss: 2.6607 - val_mae: 1.5117\n",
      "Epoch 1890/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5247 - mae: 1.3983 - val_loss: 2.6527 - val_mae: 1.5092\n",
      "Epoch 1891/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5233 - mae: 1.3978 - val_loss: 2.6498 - val_mae: 1.5082\n",
      "Epoch 1892/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5219 - mae: 1.3975 - val_loss: 2.6456 - val_mae: 1.5068\n",
      "Epoch 1893/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5205 - mae: 1.3971 - val_loss: 2.6382 - val_mae: 1.5045\n",
      "Epoch 1894/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5191 - mae: 1.3966 - val_loss: 2.6353 - val_mae: 1.5035\n",
      "Epoch 1895/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5177 - mae: 1.3963 - val_loss: 2.6306 - val_mae: 1.5020\n",
      "Epoch 1896/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5164 - mae: 1.3959 - val_loss: 2.6238 - val_mae: 1.4998\n",
      "Epoch 1897/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.5150 - mae: 1.3954 - val_loss: 2.6207 - val_mae: 1.4987\n",
      "Epoch 1898/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5136 - mae: 1.3951 - val_loss: 2.6157 - val_mae: 1.4971\n",
      "Epoch 1899/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5122 - mae: 1.3947 - val_loss: 2.6094 - val_mae: 1.4951\n",
      "Epoch 1900/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5108 - mae: 1.3942 - val_loss: 2.6062 - val_mae: 1.4940\n",
      "Epoch 1901/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5095 - mae: 1.3939 - val_loss: 2.6011 - val_mae: 1.4923\n",
      "Epoch 1902/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5081 - mae: 1.3934 - val_loss: 2.5952 - val_mae: 1.4904\n",
      "Epoch 1903/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5067 - mae: 1.3930 - val_loss: 2.5919 - val_mae: 1.4893\n",
      "Epoch 1904/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5054 - mae: 1.3927 - val_loss: 2.5864 - val_mae: 1.4875\n",
      "Epoch 1905/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5040 - mae: 1.3922 - val_loss: 2.5809 - val_mae: 1.4857\n",
      "Epoch 1906/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5026 - mae: 1.3918 - val_loss: 2.5774 - val_mae: 1.4845\n",
      "Epoch 1907/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5013 - mae: 1.3914 - val_loss: 2.5719 - val_mae: 1.4827\n",
      "Epoch 1908/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4999 - mae: 1.3910 - val_loss: 2.5669 - val_mae: 1.4811\n",
      "Epoch 1909/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4985 - mae: 1.3906 - val_loss: 2.5631 - val_mae: 1.4798\n",
      "Epoch 1910/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4972 - mae: 1.3902 - val_loss: 2.5576 - val_mae: 1.4780\n",
      "Epoch 1911/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4958 - mae: 1.3898 - val_loss: 2.5528 - val_mae: 1.4764\n",
      "Epoch 1912/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4945 - mae: 1.3894 - val_loss: 2.5487 - val_mae: 1.4750\n",
      "Epoch 1913/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.4931 - mae: 1.3890 - val_loss: 2.5434 - val_mae: 1.4732\n",
      "Epoch 1914/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4917 - mae: 1.3886 - val_loss: 2.5389 - val_mae: 1.4717\n",
      "Epoch 1915/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4904 - mae: 1.3882 - val_loss: 2.5346 - val_mae: 1.4702\n",
      "Epoch 1916/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4891 - mae: 1.3878 - val_loss: 2.5294 - val_mae: 1.4685\n",
      "Epoch 1917/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4877 - mae: 1.3874 - val_loss: 2.5248 - val_mae: 1.4670\n",
      "Epoch 1918/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.4864 - mae: 1.3870 - val_loss: 2.5205 - val_mae: 1.4655\n",
      "Epoch 1919/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4850 - mae: 1.3866 - val_loss: 2.5153 - val_mae: 1.4638\n",
      "Epoch 1920/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.4836 - mae: 1.3862 - val_loss: 2.5110 - val_mae: 1.4623\n",
      "Epoch 1921/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4823 - mae: 1.3858 - val_loss: 2.5065 - val_mae: 1.4608\n",
      "Epoch 1922/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.4810 - mae: 1.3854 - val_loss: 2.5015 - val_mae: 1.4591\n",
      "Epoch 1923/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4796 - mae: 1.3850 - val_loss: 2.4970 - val_mae: 1.4576\n",
      "Epoch 1924/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4783 - mae: 1.3846 - val_loss: 2.4926 - val_mae: 1.4560\n",
      "Epoch 1925/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4769 - mae: 1.3842 - val_loss: 2.4877 - val_mae: 1.4544\n",
      "Epoch 1926/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.4756 - mae: 1.3837 - val_loss: 2.4833 - val_mae: 1.4529\n",
      "Epoch 1927/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4742 - mae: 1.3833 - val_loss: 2.4788 - val_mae: 1.4513\n",
      "Epoch 1928/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.4729 - mae: 1.3829 - val_loss: 2.4739 - val_mae: 1.4497\n",
      "Epoch 1929/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4716 - mae: 1.3825 - val_loss: 2.4696 - val_mae: 1.4482\n",
      "Epoch 1930/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4703 - mae: 1.3821 - val_loss: 2.4651 - val_mae: 1.4466\n",
      "Epoch 1931/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4689 - mae: 1.3817 - val_loss: 2.4603 - val_mae: 1.4449\n",
      "Epoch 1932/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4676 - mae: 1.3813 - val_loss: 2.4560 - val_mae: 1.4435\n",
      "Epoch 1933/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4662 - mae: 1.3809 - val_loss: 2.4515 - val_mae: 1.4419\n",
      "Epoch 1934/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4649 - mae: 1.3805 - val_loss: 2.4467 - val_mae: 1.4403\n",
      "Epoch 1935/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4636 - mae: 1.3801 - val_loss: 2.4425 - val_mae: 1.4388\n",
      "Epoch 1936/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4623 - mae: 1.3797 - val_loss: 2.4379 - val_mae: 1.4372\n",
      "Epoch 1937/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4609 - mae: 1.3793 - val_loss: 2.4333 - val_mae: 1.4356\n",
      "Epoch 1938/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4596 - mae: 1.3789 - val_loss: 2.4290 - val_mae: 1.4341\n",
      "Epoch 1939/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4583 - mae: 1.3785 - val_loss: 2.4245 - val_mae: 1.4325\n",
      "Epoch 1940/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.4570 - mae: 1.3781 - val_loss: 2.4199 - val_mae: 1.4309\n",
      "Epoch 1941/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4557 - mae: 1.3777 - val_loss: 2.4156 - val_mae: 1.4294\n",
      "Epoch 1942/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4543 - mae: 1.3773 - val_loss: 2.4111 - val_mae: 1.4278\n",
      "Epoch 1943/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4530 - mae: 1.3769 - val_loss: 2.4066 - val_mae: 1.4262\n",
      "Epoch 1944/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4517 - mae: 1.3765 - val_loss: 2.4023 - val_mae: 1.4247\n",
      "Epoch 1945/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4504 - mae: 1.3761 - val_loss: 2.3979 - val_mae: 1.4231\n",
      "Epoch 1946/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4491 - mae: 1.3756 - val_loss: 2.3934 - val_mae: 1.4216\n",
      "Epoch 1947/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4478 - mae: 1.3752 - val_loss: 2.3891 - val_mae: 1.4200\n",
      "Epoch 1948/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4465 - mae: 1.3748 - val_loss: 2.3847 - val_mae: 1.4184\n",
      "Epoch 1949/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4451 - mae: 1.3744 - val_loss: 2.3803 - val_mae: 1.4169\n",
      "Epoch 1950/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4438 - mae: 1.3740 - val_loss: 2.3761 - val_mae: 1.4154\n",
      "Epoch 1951/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.4425 - mae: 1.3736 - val_loss: 2.3716 - val_mae: 1.4138\n",
      "Epoch 1952/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4412 - mae: 1.3732 - val_loss: 2.3673 - val_mae: 1.4122\n",
      "Epoch 1953/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4399 - mae: 1.3728 - val_loss: 2.3631 - val_mae: 1.4107\n",
      "Epoch 1954/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4386 - mae: 1.3724 - val_loss: 2.3586 - val_mae: 1.4091\n",
      "Epoch 1955/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4373 - mae: 1.3720 - val_loss: 2.3543 - val_mae: 1.4076\n",
      "Epoch 1956/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4360 - mae: 1.3716 - val_loss: 2.3501 - val_mae: 1.4061\n",
      "Epoch 1957/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4347 - mae: 1.3712 - val_loss: 2.3457 - val_mae: 1.4045\n",
      "Epoch 1958/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4334 - mae: 1.3708 - val_loss: 2.3415 - val_mae: 1.4030\n",
      "Epoch 1959/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4321 - mae: 1.3704 - val_loss: 2.3373 - val_mae: 1.4014\n",
      "Epoch 1960/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4308 - mae: 1.3700 - val_loss: 2.3329 - val_mae: 1.3998\n",
      "Epoch 1961/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4295 - mae: 1.3695 - val_loss: 2.3288 - val_mae: 1.3984\n",
      "Epoch 1962/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.4282 - mae: 1.3692 - val_loss: 2.3245 - val_mae: 1.3968\n",
      "Epoch 1963/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4269 - mae: 1.3687 - val_loss: 2.3202 - val_mae: 1.3952\n",
      "Epoch 1964/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4257 - mae: 1.3683 - val_loss: 2.3162 - val_mae: 1.3938\n",
      "Epoch 1965/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4244 - mae: 1.3679 - val_loss: 2.3118 - val_mae: 1.3922\n",
      "Epoch 1966/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4231 - mae: 1.3675 - val_loss: 2.3075 - val_mae: 1.3906\n",
      "Epoch 1967/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4218 - mae: 1.3671 - val_loss: 2.3035 - val_mae: 1.3891\n",
      "Epoch 1968/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4205 - mae: 1.3667 - val_loss: 2.2992 - val_mae: 1.3875\n",
      "Epoch 1969/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4192 - mae: 1.3663 - val_loss: 2.2951 - val_mae: 1.3860\n",
      "Epoch 1970/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4179 - mae: 1.3659 - val_loss: 2.2909 - val_mae: 1.3845\n",
      "Epoch 1971/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4166 - mae: 1.3655 - val_loss: 2.2867 - val_mae: 1.3829\n",
      "Epoch 1972/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.4154 - mae: 1.3651 - val_loss: 2.2828 - val_mae: 1.3814\n",
      "Epoch 1973/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4141 - mae: 1.3647 - val_loss: 2.2785 - val_mae: 1.3799\n",
      "Epoch 1974/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4128 - mae: 1.3643 - val_loss: 2.2743 - val_mae: 1.3783\n",
      "Epoch 1975/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4115 - mae: 1.3638 - val_loss: 2.2705 - val_mae: 1.3769\n",
      "Epoch 1976/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4102 - mae: 1.3635 - val_loss: 2.2661 - val_mae: 1.3752\n",
      "Epoch 1977/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4090 - mae: 1.3630 - val_loss: 2.2622 - val_mae: 1.3738\n",
      "Epoch 1978/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4077 - mae: 1.3626 - val_loss: 2.2581 - val_mae: 1.3723\n",
      "Epoch 1979/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4064 - mae: 1.3622 - val_loss: 2.2539 - val_mae: 1.3707\n",
      "Epoch 1980/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4052 - mae: 1.3618 - val_loss: 2.2500 - val_mae: 1.3692\n",
      "Epoch 1981/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4039 - mae: 1.3614 - val_loss: 2.2458 - val_mae: 1.3676\n",
      "Epoch 1982/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4026 - mae: 1.3610 - val_loss: 2.2418 - val_mae: 1.3661\n",
      "Epoch 1983/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4014 - mae: 1.3606 - val_loss: 2.2379 - val_mae: 1.3646\n",
      "Epoch 1984/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.4001 - mae: 1.3602 - val_loss: 2.2339 - val_mae: 1.3631\n",
      "Epoch 1985/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3988 - mae: 1.3598 - val_loss: 2.2298 - val_mae: 1.3616\n",
      "Epoch 1986/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3975 - mae: 1.3594 - val_loss: 2.2259 - val_mae: 1.3601\n",
      "Epoch 1987/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3963 - mae: 1.3590 - val_loss: 2.2219 - val_mae: 1.3586\n",
      "Epoch 1988/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3951 - mae: 1.3586 - val_loss: 2.2179 - val_mae: 1.3570\n",
      "Epoch 1989/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3938 - mae: 1.3581 - val_loss: 2.2140 - val_mae: 1.3555\n",
      "Epoch 1990/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3925 - mae: 1.3577 - val_loss: 2.2100 - val_mae: 1.3540\n",
      "Epoch 1991/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3912 - mae: 1.3573 - val_loss: 2.2061 - val_mae: 1.3525\n",
      "Epoch 1992/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3900 - mae: 1.3569 - val_loss: 2.2022 - val_mae: 1.3510\n",
      "Epoch 1993/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3887 - mae: 1.3565 - val_loss: 2.1982 - val_mae: 1.3495\n",
      "Epoch 1994/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3875 - mae: 1.3561 - val_loss: 2.1943 - val_mae: 1.3480\n",
      "Epoch 1995/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.3862 - mae: 1.3557 - val_loss: 2.1905 - val_mae: 1.3465\n",
      "Epoch 1996/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3850 - mae: 1.3553 - val_loss: 2.1865 - val_mae: 1.3450\n",
      "Epoch 1997/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3837 - mae: 1.3549 - val_loss: 2.1827 - val_mae: 1.3435\n",
      "Epoch 1998/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3825 - mae: 1.3545 - val_loss: 2.1788 - val_mae: 1.3420\n",
      "Epoch 1999/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3812 - mae: 1.3541 - val_loss: 2.1749 - val_mae: 1.3404\n",
      "Epoch 2000/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3800 - mae: 1.3536 - val_loss: 2.1712 - val_mae: 1.3390\n",
      "Epoch 2001/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3787 - mae: 1.3532 - val_loss: 2.1673 - val_mae: 1.3375\n",
      "Epoch 2002/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3775 - mae: 1.3528 - val_loss: 2.1635 - val_mae: 1.3360\n",
      "Epoch 2003/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3762 - mae: 1.3524 - val_loss: 2.1596 - val_mae: 1.3345\n",
      "Epoch 2004/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3750 - mae: 1.3520 - val_loss: 2.1559 - val_mae: 1.3330\n",
      "Epoch 2005/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3738 - mae: 1.3516 - val_loss: 2.1521 - val_mae: 1.3315\n",
      "Epoch 2006/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3725 - mae: 1.3512 - val_loss: 2.1483 - val_mae: 1.3300\n",
      "Epoch 2007/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3713 - mae: 1.3508 - val_loss: 2.1445 - val_mae: 1.3285\n",
      "Epoch 2008/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3700 - mae: 1.3504 - val_loss: 2.1408 - val_mae: 1.3270\n",
      "Epoch 2009/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3688 - mae: 1.3500 - val_loss: 2.1370 - val_mae: 1.3255\n",
      "Epoch 2010/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3676 - mae: 1.3496 - val_loss: 2.1333 - val_mae: 1.3241\n",
      "Epoch 2011/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.3663 - mae: 1.3492 - val_loss: 2.1296 - val_mae: 1.3226\n",
      "Epoch 2012/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3651 - mae: 1.3488 - val_loss: 2.1258 - val_mae: 1.3211\n",
      "Epoch 2013/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3638 - mae: 1.3483 - val_loss: 2.1221 - val_mae: 1.3196\n",
      "Epoch 2014/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3626 - mae: 1.3479 - val_loss: 2.1185 - val_mae: 1.3182\n",
      "Epoch 2015/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3614 - mae: 1.3475 - val_loss: 2.1147 - val_mae: 1.3167\n",
      "Epoch 2016/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3602 - mae: 1.3471 - val_loss: 2.1111 - val_mae: 1.3152\n",
      "Epoch 2017/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3589 - mae: 1.3467 - val_loss: 2.1075 - val_mae: 1.3137\n",
      "Epoch 2018/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3577 - mae: 1.3463 - val_loss: 2.1037 - val_mae: 1.3122\n",
      "Epoch 2019/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3565 - mae: 1.3459 - val_loss: 2.1002 - val_mae: 1.3108\n",
      "Epoch 2020/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3552 - mae: 1.3455 - val_loss: 2.0965 - val_mae: 1.3093\n",
      "Epoch 2021/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3540 - mae: 1.3451 - val_loss: 2.0928 - val_mae: 1.3078\n",
      "Epoch 2022/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3528 - mae: 1.3446 - val_loss: 2.0894 - val_mae: 1.3064\n",
      "Epoch 2023/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3516 - mae: 1.3443 - val_loss: 2.0857 - val_mae: 1.3049\n",
      "Epoch 2024/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3503 - mae: 1.3438 - val_loss: 2.0820 - val_mae: 1.3034\n",
      "Epoch 2025/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3491 - mae: 1.3434 - val_loss: 2.0786 - val_mae: 1.3020\n",
      "Epoch 2026/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3479 - mae: 1.3430 - val_loss: 2.0750 - val_mae: 1.3006\n",
      "Epoch 2027/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3467 - mae: 1.3426 - val_loss: 2.0713 - val_mae: 1.2991\n",
      "Epoch 2028/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3455 - mae: 1.3422 - val_loss: 2.0680 - val_mae: 1.2977\n",
      "Epoch 2029/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3443 - mae: 1.3418 - val_loss: 2.0643 - val_mae: 1.2962\n",
      "Epoch 2030/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3430 - mae: 1.3414 - val_loss: 2.0608 - val_mae: 1.2947\n",
      "Epoch 2031/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3418 - mae: 1.3410 - val_loss: 2.0574 - val_mae: 1.2933\n",
      "Epoch 2032/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3406 - mae: 1.3406 - val_loss: 2.0537 - val_mae: 1.2918\n",
      "Epoch 2033/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3394 - mae: 1.3401 - val_loss: 2.0503 - val_mae: 1.2904\n",
      "Epoch 2034/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3382 - mae: 1.3397 - val_loss: 2.0469 - val_mae: 1.2890\n",
      "Epoch 2035/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3370 - mae: 1.3393 - val_loss: 2.0433 - val_mae: 1.2875\n",
      "Epoch 2036/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3358 - mae: 1.3389 - val_loss: 2.0400 - val_mae: 1.2861\n",
      "Epoch 2037/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3345 - mae: 1.3385 - val_loss: 2.0365 - val_mae: 1.2847\n",
      "Epoch 2038/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3334 - mae: 1.3381 - val_loss: 2.0330 - val_mae: 1.2832\n",
      "Epoch 2039/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3321 - mae: 1.3377 - val_loss: 2.0297 - val_mae: 1.2818\n",
      "Epoch 2040/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3309 - mae: 1.3373 - val_loss: 2.0262 - val_mae: 1.2803\n",
      "Epoch 2041/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3297 - mae: 1.3369 - val_loss: 2.0228 - val_mae: 1.2789\n",
      "Epoch 2042/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3285 - mae: 1.3365 - val_loss: 2.0195 - val_mae: 1.2775\n",
      "Epoch 2043/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3273 - mae: 1.3361 - val_loss: 2.0160 - val_mae: 1.2760\n",
      "Epoch 2044/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3261 - mae: 1.3356 - val_loss: 2.0127 - val_mae: 1.2747\n",
      "Epoch 2045/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3249 - mae: 1.3352 - val_loss: 2.0094 - val_mae: 1.2733\n",
      "Epoch 2046/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3237 - mae: 1.3348 - val_loss: 2.0060 - val_mae: 1.2718\n",
      "Epoch 2047/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3225 - mae: 1.3344 - val_loss: 2.0028 - val_mae: 1.2705\n",
      "Epoch 2048/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3213 - mae: 1.3340 - val_loss: 1.9994 - val_mae: 1.2691\n",
      "Epoch 2049/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3201 - mae: 1.3336 - val_loss: 1.9961 - val_mae: 1.2676\n",
      "Epoch 2050/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3189 - mae: 1.3332 - val_loss: 1.9929 - val_mae: 1.2663\n",
      "Epoch 2051/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3178 - mae: 1.3328 - val_loss: 1.9895 - val_mae: 1.2649\n",
      "Epoch 2052/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.3165 - mae: 1.3324 - val_loss: 1.9863 - val_mae: 1.2635\n",
      "Epoch 2053/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3154 - mae: 1.3320 - val_loss: 1.9831 - val_mae: 1.2621\n",
      "Epoch 2054/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3142 - mae: 1.3315 - val_loss: 1.9797 - val_mae: 1.2607\n",
      "Epoch 2055/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3130 - mae: 1.3311 - val_loss: 1.9766 - val_mae: 1.2594\n",
      "Epoch 2056/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3118 - mae: 1.3308 - val_loss: 1.9733 - val_mae: 1.2580\n",
      "Epoch 2057/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3106 - mae: 1.3305 - val_loss: 1.9701 - val_mae: 1.2566\n",
      "Epoch 2058/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3094 - mae: 1.3302 - val_loss: 1.9669 - val_mae: 1.2552\n",
      "Epoch 2059/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3082 - mae: 1.3298 - val_loss: 1.9638 - val_mae: 1.2539\n",
      "Epoch 2060/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3070 - mae: 1.3295 - val_loss: 1.9605 - val_mae: 1.2525\n",
      "Epoch 2061/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3058 - mae: 1.3292 - val_loss: 1.9574 - val_mae: 1.2511\n",
      "Epoch 2062/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3047 - mae: 1.3289 - val_loss: 1.9542 - val_mae: 1.2498\n",
      "Epoch 2063/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.3035 - mae: 1.3286 - val_loss: 1.9510 - val_mae: 1.2484\n",
      "Epoch 2064/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3023 - mae: 1.3283 - val_loss: 1.9479 - val_mae: 1.2470\n",
      "Epoch 2065/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3011 - mae: 1.3279 - val_loss: 1.9448 - val_mae: 1.2457\n",
      "Epoch 2066/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2999 - mae: 1.3276 - val_loss: 1.9416 - val_mae: 1.2443\n",
      "Epoch 2067/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2987 - mae: 1.3273 - val_loss: 1.9386 - val_mae: 1.2430\n",
      "Epoch 2068/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2976 - mae: 1.3270 - val_loss: 1.9355 - val_mae: 1.2416\n",
      "Epoch 2069/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2964 - mae: 1.3267 - val_loss: 1.9324 - val_mae: 1.2403\n",
      "Epoch 2070/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2952 - mae: 1.3264 - val_loss: 1.9294 - val_mae: 1.2390\n",
      "Epoch 2071/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2940 - mae: 1.3260 - val_loss: 1.9262 - val_mae: 1.2376\n",
      "Epoch 2072/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2929 - mae: 1.3257 - val_loss: 1.9232 - val_mae: 1.2363\n",
      "Epoch 2073/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2917 - mae: 1.3254 - val_loss: 1.9201 - val_mae: 1.2349\n",
      "Epoch 2074/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2905 - mae: 1.3251 - val_loss: 1.9171 - val_mae: 1.2336\n",
      "Epoch 2075/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2894 - mae: 1.3248 - val_loss: 1.9141 - val_mae: 1.2323\n",
      "Epoch 2076/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2882 - mae: 1.3244 - val_loss: 1.9111 - val_mae: 1.2309\n",
      "Epoch 2077/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2870 - mae: 1.3241 - val_loss: 1.9082 - val_mae: 1.2296\n",
      "Epoch 2078/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2858 - mae: 1.3238 - val_loss: 1.9051 - val_mae: 1.2283\n",
      "Epoch 2079/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2846 - mae: 1.3235 - val_loss: 1.9021 - val_mae: 1.2270\n",
      "Epoch 2080/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2835 - mae: 1.3232 - val_loss: 1.8993 - val_mae: 1.2257\n",
      "Epoch 2081/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2823 - mae: 1.3229 - val_loss: 1.8962 - val_mae: 1.2243\n",
      "Epoch 2082/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2812 - mae: 1.3226 - val_loss: 1.8933 - val_mae: 1.2230\n",
      "Epoch 2083/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2800 - mae: 1.3223 - val_loss: 1.8900 - val_mae: 1.2215\n",
      "Epoch 2084/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2789 - mae: 1.3220 - val_loss: 1.8867 - val_mae: 1.2200\n",
      "Epoch 2085/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2777 - mae: 1.3216 - val_loss: 1.8835 - val_mae: 1.2186\n",
      "Epoch 2086/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2765 - mae: 1.3213 - val_loss: 1.8798 - val_mae: 1.2169\n",
      "Epoch 2087/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2754 - mae: 1.3210 - val_loss: 1.8769 - val_mae: 1.2155\n",
      "Epoch 2088/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2742 - mae: 1.3207 - val_loss: 1.8735 - val_mae: 1.2140\n",
      "Epoch 2089/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2731 - mae: 1.3204 - val_loss: 1.8703 - val_mae: 1.2125\n",
      "Epoch 2090/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.2719 - mae: 1.3201 - val_loss: 1.8675 - val_mae: 1.2112\n",
      "Epoch 2091/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2707 - mae: 1.3198 - val_loss: 1.8641 - val_mae: 1.2097\n",
      "Epoch 2092/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2696 - mae: 1.3195 - val_loss: 1.8611 - val_mae: 1.2083\n",
      "Epoch 2093/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2684 - mae: 1.3192 - val_loss: 1.8582 - val_mae: 1.2070\n",
      "Epoch 2094/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2672 - mae: 1.3189 - val_loss: 1.8549 - val_mae: 1.2055\n",
      "Epoch 2095/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2661 - mae: 1.3186 - val_loss: 1.8523 - val_mae: 1.2042\n",
      "Epoch 2096/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2649 - mae: 1.3183 - val_loss: 1.8492 - val_mae: 1.2028\n",
      "Epoch 2097/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2638 - mae: 1.3180 - val_loss: 1.8462 - val_mae: 1.2014\n",
      "Epoch 2098/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2626 - mae: 1.3176 - val_loss: 1.8436 - val_mae: 1.2002\n",
      "Epoch 2099/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2615 - mae: 1.3174 - val_loss: 1.8400 - val_mae: 1.1985\n",
      "Epoch 2100/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2603 - mae: 1.3170 - val_loss: 1.8371 - val_mae: 1.1972\n",
      "Epoch 2101/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2592 - mae: 1.3167 - val_loss: 1.8342 - val_mae: 1.1958\n",
      "Epoch 2102/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2580 - mae: 1.3164 - val_loss: 1.8309 - val_mae: 1.1942\n",
      "Epoch 2103/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2569 - mae: 1.3161 - val_loss: 1.8283 - val_mae: 1.1930\n",
      "Epoch 2104/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2558 - mae: 1.3158 - val_loss: 1.8252 - val_mae: 1.1916\n",
      "Epoch 2105/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2546 - mae: 1.3155 - val_loss: 1.8223 - val_mae: 1.1902\n",
      "Epoch 2106/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2535 - mae: 1.3152 - val_loss: 1.8192 - val_mae: 1.1887\n",
      "Epoch 2107/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2523 - mae: 1.3149 - val_loss: 1.8164 - val_mae: 1.1874\n",
      "Epoch 2108/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2512 - mae: 1.3146 - val_loss: 1.8135 - val_mae: 1.1860\n",
      "Epoch 2109/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2500 - mae: 1.3143 - val_loss: 1.8105 - val_mae: 1.1846\n",
      "Epoch 2110/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2489 - mae: 1.3140 - val_loss: 1.8074 - val_mae: 1.1831\n",
      "Epoch 2111/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2478 - mae: 1.3137 - val_loss: 1.8047 - val_mae: 1.1818\n",
      "Epoch 2112/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2466 - mae: 1.3134 - val_loss: 1.8017 - val_mae: 1.1804\n",
      "Epoch 2113/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2455 - mae: 1.3130 - val_loss: 1.7989 - val_mae: 1.1791\n",
      "Epoch 2114/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2443 - mae: 1.3127 - val_loss: 1.7962 - val_mae: 1.1777\n",
      "Epoch 2115/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2432 - mae: 1.3124 - val_loss: 1.7928 - val_mae: 1.1761\n",
      "Epoch 2116/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2421 - mae: 1.3121 - val_loss: 1.7905 - val_mae: 1.1750\n",
      "Epoch 2117/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2409 - mae: 1.3118 - val_loss: 1.7874 - val_mae: 1.1735\n",
      "Epoch 2118/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2398 - mae: 1.3115 - val_loss: 1.7847 - val_mae: 1.1722\n",
      "Epoch 2119/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2387 - mae: 1.3112 - val_loss: 1.7817 - val_mae: 1.1707\n",
      "Epoch 2120/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2375 - mae: 1.3109 - val_loss: 1.7789 - val_mae: 1.1694\n",
      "Epoch 2121/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2364 - mae: 1.3106 - val_loss: 1.7762 - val_mae: 1.1680\n",
      "Epoch 2122/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2352 - mae: 1.3103 - val_loss: 1.7733 - val_mae: 1.1667\n",
      "Epoch 2123/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2342 - mae: 1.3100 - val_loss: 1.7707 - val_mae: 1.1654\n",
      "Epoch 2124/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2330 - mae: 1.3097 - val_loss: 1.7676 - val_mae: 1.1639\n",
      "Epoch 2125/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2319 - mae: 1.3094 - val_loss: 1.7646 - val_mae: 1.1624\n",
      "Epoch 2126/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2307 - mae: 1.3090 - val_loss: 1.7622 - val_mae: 1.1612\n",
      "Epoch 2127/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2296 - mae: 1.3088 - val_loss: 1.7590 - val_mae: 1.1596\n",
      "Epoch 2128/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2285 - mae: 1.3084 - val_loss: 1.7566 - val_mae: 1.1584\n",
      "Epoch 2129/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2274 - mae: 1.3081 - val_loss: 1.7538 - val_mae: 1.1570\n",
      "Epoch 2130/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2262 - mae: 1.3078 - val_loss: 1.7510 - val_mae: 1.1556\n",
      "Epoch 2131/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2251 - mae: 1.3075 - val_loss: 1.7487 - val_mae: 1.1545\n",
      "Epoch 2132/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2240 - mae: 1.3072 - val_loss: 1.7458 - val_mae: 1.1531\n",
      "Epoch 2133/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2229 - mae: 1.3069 - val_loss: 1.7434 - val_mae: 1.1519\n",
      "Epoch 2134/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2218 - mae: 1.3066 - val_loss: 1.7404 - val_mae: 1.1504\n",
      "Epoch 2135/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2206 - mae: 1.3063 - val_loss: 1.7377 - val_mae: 1.1490\n",
      "Epoch 2136/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2195 - mae: 1.3060 - val_loss: 1.7348 - val_mae: 1.1475\n",
      "Epoch 2137/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2184 - mae: 1.3057 - val_loss: 1.7322 - val_mae: 1.1462\n",
      "Epoch 2138/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2173 - mae: 1.3054 - val_loss: 1.7294 - val_mae: 1.1448\n",
      "Epoch 2139/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2162 - mae: 1.3051 - val_loss: 1.7268 - val_mae: 1.1435\n",
      "Epoch 2140/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.2150 - mae: 1.3047 - val_loss: 1.7243 - val_mae: 1.1422\n",
      "Epoch 2141/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2139 - mae: 1.3044 - val_loss: 1.7215 - val_mae: 1.1408\n",
      "Epoch 2142/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.2128 - mae: 1.3041 - val_loss: 1.7192 - val_mae: 1.1396\n",
      "Epoch 2143/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2117 - mae: 1.3038 - val_loss: 1.7165 - val_mae: 1.1383\n",
      "Epoch 2144/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2105 - mae: 1.3035 - val_loss: 1.7142 - val_mae: 1.1371\n",
      "Epoch 2145/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2094 - mae: 1.3032 - val_loss: 1.7117 - val_mae: 1.1358\n",
      "Epoch 2146/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.2083 - mae: 1.3029 - val_loss: 1.7089 - val_mae: 1.1344\n",
      "Epoch 2147/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.2072 - mae: 1.3026 - val_loss: 1.7064 - val_mae: 1.1331\n",
      "Epoch 2148/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.2061 - mae: 1.3023 - val_loss: 1.7035 - val_mae: 1.1315\n",
      "Epoch 2149/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.2050 - mae: 1.3020 - val_loss: 1.7010 - val_mae: 1.1303\n",
      "Epoch 2150/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.2039 - mae: 1.3017 - val_loss: 1.6984 - val_mae: 1.1289\n",
      "Epoch 2151/3000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.2028 - mae: 1.3013 - val_loss: 1.6959 - val_mae: 1.1276\n",
      "Epoch 2152/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2016 - mae: 1.3010 - val_loss: 1.6935 - val_mae: 1.1264\n",
      "Epoch 2153/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2005 - mae: 1.3007 - val_loss: 1.6909 - val_mae: 1.1251\n",
      "Epoch 2154/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1994 - mae: 1.3004 - val_loss: 1.6887 - val_mae: 1.1239\n",
      "Epoch 2155/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1983 - mae: 1.3001 - val_loss: 1.6862 - val_mae: 1.1226\n",
      "Epoch 2156/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.1972 - mae: 1.2998 - val_loss: 1.6840 - val_mae: 1.1215\n",
      "Epoch 2157/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.1961 - mae: 1.2995 - val_loss: 1.6812 - val_mae: 1.1200\n",
      "Epoch 2158/3000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.1950 - mae: 1.2992 - val_loss: 1.6788 - val_mae: 1.1187\n",
      "Epoch 2159/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1939 - mae: 1.2989 - val_loss: 1.6760 - val_mae: 1.1172\n",
      "Epoch 2160/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.1928 - mae: 1.2986 - val_loss: 1.6736 - val_mae: 1.1159\n",
      "Epoch 2161/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1917 - mae: 1.2983 - val_loss: 1.6712 - val_mae: 1.1147\n",
      "Epoch 2162/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1905 - mae: 1.2979 - val_loss: 1.6686 - val_mae: 1.1133\n",
      "Epoch 2163/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1895 - mae: 1.2976 - val_loss: 1.6664 - val_mae: 1.1122\n",
      "Epoch 2164/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1884 - mae: 1.2973 - val_loss: 1.6640 - val_mae: 1.1109\n",
      "Epoch 2165/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1873 - mae: 1.2970 - val_loss: 1.6618 - val_mae: 1.1097\n",
      "Epoch 2166/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1861 - mae: 1.2967 - val_loss: 1.6595 - val_mae: 1.1085\n",
      "Epoch 2167/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1851 - mae: 1.2964 - val_loss: 1.6568 - val_mae: 1.1070\n",
      "Epoch 2168/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.1839 - mae: 1.2961 - val_loss: 1.6546 - val_mae: 1.1058\n",
      "Epoch 2169/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1828 - mae: 1.2958 - val_loss: 1.6522 - val_mae: 1.1046\n",
      "Epoch 2170/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1817 - mae: 1.2955 - val_loss: 1.6497 - val_mae: 1.1037\n",
      "Epoch 2171/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.1806 - mae: 1.2951 - val_loss: 1.6478 - val_mae: 1.1030\n",
      "Epoch 2172/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1795 - mae: 1.2949 - val_loss: 1.6447 - val_mae: 1.1019\n",
      "Epoch 2173/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.1784 - mae: 1.2945 - val_loss: 1.6431 - val_mae: 1.1014\n",
      "Epoch 2174/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1774 - mae: 1.2942 - val_loss: 1.6404 - val_mae: 1.1004\n",
      "Epoch 2175/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1762 - mae: 1.2939 - val_loss: 1.6383 - val_mae: 1.0997\n",
      "Epoch 2176/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1751 - mae: 1.2936 - val_loss: 1.6359 - val_mae: 1.0988\n",
      "Epoch 2177/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1740 - mae: 1.2933 - val_loss: 1.6332 - val_mae: 1.0979\n",
      "Epoch 2178/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1730 - mae: 1.2930 - val_loss: 1.6314 - val_mae: 1.0973\n",
      "Epoch 2179/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1719 - mae: 1.2927 - val_loss: 1.6285 - val_mae: 1.0962\n",
      "Epoch 2180/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1708 - mae: 1.2923 - val_loss: 1.6268 - val_mae: 1.0956\n",
      "Epoch 2181/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1697 - mae: 1.2921 - val_loss: 1.6244 - val_mae: 1.0948\n",
      "Epoch 2182/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1685 - mae: 1.2917 - val_loss: 1.6222 - val_mae: 1.0940\n",
      "Epoch 2183/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1675 - mae: 1.2914 - val_loss: 1.6200 - val_mae: 1.0932\n",
      "Epoch 2184/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1664 - mae: 1.2911 - val_loss: 1.6173 - val_mae: 1.0922\n",
      "Epoch 2185/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1653 - mae: 1.2908 - val_loss: 1.6157 - val_mae: 1.0917\n",
      "Epoch 2186/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1642 - mae: 1.2905 - val_loss: 1.6129 - val_mae: 1.0906\n",
      "Epoch 2187/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1631 - mae: 1.2902 - val_loss: 1.6112 - val_mae: 1.0900\n",
      "Epoch 2188/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1620 - mae: 1.2899 - val_loss: 1.6089 - val_mae: 1.0892\n",
      "Epoch 2189/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1609 - mae: 1.2896 - val_loss: 1.6063 - val_mae: 1.0883\n",
      "Epoch 2190/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1598 - mae: 1.2892 - val_loss: 1.6045 - val_mae: 1.0876\n",
      "Epoch 2191/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1587 - mae: 1.2889 - val_loss: 1.6019 - val_mae: 1.0867\n",
      "Epoch 2192/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1576 - mae: 1.2886 - val_loss: 1.6001 - val_mae: 1.0860\n",
      "Epoch 2193/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1566 - mae: 1.2883 - val_loss: 1.5978 - val_mae: 1.0852\n",
      "Epoch 2194/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1555 - mae: 1.2880 - val_loss: 1.5958 - val_mae: 1.0844\n",
      "Epoch 2195/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1544 - mae: 1.2877 - val_loss: 1.5940 - val_mae: 1.0838\n",
      "Epoch 2196/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1533 - mae: 1.2874 - val_loss: 1.5912 - val_mae: 1.0828\n",
      "Epoch 2197/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1522 - mae: 1.2870 - val_loss: 1.5895 - val_mae: 1.0821\n",
      "Epoch 2198/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1511 - mae: 1.2868 - val_loss: 1.5867 - val_mae: 1.0811\n",
      "Epoch 2199/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1501 - mae: 1.2864 - val_loss: 1.5850 - val_mae: 1.0805\n",
      "Epoch 2200/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1489 - mae: 1.2861 - val_loss: 1.5828 - val_mae: 1.0796\n",
      "Epoch 2201/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1479 - mae: 1.2858 - val_loss: 1.5806 - val_mae: 1.0788\n",
      "Epoch 2202/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1468 - mae: 1.2855 - val_loss: 1.5789 - val_mae: 1.0782\n",
      "Epoch 2203/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.1457 - mae: 1.2852 - val_loss: 1.5764 - val_mae: 1.0773\n",
      "Epoch 2204/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1446 - mae: 1.2849 - val_loss: 1.5750 - val_mae: 1.0768\n",
      "Epoch 2205/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1435 - mae: 1.2846 - val_loss: 1.5722 - val_mae: 1.0757\n",
      "Epoch 2206/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1424 - mae: 1.2842 - val_loss: 1.5706 - val_mae: 1.0751\n",
      "Epoch 2207/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1414 - mae: 1.2840 - val_loss: 1.5680 - val_mae: 1.0741\n",
      "Epoch 2208/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1403 - mae: 1.2836 - val_loss: 1.5662 - val_mae: 1.0735\n",
      "Epoch 2209/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1392 - mae: 1.2833 - val_loss: 1.5641 - val_mae: 1.0727\n",
      "Epoch 2210/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1381 - mae: 1.2830 - val_loss: 1.5621 - val_mae: 1.0719\n",
      "Epoch 2211/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1371 - mae: 1.2827 - val_loss: 1.5604 - val_mae: 1.0713\n",
      "Epoch 2212/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1360 - mae: 1.2824 - val_loss: 1.5582 - val_mae: 1.0704\n",
      "Epoch 2213/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1349 - mae: 1.2821 - val_loss: 1.5566 - val_mae: 1.0698\n",
      "Epoch 2214/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1338 - mae: 1.2818 - val_loss: 1.5542 - val_mae: 1.0689\n",
      "Epoch 2215/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1327 - mae: 1.2814 - val_loss: 1.5523 - val_mae: 1.0682\n",
      "Epoch 2216/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1316 - mae: 1.2811 - val_loss: 1.5501 - val_mae: 1.0673\n",
      "Epoch 2217/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1305 - mae: 1.2808 - val_loss: 1.5483 - val_mae: 1.0667\n",
      "Epoch 2218/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1295 - mae: 1.2805 - val_loss: 1.5462 - val_mae: 1.0658\n",
      "Epoch 2219/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1284 - mae: 1.2802 - val_loss: 1.5444 - val_mae: 1.0652\n",
      "Epoch 2220/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1273 - mae: 1.2799 - val_loss: 1.5425 - val_mae: 1.0644\n",
      "Epoch 2221/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1262 - mae: 1.2796 - val_loss: 1.5402 - val_mae: 1.0636\n",
      "Epoch 2222/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1252 - mae: 1.2793 - val_loss: 1.5384 - val_mae: 1.0629\n",
      "Epoch 2223/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1241 - mae: 1.2790 - val_loss: 1.5364 - val_mae: 1.0621\n",
      "Epoch 2224/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1230 - mae: 1.2786 - val_loss: 1.5346 - val_mae: 1.0614\n",
      "Epoch 2225/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.1219 - mae: 1.2783 - val_loss: 1.5329 - val_mae: 1.0607\n",
      "Epoch 2226/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1209 - mae: 1.2780 - val_loss: 1.5309 - val_mae: 1.0600\n",
      "Epoch 2227/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1198 - mae: 1.2777 - val_loss: 1.5290 - val_mae: 1.0592\n",
      "Epoch 2228/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1187 - mae: 1.2774 - val_loss: 1.5270 - val_mae: 1.0584\n",
      "Epoch 2229/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1176 - mae: 1.2771 - val_loss: 1.5247 - val_mae: 1.0575\n",
      "Epoch 2230/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1166 - mae: 1.2768 - val_loss: 1.5232 - val_mae: 1.0569\n",
      "Epoch 2231/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1155 - mae: 1.2765 - val_loss: 1.5209 - val_mae: 1.0560\n",
      "Epoch 2232/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1144 - mae: 1.2761 - val_loss: 1.5196 - val_mae: 1.0555\n",
      "Epoch 2233/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1134 - mae: 1.2758 - val_loss: 1.5175 - val_mae: 1.0547\n",
      "Epoch 2234/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1123 - mae: 1.2755 - val_loss: 1.5159 - val_mae: 1.0540\n",
      "Epoch 2235/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1112 - mae: 1.2752 - val_loss: 1.5143 - val_mae: 1.0534\n",
      "Epoch 2236/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1101 - mae: 1.2749 - val_loss: 1.5120 - val_mae: 1.0525\n",
      "Epoch 2237/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1091 - mae: 1.2745 - val_loss: 1.5106 - val_mae: 1.0519\n",
      "Epoch 2238/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1080 - mae: 1.2743 - val_loss: 1.5081 - val_mae: 1.0509\n",
      "Epoch 2239/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1069 - mae: 1.2739 - val_loss: 1.5066 - val_mae: 1.0503\n",
      "Epoch 2240/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1059 - mae: 1.2736 - val_loss: 1.5045 - val_mae: 1.0495\n",
      "Epoch 2241/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1048 - mae: 1.2733 - val_loss: 1.5027 - val_mae: 1.0487\n",
      "Epoch 2242/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1037 - mae: 1.2730 - val_loss: 1.5012 - val_mae: 1.0481\n",
      "Epoch 2243/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1026 - mae: 1.2727 - val_loss: 1.4992 - val_mae: 1.0473\n",
      "Epoch 2244/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1016 - mae: 1.2723 - val_loss: 1.4979 - val_mae: 1.0468\n",
      "Epoch 2245/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1005 - mae: 1.2721 - val_loss: 1.4959 - val_mae: 1.0460\n",
      "Epoch 2246/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0994 - mae: 1.2717 - val_loss: 1.4942 - val_mae: 1.0453\n",
      "Epoch 2247/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0984 - mae: 1.2714 - val_loss: 1.4925 - val_mae: 1.0450\n",
      "Epoch 2248/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0973 - mae: 1.2711 - val_loss: 1.4903 - val_mae: 1.0447\n",
      "Epoch 2249/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0962 - mae: 1.2708 - val_loss: 1.4886 - val_mae: 1.0444\n",
      "Epoch 2250/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0952 - mae: 1.2705 - val_loss: 1.4868 - val_mae: 1.0441\n",
      "Epoch 2251/3000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.0941 - mae: 1.2702 - val_loss: 1.4850 - val_mae: 1.0438\n",
      "Epoch 2252/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.0930 - mae: 1.2698 - val_loss: 1.4835 - val_mae: 1.0436\n",
      "Epoch 2253/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0920 - mae: 1.2695 - val_loss: 1.4817 - val_mae: 1.0433\n",
      "Epoch 2254/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0909 - mae: 1.2692 - val_loss: 1.4804 - val_mae: 1.0430\n",
      "Epoch 2255/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0899 - mae: 1.2689 - val_loss: 1.4786 - val_mae: 1.0427\n",
      "Epoch 2256/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0888 - mae: 1.2686 - val_loss: 1.4768 - val_mae: 1.0424\n",
      "Epoch 2257/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0877 - mae: 1.2683 - val_loss: 1.4752 - val_mae: 1.0422\n",
      "Epoch 2258/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0866 - mae: 1.2680 - val_loss: 1.4731 - val_mae: 1.0418\n",
      "Epoch 2259/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0856 - mae: 1.2676 - val_loss: 1.4715 - val_mae: 1.0416\n",
      "Epoch 2260/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0845 - mae: 1.2673 - val_loss: 1.4697 - val_mae: 1.0412\n",
      "Epoch 2261/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.0835 - mae: 1.2670 - val_loss: 1.4681 - val_mae: 1.0410\n",
      "Epoch 2262/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0824 - mae: 1.2667 - val_loss: 1.4665 - val_mae: 1.0407\n",
      "Epoch 2263/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0813 - mae: 1.2664 - val_loss: 1.4649 - val_mae: 1.0404\n",
      "Epoch 2264/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.0803 - mae: 1.2661 - val_loss: 1.4636 - val_mae: 1.0402\n",
      "Epoch 2265/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0792 - mae: 1.2658 - val_loss: 1.4615 - val_mae: 1.0398\n",
      "Epoch 2266/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0781 - mae: 1.2654 - val_loss: 1.4602 - val_mae: 1.0396\n",
      "Epoch 2267/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0771 - mae: 1.2651 - val_loss: 1.4580 - val_mae: 1.0392\n",
      "Epoch 2268/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.0760 - mae: 1.2648 - val_loss: 1.4569 - val_mae: 1.0390\n",
      "Epoch 2269/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0749 - mae: 1.2645 - val_loss: 1.4549 - val_mae: 1.0387\n",
      "Epoch 2270/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.0739 - mae: 1.2641 - val_loss: 1.4537 - val_mae: 1.0385\n",
      "Epoch 2271/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0728 - mae: 1.2639 - val_loss: 1.4518 - val_mae: 1.0382\n",
      "Epoch 2272/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.0718 - mae: 1.2635 - val_loss: 1.4501 - val_mae: 1.0379\n",
      "Epoch 2273/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.0707 - mae: 1.2632 - val_loss: 1.4488 - val_mae: 1.0376\n",
      "Epoch 2274/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0697 - mae: 1.2629 - val_loss: 1.4470 - val_mae: 1.0373\n",
      "Epoch 2275/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0686 - mae: 1.2626 - val_loss: 1.4455 - val_mae: 1.0370\n",
      "Epoch 2276/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0675 - mae: 1.2623 - val_loss: 1.4441 - val_mae: 1.0368\n",
      "Epoch 2277/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0665 - mae: 1.2620 - val_loss: 1.4419 - val_mae: 1.0364\n",
      "Epoch 2278/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0654 - mae: 1.2616 - val_loss: 1.4413 - val_mae: 1.0363\n",
      "Epoch 2279/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0644 - mae: 1.2614 - val_loss: 1.4383 - val_mae: 1.0358\n",
      "Epoch 2280/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0633 - mae: 1.2609 - val_loss: 1.4385 - val_mae: 1.0358\n",
      "Epoch 2281/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0622 - mae: 1.2608 - val_loss: 1.4353 - val_mae: 1.0353\n",
      "Epoch 2282/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0612 - mae: 1.2603 - val_loss: 1.4351 - val_mae: 1.0352\n",
      "Epoch 2283/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0601 - mae: 1.2601 - val_loss: 1.4323 - val_mae: 1.0347\n",
      "Epoch 2284/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0590 - mae: 1.2597 - val_loss: 1.4318 - val_mae: 1.0346\n",
      "Epoch 2285/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0580 - mae: 1.2594 - val_loss: 1.4296 - val_mae: 1.0342\n",
      "Epoch 2286/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0570 - mae: 1.2591 - val_loss: 1.4286 - val_mae: 1.0341\n",
      "Epoch 2287/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0559 - mae: 1.2588 - val_loss: 1.4268 - val_mae: 1.0337\n",
      "Epoch 2288/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0548 - mae: 1.2584 - val_loss: 1.4252 - val_mae: 1.0335\n",
      "Epoch 2289/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0538 - mae: 1.2581 - val_loss: 1.4237 - val_mae: 1.0332\n",
      "Epoch 2290/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0527 - mae: 1.2578 - val_loss: 1.4221 - val_mae: 1.0329\n",
      "Epoch 2291/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0517 - mae: 1.2575 - val_loss: 1.4209 - val_mae: 1.0327\n",
      "Epoch 2292/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0506 - mae: 1.2572 - val_loss: 1.4193 - val_mae: 1.0324\n",
      "Epoch 2293/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0496 - mae: 1.2569 - val_loss: 1.4177 - val_mae: 1.0321\n",
      "Epoch 2294/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0485 - mae: 1.2565 - val_loss: 1.4162 - val_mae: 1.0318\n",
      "Epoch 2295/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0475 - mae: 1.2562 - val_loss: 1.4149 - val_mae: 1.0316\n",
      "Epoch 2296/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0464 - mae: 1.2559 - val_loss: 1.4133 - val_mae: 1.0313\n",
      "Epoch 2297/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0453 - mae: 1.2556 - val_loss: 1.4119 - val_mae: 1.0310\n",
      "Epoch 2298/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0443 - mae: 1.2553 - val_loss: 1.4103 - val_mae: 1.0307\n",
      "Epoch 2299/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0432 - mae: 1.2549 - val_loss: 1.4090 - val_mae: 1.0305\n",
      "Epoch 2300/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0422 - mae: 1.2546 - val_loss: 1.4074 - val_mae: 1.0302\n",
      "Epoch 2301/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0411 - mae: 1.2543 - val_loss: 1.4064 - val_mae: 1.0300\n",
      "Epoch 2302/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0401 - mae: 1.2540 - val_loss: 1.4044 - val_mae: 1.0296\n",
      "Epoch 2303/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0390 - mae: 1.2536 - val_loss: 1.4035 - val_mae: 1.0295\n",
      "Epoch 2304/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0380 - mae: 1.2534 - val_loss: 1.4013 - val_mae: 1.0291\n",
      "Epoch 2305/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0369 - mae: 1.2530 - val_loss: 1.4002 - val_mae: 1.0289\n",
      "Epoch 2306/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0359 - mae: 1.2527 - val_loss: 1.3986 - val_mae: 1.0286\n",
      "Epoch 2307/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0348 - mae: 1.2524 - val_loss: 1.3973 - val_mae: 1.0283\n",
      "Epoch 2308/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0338 - mae: 1.2521 - val_loss: 1.3960 - val_mae: 1.0281\n",
      "Epoch 2309/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0327 - mae: 1.2518 - val_loss: 1.3946 - val_mae: 1.0278\n",
      "Epoch 2310/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0317 - mae: 1.2514 - val_loss: 1.3937 - val_mae: 1.0276\n",
      "Epoch 2311/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0306 - mae: 1.2511 - val_loss: 1.3917 - val_mae: 1.0273\n",
      "Epoch 2312/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0295 - mae: 1.2508 - val_loss: 1.3910 - val_mae: 1.0271\n",
      "Epoch 2313/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0285 - mae: 1.2505 - val_loss: 1.3886 - val_mae: 1.0267\n",
      "Epoch 2314/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0274 - mae: 1.2501 - val_loss: 1.3880 - val_mae: 1.0266\n",
      "Epoch 2315/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0264 - mae: 1.2499 - val_loss: 1.3855 - val_mae: 1.0261\n",
      "Epoch 2316/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0253 - mae: 1.2495 - val_loss: 1.3853 - val_mae: 1.0260\n",
      "Epoch 2317/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0243 - mae: 1.2493 - val_loss: 1.3827 - val_mae: 1.0256\n",
      "Epoch 2318/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0232 - mae: 1.2488 - val_loss: 1.3829 - val_mae: 1.0256\n",
      "Epoch 2319/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0222 - mae: 1.2486 - val_loss: 1.3801 - val_mae: 1.0251\n",
      "Epoch 2320/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0212 - mae: 1.2482 - val_loss: 1.3801 - val_mae: 1.0251\n",
      "Epoch 2321/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0201 - mae: 1.2480 - val_loss: 1.3773 - val_mae: 1.0245\n",
      "Epoch 2322/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0191 - mae: 1.2475 - val_loss: 1.3772 - val_mae: 1.0245\n",
      "Epoch 2323/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0180 - mae: 1.2473 - val_loss: 1.3747 - val_mae: 1.0240\n",
      "Epoch 2324/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0170 - mae: 1.2471 - val_loss: 1.3708 - val_mae: 1.0233\n",
      "Epoch 2325/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0159 - mae: 1.2467 - val_loss: 1.3719 - val_mae: 1.0235\n",
      "Epoch 2326/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0149 - mae: 1.2468 - val_loss: 1.3650 - val_mae: 1.0221\n",
      "Epoch 2327/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0139 - mae: 1.2460 - val_loss: 1.3695 - val_mae: 1.0230\n",
      "Epoch 2328/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0129 - mae: 1.2464 - val_loss: 1.3599 - val_mae: 1.0212\n",
      "Epoch 2329/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0119 - mae: 1.2453 - val_loss: 1.3672 - val_mae: 1.0226\n",
      "Epoch 2330/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0108 - mae: 1.2460 - val_loss: 1.3550 - val_mae: 1.0202\n",
      "Epoch 2331/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0098 - mae: 1.2445 - val_loss: 1.3657 - val_mae: 1.0222\n",
      "Epoch 2332/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0088 - mae: 1.2456 - val_loss: 1.3503 - val_mae: 1.0192\n",
      "Epoch 2333/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0078 - mae: 1.2439 - val_loss: 1.3646 - val_mae: 1.0220\n",
      "Epoch 2334/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0069 - mae: 1.2452 - val_loss: 1.3451 - val_mae: 1.0181\n",
      "Epoch 2335/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0058 - mae: 1.2435 - val_loss: 1.3603 - val_mae: 1.0212\n",
      "Epoch 2336/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0048 - mae: 1.2448 - val_loss: 1.3398 - val_mae: 1.0170\n",
      "Epoch 2337/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0039 - mae: 1.2430 - val_loss: 1.3580 - val_mae: 1.0207\n",
      "Epoch 2338/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0029 - mae: 1.2445 - val_loss: 1.3341 - val_mae: 1.0157\n",
      "Epoch 2339/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0020 - mae: 1.2425 - val_loss: 1.3575 - val_mae: 1.0206\n",
      "Epoch 2340/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0011 - mae: 1.2443 - val_loss: 1.3274 - val_mae: 1.0142\n",
      "Epoch 2341/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0002 - mae: 1.2420 - val_loss: 1.3592 - val_mae: 1.0208\n",
      "Epoch 2342/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9995 - mae: 1.2442 - val_loss: 1.3191 - val_mae: 1.0123\n",
      "Epoch 2343/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9990 - mae: 1.2414 - val_loss: 1.3647 - val_mae: 1.0217\n",
      "Epoch 2344/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.9987 - mae: 1.2446 - val_loss: 1.3064 - val_mae: 1.0091\n",
      "Epoch 2345/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.9989 - mae: 1.2419 - val_loss: 1.3761 - val_mae: 1.0236\n",
      "Epoch 2346/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9997 - mae: 1.2456 - val_loss: 1.2921 - val_mae: 1.0049\n",
      "Epoch 2347/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0014 - mae: 1.2431 - val_loss: 1.3983 - val_mae: 1.0271\n",
      "Epoch 2348/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0045 - mae: 1.2474 - val_loss: 1.2762 - val_mae: 0.9991\n",
      "Epoch 2349/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0098 - mae: 1.2453 - val_loss: 1.4401 - val_mae: 1.0329\n",
      "Epoch 2350/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0185 - mae: 1.2505 - val_loss: 1.2616 - val_mae: 0.9903\n",
      "Epoch 2351/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0328 - mae: 1.2492 - val_loss: 1.5218 - val_mae: 1.0525\n",
      "Epoch 2352/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0563 - mae: 1.2559 - val_loss: 1.2630 - val_mae: 0.9939\n",
      "Epoch 2353/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.0945 - mae: 1.2558 - val_loss: 1.6920 - val_mae: 1.1132\n",
      "Epoch 2354/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1571 - mae: 1.2716 - val_loss: 1.3315 - val_mae: 1.0157\n",
      "Epoch 2355/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2589 - mae: 1.2828 - val_loss: 2.0730 - val_mae: 1.2481\n",
      "Epoch 2356/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.4248 - mae: 1.3318 - val_loss: 1.6149 - val_mae: 1.0511\n",
      "Epoch 2357/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.6979 - mae: 1.3645 - val_loss: 2.9858 - val_mae: 1.4760\n",
      "Epoch 2358/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.1510 - mae: 1.4651 - val_loss: 2.5645 - val_mae: 1.2044\n",
      "Epoch 2359/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.9065 - mae: 1.5950 - val_loss: 5.3155 - val_mae: 2.0144\n",
      "Epoch 2360/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.1717 - mae: 1.8646 - val_loss: 5.5218 - val_mae: 2.0688\n",
      "Epoch 2361/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 7.3088 - mae: 2.3113 - val_loss: 11.5879 - val_mae: 3.2137\n",
      "Epoch 2362/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 10.9222 - mae: 2.9876 - val_loss: 14.4984 - val_mae: 3.6419\n",
      "Epoch 2363/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 17.0857 - mae: 3.8895 - val_loss: 29.1376 - val_mae: 5.2793\n",
      "Epoch 2364/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 27.5553 - mae: 5.0545 - val_loss: 41.3307 - val_mae: 6.3329\n",
      "Epoch 2365/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 45.4417 - mae: 6.5953 - val_loss: 78.8792 - val_mae: 8.8090\n",
      "Epoch 2366/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 75.5683 - mae: 8.5756 - val_loss: 118.8012 - val_mae: 10.8440\n",
      "Epoch 2367/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 125.9151 - mae: 11.1351 - val_loss: 213.8130 - val_mae: 14.5777\n",
      "Epoch 2368/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 206.9276 - mae: 14.3131 - val_loss: 318.4287 - val_mae: 17.8112\n",
      "Epoch 2369/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 331.0746 - mae: 18.1432 - val_loss: 515.4520 - val_mae: 22.6739\n",
      "Epoch 2370/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 500.5294 - mae: 22.3252 - val_loss: 670.6140 - val_mae: 25.8736\n",
      "Epoch 2371/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 691.4612 - mae: 26.2600 - val_loss: 849.1215 - val_mae: 29.1158\n",
      "Epoch 2372/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 821.4847 - mae: 28.6236 - val_loss: 747.7631 - val_mae: 27.3233\n",
      "Epoch 2373/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 774.5035 - mae: 27.7960 - val_loss: 530.2538 - val_mae: 22.9965\n",
      "Epoch 2374/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 502.2371 - mae: 22.3621 - val_loss: 143.6348 - val_mae: 11.9294\n",
      "Epoch 2375/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 159.6963 - mae: 12.5572 - val_loss: 2.9237 - val_mae: 1.5170\n",
      "Epoch 2376/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3818 - mae: 1.3429 - val_loss: 50.1405 - val_mae: 6.9784\n",
      "Epoch 2377/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 41.6722 - mae: 6.2850 - val_loss: 118.3738 - val_mae: 10.8179\n",
      "Epoch 2378/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 134.1672 - mae: 11.4929 - val_loss: 392.6334 - val_mae: 19.7767\n",
      "Epoch 2379/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 362.5051 - mae: 18.9794 - val_loss: 538.7528 - val_mae: 23.1831\n",
      "Epoch 2380/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 572.0654 - mae: 23.8751 - val_loss: 584.8897 - val_mae: 24.1519\n",
      "Epoch 2381/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 543.7308 - mae: 23.2673 - val_loss: 226.7015 - val_mae: 15.0107\n",
      "Epoch 2382/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 251.2520 - mae: 15.7833 - val_loss: 21.3494 - val_mae: 4.4527\n",
      "Epoch 2383/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 15.1204 - mae: 3.5824 - val_loss: 93.7403 - val_mae: 9.5997\n",
      "Epoch 2384/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 77.8387 - mae: 8.6890 - val_loss: 238.1343 - val_mae: 15.3851\n",
      "Epoch 2385/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 265.2899 - mae: 16.2204 - val_loss: 292.0291 - val_mae: 17.0398\n",
      "Epoch 2386/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 260.6506 - mae: 16.0695 - val_loss: 61.7360 - val_mae: 7.7608\n",
      "Epoch 2387/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 77.0976 - mae: 8.6510 - val_loss: 3.0219 - val_mae: 1.2811\n",
      "Epoch 2388/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 6.8595 - mae: 2.1324 - val_loss: 139.0190 - val_mae: 11.7201\n",
      "Epoch 2389/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 117.8271 - mae: 10.7433 - val_loss: 148.8119 - val_mae: 12.1372\n",
      "Epoch 2390/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 172.0094 - mae: 13.0292 - val_loss: 86.4851 - val_mae: 9.2106\n",
      "Epoch 2391/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 70.2936 - mae: 8.2398 - val_loss: 3.6633 - val_mae: 1.7168\n",
      "Epoch 2392/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5942 - mae: 1.4547 - val_loss: 52.9867 - val_mae: 7.1722\n",
      "Epoch 2393/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 67.5312 - mae: 8.0772 - val_loss: 129.4956 - val_mae: 11.3058\n",
      "Epoch 2394/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 109.3452 - mae: 10.3405 - val_loss: 32.5740 - val_mae: 5.5689\n",
      "Epoch 2395/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 44.0835 - mae: 6.4640 - val_loss: 1.6151 - val_mae: 1.0730\n",
      "Epoch 2396/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.9838 - mae: 1.4201 - val_loss: 62.2347 - val_mae: 7.7831\n",
      "Epoch 2397/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 49.2084 - mae: 6.8418 - val_loss: 55.0677 - val_mae: 7.3151\n",
      "Epoch 2398/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 69.4316 - mae: 8.1939 - val_loss: 30.4609 - val_mae: 5.3680\n",
      "Epoch 2399/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 22.1229 - mae: 4.4430 - val_loss: 8.0875 - val_mae: 2.5415\n",
      "Epoch 2400/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.0258 - mae: 1.8521 - val_loss: 28.8837 - val_mae: 5.2256\n",
      "Epoch 2401/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 39.5127 - mae: 6.0997 - val_loss: 54.0548 - val_mae: 7.2381\n",
      "Epoch 2402/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 42.3437 - mae: 6.3205 - val_loss: 4.4916 - val_mae: 1.6993\n",
      "Epoch 2403/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 8.9683 - mae: 2.5764 - val_loss: 4.0110 - val_mae: 1.5579\n",
      "Epoch 2404/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.1993 - mae: 2.4226 - val_loss: 41.0061 - val_mae: 6.2725\n",
      "Epoch 2405/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 31.2819 - mae: 5.3756 - val_loss: 15.8416 - val_mae: 3.7748\n",
      "Epoch 2406/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 23.7070 - mae: 4.6255 - val_loss: 5.0777 - val_mae: 1.9625\n",
      "Epoch 2407/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.3288 - mae: 1.5821 - val_loss: 15.8803 - val_mae: 3.7728\n",
      "Epoch 2408/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.7958 - mae: 2.9039 - val_loss: 15.4283 - val_mae: 3.7195\n",
      "Epoch 2409/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.0246 - mae: 4.5517 - val_loss: 17.2311 - val_mae: 3.9475\n",
      "Epoch 2410/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 11.9152 - mae: 3.0908 - val_loss: 2.7245 - val_mae: 1.5117\n",
      "Epoch 2411/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3824 - mae: 1.3960 - val_loss: 6.5960 - val_mae: 2.2344\n",
      "Epoch 2412/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 11.6416 - mae: 3.0543 - val_loss: 21.5593 - val_mae: 4.4608\n",
      "Epoch 2413/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 15.5084 - mae: 3.6258 - val_loss: 2.5960 - val_mae: 1.1655\n",
      "Epoch 2414/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.5663 - mae: 1.8563 - val_loss: 1.6651 - val_mae: 1.0444\n",
      "Epoch 2415/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.3636 - mae: 1.4758 - val_loss: 15.3313 - val_mae: 3.6979\n",
      "Epoch 2416/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 10.6833 - mae: 2.8865 - val_loss: 5.2837 - val_mae: 1.9181\n",
      "Epoch 2417/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 9.6279 - mae: 2.7058 - val_loss: 4.0968 - val_mae: 1.8050\n",
      "Epoch 2418/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9343 - mae: 1.5196 - val_loss: 6.6537 - val_mae: 2.2426\n",
      "Epoch 2419/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 4.4399 - mae: 1.7460 - val_loss: 4.6945 - val_mae: 1.7586\n",
      "Epoch 2420/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 8.6993 - mae: 2.5294 - val_loss: 8.5591 - val_mae: 2.6302\n",
      "Epoch 2421/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.7633 - mae: 1.9647 - val_loss: 2.1263 - val_mae: 1.3227\n",
      "Epoch 2422/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3203 - mae: 1.3407 - val_loss: 2.3203 - val_mae: 1.1121\n",
      "Epoch 2423/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.8868 - mae: 1.7148 - val_loss: 9.6178 - val_mae: 2.8255\n",
      "Epoch 2424/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5664 - mae: 2.1255 - val_loss: 1.7576 - val_mae: 1.0620\n",
      "Epoch 2425/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.6299 - mae: 1.5060 - val_loss: 1.7172 - val_mae: 1.1188\n",
      "Epoch 2426/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.4774 - mae: 1.3404 - val_loss: 6.9364 - val_mae: 2.3065\n",
      "Epoch 2427/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4.7163 - mae: 1.7816 - val_loss: 2.2985 - val_mae: 1.1104\n",
      "Epoch 2428/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.8188 - mae: 1.7026 - val_loss: 3.4227 - val_mae: 1.6690\n",
      "Epoch 2429/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6633 - mae: 1.4628 - val_loss: 3.5905 - val_mae: 1.7020\n",
      "Epoch 2430/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.7409 - mae: 1.4776 - val_loss: 2.0003 - val_mae: 1.0882\n",
      "Epoch 2431/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.2139 - mae: 1.5971 - val_loss: 5.1924 - val_mae: 1.9698\n",
      "Epoch 2432/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.6208 - mae: 1.6206 - val_loss: 1.8531 - val_mae: 1.2013\n",
      "Epoch 2433/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.3317 - mae: 1.3279 - val_loss: 1.5754 - val_mae: 1.0505\n",
      "Epoch 2434/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.8704 - mae: 1.4066 - val_loss: 5.2151 - val_mae: 1.9710\n",
      "Epoch 2435/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.6423 - mae: 1.6218 - val_loss: 1.5731 - val_mae: 1.0458\n",
      "Epoch 2436/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9060 - mae: 1.4122 - val_loss: 2.0468 - val_mae: 1.2905\n",
      "Epoch 2437/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2710 - mae: 1.3281 - val_loss: 3.8094 - val_mae: 1.7388\n",
      "Epoch 2438/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.8518 - mae: 1.4902 - val_loss: 1.6087 - val_mae: 1.0388\n",
      "Epoch 2439/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1504 - mae: 1.4468 - val_loss: 3.1065 - val_mae: 1.5947\n",
      "Epoch 2440/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5243 - mae: 1.4250 - val_loss: 2.3884 - val_mae: 1.4085\n",
      "Epoch 2441/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2894 - mae: 1.3613 - val_loss: 1.5537 - val_mae: 1.0517\n",
      "Epoch 2442/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7487 - mae: 1.3864 - val_loss: 3.6798 - val_mae: 1.7115\n",
      "Epoch 2443/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.7901 - mae: 1.4757 - val_loss: 1.7125 - val_mae: 1.1233\n",
      "Epoch 2444/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3415 - mae: 1.3183 - val_loss: 1.7510 - val_mae: 1.1478\n",
      "Epoch 2445/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3106 - mae: 1.3161 - val_loss: 3.3267 - val_mae: 1.6395\n",
      "Epoch 2446/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.6231 - mae: 1.4427 - val_loss: 1.5635 - val_mae: 1.0645\n",
      "Epoch 2447/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.5551 - mae: 1.3495 - val_loss: 2.3170 - val_mae: 1.3846\n",
      "Epoch 2448/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2645 - mae: 1.3505 - val_loss: 2.5263 - val_mae: 1.4466\n",
      "Epoch 2449/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3146 - mae: 1.3713 - val_loss: 1.5677 - val_mae: 1.0669\n",
      "Epoch 2450/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5067 - mae: 1.3408 - val_loss: 2.8092 - val_mae: 1.5203\n",
      "Epoch 2451/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4091 - mae: 1.3958 - val_loss: 1.9180 - val_mae: 1.2361\n",
      "Epoch 2452/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2324 - mae: 1.3126 - val_loss: 1.7045 - val_mae: 1.1217\n",
      "Epoch 2453/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3017 - mae: 1.3110 - val_loss: 2.8113 - val_mae: 1.5198\n",
      "Epoch 2454/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4107 - mae: 1.3945 - val_loss: 1.6671 - val_mae: 1.1061\n",
      "Epoch 2455/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3186 - mae: 1.3118 - val_loss: 2.0314 - val_mae: 1.2836\n",
      "Epoch 2456/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2162 - mae: 1.3158 - val_loss: 2.4156 - val_mae: 1.4126\n",
      "Epoch 2457/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2791 - mae: 1.3572 - val_loss: 1.6248 - val_mae: 1.0873\n",
      "Epoch 2458/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3372 - mae: 1.3122 - val_loss: 2.3590 - val_mae: 1.3950\n",
      "Epoch 2459/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2635 - mae: 1.3510 - val_loss: 1.9869 - val_mae: 1.2659\n",
      "Epoch 2460/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2058 - mae: 1.3121 - val_loss: 1.7080 - val_mae: 1.1301\n",
      "Epoch 2461/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2545 - mae: 1.3058 - val_loss: 2.4317 - val_mae: 1.4154\n",
      "Epoch 2462/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2839 - mae: 1.3579 - val_loss: 1.7414 - val_mae: 1.1513\n",
      "Epoch 2463/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2290 - mae: 1.3046 - val_loss: 1.9064 - val_mae: 1.2327\n",
      "Epoch 2464/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1953 - mae: 1.3069 - val_loss: 2.2279 - val_mae: 1.3518\n",
      "Epoch 2465/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2285 - mae: 1.3362 - val_loss: 1.6640 - val_mae: 1.1088\n",
      "Epoch 2466/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2406 - mae: 1.3020 - val_loss: 2.1047 - val_mae: 1.3094\n",
      "Epoch 2467/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2005 - mae: 1.3217 - val_loss: 1.9358 - val_mae: 1.2455\n",
      "Epoch 2468/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1802 - mae: 1.3066 - val_loss: 1.6978 - val_mae: 1.1326\n",
      "Epoch 2469/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2034 - mae: 1.3005 - val_loss: 2.1519 - val_mae: 1.3243\n",
      "Epoch 2470/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2108 - mae: 1.3282 - val_loss: 1.7345 - val_mae: 1.1543\n",
      "Epoch 2471/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1844 - mae: 1.3000 - val_loss: 1.8141 - val_mae: 1.1935\n",
      "Epoch 2472/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1715 - mae: 1.3007 - val_loss: 2.0273 - val_mae: 1.2798\n",
      "Epoch 2473/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1858 - mae: 1.3140 - val_loss: 1.6600 - val_mae: 1.1149\n",
      "Epoch 2474/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1886 - mae: 1.2983 - val_loss: 1.9362 - val_mae: 1.2447\n",
      "Epoch 2475/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1697 - mae: 1.3057 - val_loss: 1.8393 - val_mae: 1.2047\n",
      "Epoch 2476/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1603 - mae: 1.3009 - val_loss: 1.6786 - val_mae: 1.1270\n",
      "Epoch 2477/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1691 - mae: 1.2963 - val_loss: 1.9607 - val_mae: 1.2533\n",
      "Epoch 2478/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.1708 - mae: 1.3068 - val_loss: 1.6979 - val_mae: 1.1381\n",
      "Epoch 2479/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1580 - mae: 1.2950 - val_loss: 1.7524 - val_mae: 1.1653\n",
      "Epoch 2480/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1507 - mae: 1.2959 - val_loss: 1.8714 - val_mae: 1.2175\n",
      "Epoch 2481/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1556 - mae: 1.3018 - val_loss: 1.6397 - val_mae: 1.1075\n",
      "Epoch 2482/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1566 - mae: 1.2928 - val_loss: 1.8189 - val_mae: 1.1951\n",
      "Epoch 2483/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1480 - mae: 1.2991 - val_loss: 1.7432 - val_mae: 1.1609\n",
      "Epoch 2484/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1423 - mae: 1.2951 - val_loss: 1.6533 - val_mae: 1.1154\n",
      "Epoch 2485/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1449 - mae: 1.2912 - val_loss: 1.8233 - val_mae: 1.1958\n",
      "Epoch 2486/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1456 - mae: 1.2989 - val_loss: 1.6525 - val_mae: 1.1148\n",
      "Epoch 2487/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1397 - mae: 1.2901 - val_loss: 1.7042 - val_mae: 1.1412\n",
      "Epoch 2488/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1350 - mae: 1.2924 - val_loss: 1.7581 - val_mae: 1.1662\n",
      "Epoch 2489/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1357 - mae: 1.2953 - val_loss: 1.6196 - val_mae: 1.0964\n",
      "Epoch 2490/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1361 - mae: 1.2884 - val_loss: 1.7419 - val_mae: 1.1582\n",
      "Epoch 2491/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1321 - mae: 1.2942 - val_loss: 1.6726 - val_mae: 1.1245\n",
      "Epoch 2492/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1281 - mae: 1.2902 - val_loss: 1.6337 - val_mae: 1.1040\n",
      "Epoch 2493/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1276 - mae: 1.2877 - val_loss: 1.7291 - val_mae: 1.1514\n",
      "Epoch 2494/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1275 - mae: 1.2931 - val_loss: 1.6152 - val_mae: 1.0936\n",
      "Epoch 2495/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1247 - mae: 1.2863 - val_loss: 1.6648 - val_mae: 1.1198\n",
      "Epoch 2496/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1213 - mae: 1.2892 - val_loss: 1.6751 - val_mae: 1.1247\n",
      "Epoch 2497/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1202 - mae: 1.2897 - val_loss: 1.5976 - val_mae: 1.0855\n",
      "Epoch 2498/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1198 - mae: 1.2848 - val_loss: 1.6777 - val_mae: 1.1256\n",
      "Epoch 2499/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1177 - mae: 1.2896 - val_loss: 1.6161 - val_mae: 1.0935\n",
      "Epoch 2500/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1148 - mae: 1.2858 - val_loss: 1.6092 - val_mae: 1.0897\n",
      "Epoch 2501/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1132 - mae: 1.2852 - val_loss: 1.6548 - val_mae: 1.1134\n",
      "Epoch 2502/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1125 - mae: 1.2878 - val_loss: 1.5806 - val_mae: 1.0790\n",
      "Epoch 2503/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1109 - mae: 1.2831 - val_loss: 1.6249 - val_mae: 1.0976\n",
      "Epoch 2504/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1086 - mae: 1.2859 - val_loss: 1.6099 - val_mae: 1.0895\n",
      "Epoch 2505/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1070 - mae: 1.2849 - val_loss: 1.5735 - val_mae: 1.0761\n",
      "Epoch 2506/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1062 - mae: 1.2825 - val_loss: 1.6212 - val_mae: 1.0952\n",
      "Epoch 2507/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1050 - mae: 1.2856 - val_loss: 1.5705 - val_mae: 1.0748\n",
      "Epoch 2508/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1032 - mae: 1.2824 - val_loss: 1.5820 - val_mae: 1.0786\n",
      "Epoch 2509/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1017 - mae: 1.2832 - val_loss: 1.5945 - val_mae: 1.0827\n",
      "Epoch 2510/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1007 - mae: 1.2840 - val_loss: 1.5519 - val_mae: 1.0680\n",
      "Epoch 2511/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0998 - mae: 1.2812 - val_loss: 1.5866 - val_mae: 1.0798\n",
      "Epoch 2512/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0984 - mae: 1.2835 - val_loss: 1.5616 - val_mae: 1.0712\n",
      "Epoch 2513/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0969 - mae: 1.2819 - val_loss: 1.5522 - val_mae: 1.0678\n",
      "Epoch 2514/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0957 - mae: 1.2812 - val_loss: 1.5752 - val_mae: 1.0756\n",
      "Epoch 2515/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0947 - mae: 1.2827 - val_loss: 1.5391 - val_mae: 1.0630\n",
      "Epoch 2516/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0935 - mae: 1.2802 - val_loss: 1.5579 - val_mae: 1.0695\n",
      "Epoch 2517/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0920 - mae: 1.2814 - val_loss: 1.5517 - val_mae: 1.0673\n",
      "Epoch 2518/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0908 - mae: 1.2809 - val_loss: 1.5327 - val_mae: 1.0604\n",
      "Epoch 2519/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0897 - mae: 1.2795 - val_loss: 1.5544 - val_mae: 1.0681\n",
      "Epoch 2520/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0885 - mae: 1.2809 - val_loss: 1.5301 - val_mae: 1.0594\n",
      "Epoch 2521/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0872 - mae: 1.2791 - val_loss: 1.5354 - val_mae: 1.0613\n",
      "Epoch 2522/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0859 - mae: 1.2794 - val_loss: 1.5394 - val_mae: 1.0626\n",
      "Epoch 2523/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0848 - mae: 1.2795 - val_loss: 1.5194 - val_mae: 1.0553\n",
      "Epoch 2524/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0836 - mae: 1.2780 - val_loss: 1.5351 - val_mae: 1.0610\n",
      "Epoch 2525/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0824 - mae: 1.2789 - val_loss: 1.5212 - val_mae: 1.0559\n",
      "Epoch 2526/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0811 - mae: 1.2778 - val_loss: 1.5180 - val_mae: 1.0547\n",
      "Epoch 2527/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0799 - mae: 1.2774 - val_loss: 1.5263 - val_mae: 1.0577\n",
      "Epoch 2528/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0788 - mae: 1.2778 - val_loss: 1.5086 - val_mae: 1.0511\n",
      "Epoch 2529/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0776 - mae: 1.2764 - val_loss: 1.5183 - val_mae: 1.0547\n",
      "Epoch 2530/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0763 - mae: 1.2769 - val_loss: 1.5116 - val_mae: 1.0522\n",
      "Epoch 2531/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0751 - mae: 1.2763 - val_loss: 1.5044 - val_mae: 1.0495\n",
      "Epoch 2532/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0739 - mae: 1.2756 - val_loss: 1.5128 - val_mae: 1.0526\n",
      "Epoch 2533/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0727 - mae: 1.2760 - val_loss: 1.4991 - val_mae: 1.0475\n",
      "Epoch 2534/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0715 - mae: 1.2748 - val_loss: 1.5036 - val_mae: 1.0491\n",
      "Epoch 2535/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0703 - mae: 1.2750 - val_loss: 1.5016 - val_mae: 1.0483\n",
      "Epoch 2536/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0691 - mae: 1.2746 - val_loss: 1.4924 - val_mae: 1.0448\n",
      "Epoch 2537/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0679 - mae: 1.2738 - val_loss: 1.5000 - val_mae: 1.0477\n",
      "Epoch 2538/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0667 - mae: 1.2741 - val_loss: 1.4900 - val_mae: 1.0441\n",
      "Epoch 2539/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0655 - mae: 1.2732 - val_loss: 1.4902 - val_mae: 1.0441\n",
      "Epoch 2540/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0643 - mae: 1.2730 - val_loss: 1.4914 - val_mae: 1.0443\n",
      "Epoch 2541/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0631 - mae: 1.2729 - val_loss: 1.4821 - val_mae: 1.0428\n",
      "Epoch 2542/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0619 - mae: 1.2720 - val_loss: 1.4874 - val_mae: 1.0434\n",
      "Epoch 2543/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0607 - mae: 1.2722 - val_loss: 1.4807 - val_mae: 1.0424\n",
      "Epoch 2544/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0595 - mae: 1.2715 - val_loss: 1.4787 - val_mae: 1.0421\n",
      "Epoch 2545/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0583 - mae: 1.2711 - val_loss: 1.4806 - val_mae: 1.0422\n",
      "Epoch 2546/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0571 - mae: 1.2711 - val_loss: 1.4726 - val_mae: 1.0411\n",
      "Epoch 2547/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0560 - mae: 1.2702 - val_loss: 1.4757 - val_mae: 1.0414\n",
      "Epoch 2548/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0548 - mae: 1.2703 - val_loss: 1.4714 - val_mae: 1.0407\n",
      "Epoch 2549/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0536 - mae: 1.2697 - val_loss: 1.4682 - val_mae: 1.0402\n",
      "Epoch 2550/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0524 - mae: 1.2693 - val_loss: 1.4701 - val_mae: 1.0404\n",
      "Epoch 2551/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0512 - mae: 1.2692 - val_loss: 1.4629 - val_mae: 1.0393\n",
      "Epoch 2552/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0500 - mae: 1.2684 - val_loss: 1.4651 - val_mae: 1.0395\n",
      "Epoch 2553/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0488 - mae: 1.2684 - val_loss: 1.4619 - val_mae: 1.0390\n",
      "Epoch 2554/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0476 - mae: 1.2679 - val_loss: 1.4579 - val_mae: 1.0384\n",
      "Epoch 2555/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0465 - mae: 1.2674 - val_loss: 1.4600 - val_mae: 1.0386\n",
      "Epoch 2556/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0453 - mae: 1.2673 - val_loss: 1.4538 - val_mae: 1.0376\n",
      "Epoch 2557/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0441 - mae: 1.2667 - val_loss: 1.4546 - val_mae: 1.0377\n",
      "Epoch 2558/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0430 - mae: 1.2665 - val_loss: 1.4524 - val_mae: 1.0373\n",
      "Epoch 2559/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0418 - mae: 1.2661 - val_loss: 1.4485 - val_mae: 1.0366\n",
      "Epoch 2560/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0406 - mae: 1.2656 - val_loss: 1.4498 - val_mae: 1.0367\n",
      "Epoch 2561/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0394 - mae: 1.2655 - val_loss: 1.4449 - val_mae: 1.0360\n",
      "Epoch 2562/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0382 - mae: 1.2649 - val_loss: 1.4448 - val_mae: 1.0359\n",
      "Epoch 2563/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0371 - mae: 1.2646 - val_loss: 1.4430 - val_mae: 1.0356\n",
      "Epoch 2564/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0359 - mae: 1.2643 - val_loss: 1.4395 - val_mae: 1.0350\n",
      "Epoch 2565/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0348 - mae: 1.2638 - val_loss: 1.4398 - val_mae: 1.0349\n",
      "Epoch 2566/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0336 - mae: 1.2636 - val_loss: 1.4362 - val_mae: 1.0343\n",
      "Epoch 2567/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0324 - mae: 1.2631 - val_loss: 1.4354 - val_mae: 1.0341\n",
      "Epoch 2568/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0312 - mae: 1.2628 - val_loss: 1.4334 - val_mae: 1.0338\n",
      "Epoch 2569/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0301 - mae: 1.2624 - val_loss: 1.4307 - val_mae: 1.0333\n",
      "Epoch 2570/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0289 - mae: 1.2620 - val_loss: 1.4302 - val_mae: 1.0331\n",
      "Epoch 2571/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0278 - mae: 1.2617 - val_loss: 1.4270 - val_mae: 1.0326\n",
      "Epoch 2572/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0267 - mae: 1.2613 - val_loss: 1.4255 - val_mae: 1.0323\n",
      "Epoch 2573/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0255 - mae: 1.2611 - val_loss: 1.4215 - val_mae: 1.0316\n",
      "Epoch 2574/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0244 - mae: 1.2607 - val_loss: 1.4177 - val_mae: 1.0310\n",
      "Epoch 2575/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0232 - mae: 1.2604 - val_loss: 1.4161 - val_mae: 1.0306\n",
      "Epoch 2576/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0221 - mae: 1.2603 - val_loss: 1.4107 - val_mae: 1.0297\n",
      "Epoch 2577/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0209 - mae: 1.2598 - val_loss: 1.4098 - val_mae: 1.0295\n",
      "Epoch 2578/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0198 - mae: 1.2596 - val_loss: 1.4059 - val_mae: 1.0288\n",
      "Epoch 2579/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0187 - mae: 1.2593 - val_loss: 1.4023 - val_mae: 1.0282\n",
      "Epoch 2580/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0176 - mae: 1.2589 - val_loss: 1.4014 - val_mae: 1.0280\n",
      "Epoch 2581/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0164 - mae: 1.2587 - val_loss: 1.3967 - val_mae: 1.0272\n",
      "Epoch 2582/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0153 - mae: 1.2582 - val_loss: 1.3959 - val_mae: 1.0270\n",
      "Epoch 2583/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0142 - mae: 1.2580 - val_loss: 1.3930 - val_mae: 1.0265\n",
      "Epoch 2584/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0131 - mae: 1.2577 - val_loss: 1.3902 - val_mae: 1.0259\n",
      "Epoch 2585/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0119 - mae: 1.2573 - val_loss: 1.3895 - val_mae: 1.0258\n",
      "Epoch 2586/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0108 - mae: 1.2570 - val_loss: 1.3858 - val_mae: 1.0251\n",
      "Epoch 2587/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0096 - mae: 1.2565 - val_loss: 1.3852 - val_mae: 1.0249\n",
      "Epoch 2588/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0085 - mae: 1.2563 - val_loss: 1.3823 - val_mae: 1.0244\n",
      "Epoch 2589/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0074 - mae: 1.2558 - val_loss: 1.3807 - val_mae: 1.0241\n",
      "Epoch 2590/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0062 - mae: 1.2555 - val_loss: 1.3797 - val_mae: 1.0238\n",
      "Epoch 2591/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0051 - mae: 1.2552 - val_loss: 1.3758 - val_mae: 1.0231\n",
      "Epoch 2592/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0041 - mae: 1.2547 - val_loss: 1.3757 - val_mae: 1.0230\n",
      "Epoch 2593/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0030 - mae: 1.2546 - val_loss: 1.3702 - val_mae: 1.0220\n",
      "Epoch 2594/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0018 - mae: 1.2541 - val_loss: 1.3678 - val_mae: 1.0215\n",
      "Epoch 2595/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0007 - mae: 1.2538 - val_loss: 1.3660 - val_mae: 1.0212\n",
      "Epoch 2596/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9996 - mae: 1.2536 - val_loss: 1.3613 - val_mae: 1.0203\n",
      "Epoch 2597/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9985 - mae: 1.2531 - val_loss: 1.3611 - val_mae: 1.0202\n",
      "Epoch 2598/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9974 - mae: 1.2530 - val_loss: 1.3565 - val_mae: 1.0194\n",
      "Epoch 2599/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9963 - mae: 1.2525 - val_loss: 1.3557 - val_mae: 1.0192\n",
      "Epoch 2600/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9952 - mae: 1.2523 - val_loss: 1.3532 - val_mae: 1.0187\n",
      "Epoch 2601/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9941 - mae: 1.2520 - val_loss: 1.3497 - val_mae: 1.0180\n",
      "Epoch 2602/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9930 - mae: 1.2515 - val_loss: 1.3494 - val_mae: 1.0179\n",
      "Epoch 2603/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9919 - mae: 1.2513 - val_loss: 1.3454 - val_mae: 1.0171\n",
      "Epoch 2604/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9907 - mae: 1.2508 - val_loss: 1.3448 - val_mae: 1.0169\n",
      "Epoch 2605/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9896 - mae: 1.2505 - val_loss: 1.3425 - val_mae: 1.0165\n",
      "Epoch 2606/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9885 - mae: 1.2501 - val_loss: 1.3402 - val_mae: 1.0160\n",
      "Epoch 2607/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9874 - mae: 1.2497 - val_loss: 1.3397 - val_mae: 1.0158\n",
      "Epoch 2608/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9864 - mae: 1.2495 - val_loss: 1.3357 - val_mae: 1.0151\n",
      "Epoch 2609/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9852 - mae: 1.2490 - val_loss: 1.3344 - val_mae: 1.0148\n",
      "Epoch 2610/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9842 - mae: 1.2489 - val_loss: 1.3293 - val_mae: 1.0138\n",
      "Epoch 2611/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9831 - mae: 1.2483 - val_loss: 1.3294 - val_mae: 1.0138\n",
      "Epoch 2612/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9820 - mae: 1.2483 - val_loss: 1.3247 - val_mae: 1.0129\n",
      "Epoch 2613/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9809 - mae: 1.2477 - val_loss: 1.3235 - val_mae: 1.0126\n",
      "Epoch 2614/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9798 - mae: 1.2475 - val_loss: 1.3214 - val_mae: 1.0121\n",
      "Epoch 2615/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9788 - mae: 1.2472 - val_loss: 1.3179 - val_mae: 1.0114\n",
      "Epoch 2616/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9777 - mae: 1.2467 - val_loss: 1.3175 - val_mae: 1.0113\n",
      "Epoch 2617/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9766 - mae: 1.2466 - val_loss: 1.3134 - val_mae: 1.0105\n",
      "Epoch 2618/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9755 - mae: 1.2460 - val_loss: 1.3137 - val_mae: 1.0104\n",
      "Epoch 2619/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9744 - mae: 1.2458 - val_loss: 1.3103 - val_mae: 1.0097\n",
      "Epoch 2620/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9733 - mae: 1.2453 - val_loss: 1.3085 - val_mae: 1.0094\n",
      "Epoch 2621/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9722 - mae: 1.2450 - val_loss: 1.3080 - val_mae: 1.0092\n",
      "Epoch 2622/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9711 - mae: 1.2447 - val_loss: 1.3040 - val_mae: 1.0084\n",
      "Epoch 2623/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9701 - mae: 1.2441 - val_loss: 1.3049 - val_mae: 1.0085\n",
      "Epoch 2624/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9690 - mae: 1.2441 - val_loss: 1.2990 - val_mae: 1.0073\n",
      "Epoch 2625/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9679 - mae: 1.2435 - val_loss: 1.2984 - val_mae: 1.0071\n",
      "Epoch 2626/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.9669 - mae: 1.2434 - val_loss: 1.2955 - val_mae: 1.0065\n",
      "Epoch 2627/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9658 - mae: 1.2430 - val_loss: 1.2921 - val_mae: 1.0059\n",
      "Epoch 2628/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9648 - mae: 1.2426 - val_loss: 1.2921 - val_mae: 1.0058\n",
      "Epoch 2629/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9637 - mae: 1.2425 - val_loss: 1.2873 - val_mae: 1.0048\n",
      "Epoch 2630/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9626 - mae: 1.2419 - val_loss: 1.2879 - val_mae: 1.0048\n",
      "Epoch 2631/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9616 - mae: 1.2418 - val_loss: 1.2844 - val_mae: 1.0041\n",
      "Epoch 2632/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9605 - mae: 1.2413 - val_loss: 1.2828 - val_mae: 1.0038\n",
      "Epoch 2633/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9594 - mae: 1.2409 - val_loss: 1.2819 - val_mae: 1.0035\n",
      "Epoch 2634/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9583 - mae: 1.2407 - val_loss: 1.2782 - val_mae: 1.0027\n",
      "Epoch 2635/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9573 - mae: 1.2401 - val_loss: 1.2785 - val_mae: 1.0027\n",
      "Epoch 2636/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9562 - mae: 1.2399 - val_loss: 1.2753 - val_mae: 1.0020\n",
      "Epoch 2637/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9552 - mae: 1.2394 - val_loss: 1.2748 - val_mae: 1.0019\n",
      "Epoch 2638/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9542 - mae: 1.2392 - val_loss: 1.2709 - val_mae: 1.0010\n",
      "Epoch 2639/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9531 - mae: 1.2388 - val_loss: 1.2689 - val_mae: 1.0006\n",
      "Epoch 2640/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9520 - mae: 1.2385 - val_loss: 1.2672 - val_mae: 1.0002\n",
      "Epoch 2641/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9510 - mae: 1.2383 - val_loss: 1.2635 - val_mae: 0.9994\n",
      "Epoch 2642/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9499 - mae: 1.2378 - val_loss: 1.2631 - val_mae: 0.9992\n",
      "Epoch 2643/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9489 - mae: 1.2377 - val_loss: 1.2590 - val_mae: 0.9983\n",
      "Epoch 2644/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9479 - mae: 1.2371 - val_loss: 1.2589 - val_mae: 0.9983\n",
      "Epoch 2645/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9468 - mae: 1.2370 - val_loss: 1.2562 - val_mae: 0.9977\n",
      "Epoch 2646/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9457 - mae: 1.2365 - val_loss: 1.2544 - val_mae: 0.9972\n",
      "Epoch 2647/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9447 - mae: 1.2361 - val_loss: 1.2539 - val_mae: 0.9971\n",
      "Epoch 2648/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9436 - mae: 1.2359 - val_loss: 1.2509 - val_mae: 0.9964\n",
      "Epoch 2649/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9426 - mae: 1.2353 - val_loss: 1.2509 - val_mae: 0.9963\n",
      "Epoch 2650/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9416 - mae: 1.2351 - val_loss: 1.2477 - val_mae: 0.9956\n",
      "Epoch 2651/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9405 - mae: 1.2347 - val_loss: 1.2455 - val_mae: 0.9951\n",
      "Epoch 2652/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9395 - mae: 1.2344 - val_loss: 1.2432 - val_mae: 0.9946\n",
      "Epoch 2653/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9385 - mae: 1.2341 - val_loss: 1.2407 - val_mae: 0.9940\n",
      "Epoch 2654/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9374 - mae: 1.2338 - val_loss: 1.2393 - val_mae: 0.9937\n",
      "Epoch 2655/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9364 - mae: 1.2335 - val_loss: 1.2366 - val_mae: 0.9930\n",
      "Epoch 2656/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9354 - mae: 1.2331 - val_loss: 1.2357 - val_mae: 0.9928\n",
      "Epoch 2657/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9343 - mae: 1.2329 - val_loss: 1.2331 - val_mae: 0.9922\n",
      "Epoch 2658/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9333 - mae: 1.2324 - val_loss: 1.2316 - val_mae: 0.9918\n",
      "Epoch 2659/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9323 - mae: 1.2321 - val_loss: 1.2300 - val_mae: 0.9914\n",
      "Epoch 2660/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9312 - mae: 1.2318 - val_loss: 1.2282 - val_mae: 0.9909\n",
      "Epoch 2661/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9302 - mae: 1.2313 - val_loss: 1.2270 - val_mae: 0.9906\n",
      "Epoch 2662/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9292 - mae: 1.2310 - val_loss: 1.2254 - val_mae: 0.9902\n",
      "Epoch 2663/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9282 - mae: 1.2307 - val_loss: 1.2222 - val_mae: 0.9894\n",
      "Epoch 2664/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9271 - mae: 1.2303 - val_loss: 1.2205 - val_mae: 0.9890\n",
      "Epoch 2665/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9261 - mae: 1.2301 - val_loss: 1.2177 - val_mae: 0.9883\n",
      "Epoch 2666/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9251 - mae: 1.2297 - val_loss: 1.2163 - val_mae: 0.9880\n",
      "Epoch 2667/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9241 - mae: 1.2295 - val_loss: 1.2144 - val_mae: 0.9875\n",
      "Epoch 2668/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9231 - mae: 1.2291 - val_loss: 1.2125 - val_mae: 0.9870\n",
      "Epoch 2669/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9221 - mae: 1.2287 - val_loss: 1.2116 - val_mae: 0.9868\n",
      "Epoch 2670/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9211 - mae: 1.2285 - val_loss: 1.2091 - val_mae: 0.9862\n",
      "Epoch 2671/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9200 - mae: 1.2280 - val_loss: 1.2082 - val_mae: 0.9859\n",
      "Epoch 2672/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9190 - mae: 1.2277 - val_loss: 1.2066 - val_mae: 0.9855\n",
      "Epoch 2673/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9180 - mae: 1.2273 - val_loss: 1.2047 - val_mae: 0.9850\n",
      "Epoch 2674/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9171 - mae: 1.2269 - val_loss: 1.2040 - val_mae: 0.9848\n",
      "Epoch 2675/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9160 - mae: 1.2267 - val_loss: 1.2007 - val_mae: 0.9840\n",
      "Epoch 2676/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9150 - mae: 1.2262 - val_loss: 1.1994 - val_mae: 0.9837\n",
      "Epoch 2677/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9140 - mae: 1.2260 - val_loss: 1.1971 - val_mae: 0.9831\n",
      "Epoch 2678/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9130 - mae: 1.2257 - val_loss: 1.1955 - val_mae: 0.9826\n",
      "Epoch 2679/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9120 - mae: 1.2254 - val_loss: 1.1936 - val_mae: 0.9822\n",
      "Epoch 2680/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9110 - mae: 1.2250 - val_loss: 1.1918 - val_mae: 0.9817\n",
      "Epoch 2681/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9100 - mae: 1.2247 - val_loss: 1.1900 - val_mae: 0.9812\n",
      "Epoch 2682/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9090 - mae: 1.2243 - val_loss: 1.1888 - val_mae: 0.9809\n",
      "Epoch 2683/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9080 - mae: 1.2240 - val_loss: 1.1873 - val_mae: 0.9805\n",
      "Epoch 2684/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9070 - mae: 1.2236 - val_loss: 1.1860 - val_mae: 0.9801\n",
      "Epoch 2685/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9060 - mae: 1.2233 - val_loss: 1.1833 - val_mae: 0.9794\n",
      "Epoch 2686/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9050 - mae: 1.2228 - val_loss: 1.1832 - val_mae: 0.9793\n",
      "Epoch 2687/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9040 - mae: 1.2227 - val_loss: 1.1801 - val_mae: 0.9785\n",
      "Epoch 2688/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9030 - mae: 1.2222 - val_loss: 1.1780 - val_mae: 0.9779\n",
      "Epoch 2689/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9020 - mae: 1.2219 - val_loss: 1.1773 - val_mae: 0.9777\n",
      "Epoch 2690/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9011 - mae: 1.2218 - val_loss: 1.1739 - val_mae: 0.9768\n",
      "Epoch 2691/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9001 - mae: 1.2212 - val_loss: 1.1744 - val_mae: 0.9770\n",
      "Epoch 2692/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8991 - mae: 1.2211 - val_loss: 1.1709 - val_mae: 0.9760\n",
      "Epoch 2693/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8981 - mae: 1.2205 - val_loss: 1.1715 - val_mae: 0.9762\n",
      "Epoch 2694/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8971 - mae: 1.2204 - val_loss: 1.1687 - val_mae: 0.9754\n",
      "Epoch 2695/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8961 - mae: 1.2199 - val_loss: 1.1672 - val_mae: 0.9749\n",
      "Epoch 2696/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8951 - mae: 1.2195 - val_loss: 1.1667 - val_mae: 0.9748\n",
      "Epoch 2697/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8942 - mae: 1.2194 - val_loss: 1.1631 - val_mae: 0.9738\n",
      "Epoch 2698/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8932 - mae: 1.2187 - val_loss: 1.1643 - val_mae: 0.9741\n",
      "Epoch 2699/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8922 - mae: 1.2189 - val_loss: 1.1585 - val_mae: 0.9725\n",
      "Epoch 2700/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8913 - mae: 1.2182 - val_loss: 1.1610 - val_mae: 0.9732\n",
      "Epoch 2701/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8903 - mae: 1.2183 - val_loss: 1.1556 - val_mae: 0.9716\n",
      "Epoch 2702/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8893 - mae: 1.2176 - val_loss: 1.1576 - val_mae: 0.9722\n",
      "Epoch 2703/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8883 - mae: 1.2175 - val_loss: 1.1538 - val_mae: 0.9711\n",
      "Epoch 2704/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8874 - mae: 1.2170 - val_loss: 1.1539 - val_mae: 0.9712\n",
      "Epoch 2705/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8863 - mae: 1.2167 - val_loss: 1.1505 - val_mae: 0.9701\n",
      "Epoch 2706/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.8854 - mae: 1.2165 - val_loss: 1.1507 - val_mae: 0.9702\n",
      "Epoch 2707/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8844 - mae: 1.2162 - val_loss: 1.1480 - val_mae: 0.9694\n",
      "Epoch 2708/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8835 - mae: 1.2159 - val_loss: 1.1474 - val_mae: 0.9693\n",
      "Epoch 2709/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8825 - mae: 1.2156 - val_loss: 1.1445 - val_mae: 0.9684\n",
      "Epoch 2710/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8816 - mae: 1.2154 - val_loss: 1.1444 - val_mae: 0.9684\n",
      "Epoch 2711/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8806 - mae: 1.2151 - val_loss: 1.1415 - val_mae: 0.9675\n",
      "Epoch 2712/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8796 - mae: 1.2148 - val_loss: 1.1413 - val_mae: 0.9675\n",
      "Epoch 2713/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8787 - mae: 1.2145 - val_loss: 1.1390 - val_mae: 0.9667\n",
      "Epoch 2714/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8777 - mae: 1.2142 - val_loss: 1.1386 - val_mae: 0.9667\n",
      "Epoch 2715/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8767 - mae: 1.2140 - val_loss: 1.1354 - val_mae: 0.9656\n",
      "Epoch 2716/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.8758 - mae: 1.2137 - val_loss: 1.1348 - val_mae: 0.9655\n",
      "Epoch 2717/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8749 - mae: 1.2135 - val_loss: 1.1323 - val_mae: 0.9647\n",
      "Epoch 2718/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8739 - mae: 1.2132 - val_loss: 1.1314 - val_mae: 0.9644\n",
      "Epoch 2719/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8730 - mae: 1.2129 - val_loss: 1.1295 - val_mae: 0.9638\n",
      "Epoch 2720/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8720 - mae: 1.2127 - val_loss: 1.1283 - val_mae: 0.9634\n",
      "Epoch 2721/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8711 - mae: 1.2124 - val_loss: 1.1271 - val_mae: 0.9631\n",
      "Epoch 2722/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8701 - mae: 1.2121 - val_loss: 1.1257 - val_mae: 0.9626\n",
      "Epoch 2723/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8691 - mae: 1.2118 - val_loss: 1.1250 - val_mae: 0.9624\n",
      "Epoch 2724/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8682 - mae: 1.2114 - val_loss: 1.1235 - val_mae: 0.9619\n",
      "Epoch 2725/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8672 - mae: 1.2112 - val_loss: 1.1214 - val_mae: 0.9613\n",
      "Epoch 2726/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8663 - mae: 1.2109 - val_loss: 1.1202 - val_mae: 0.9609\n",
      "Epoch 2727/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8654 - mae: 1.2107 - val_loss: 1.1182 - val_mae: 0.9602\n",
      "Epoch 2728/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8645 - mae: 1.2104 - val_loss: 1.1174 - val_mae: 0.9600\n",
      "Epoch 2729/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8635 - mae: 1.2101 - val_loss: 1.1155 - val_mae: 0.9593\n",
      "Epoch 2730/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8626 - mae: 1.2098 - val_loss: 45.2775 - val_mae: 6.6558\n",
      "Epoch 2731/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 48.6914 - mae: 6.8456 - val_loss: 665.2893 - val_mae: 25.7693\n",
      "Epoch 2732/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 660.5856 - mae: 25.6622 - val_loss: 2141.7153 - val_mae: 46.2689\n",
      "Epoch 2733/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2156.4089 - mae: 46.4194 - val_loss: 3087.9199 - val_mae: 55.5567\n",
      "Epoch 2734/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3058.9570 - mae: 55.2875 - val_loss: 1725.4961 - val_mae: 41.5282\n",
      "Epoch 2735/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1747.0605 - mae: 41.7774 - val_loss: 55.3374 - val_mae: 7.3633\n",
      "Epoch 2736/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 49.6324 - mae: 6.9022 - val_loss: 850.1064 - val_mae: 29.1352\n",
      "Epoch 2737/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 815.5646 - mae: 28.5201 - val_loss: 1830.8292 - val_mae: 42.7776\n",
      "Epoch 2738/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1890.3444 - mae: 43.4565 - val_loss: 836.8834 - val_mae: 28.9068\n",
      "Epoch 2739/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 783.5701 - mae: 27.9510 - val_loss: 82.7593 - val_mae: 9.0332\n",
      "Epoch 2740/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 66.6383 - mae: 8.0244 - val_loss: 1024.9594 - val_mae: 32.0001\n",
      "Epoch 2741/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1089.8141 - mae: 32.9809 - val_loss: 631.0958 - val_mae: 25.0955\n",
      "Epoch 2742/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 577.5127 - mae: 23.9817 - val_loss: 83.6001 - val_mae: 9.0770\n",
      "Epoch 2743/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 66.5337 - mae: 8.0155 - val_loss: 715.2553 - val_mae: 26.7254\n",
      "Epoch 2744/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 771.9250 - mae: 27.7454 - val_loss: 228.7631 - val_mae: 15.0837\n",
      "Epoch 2745/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 195.9497 - mae: 13.9134 - val_loss: 253.0450 - val_mae: 15.8680\n",
      "Epoch 2746/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 217.3915 - mae: 14.6629 - val_loss: 456.8526 - val_mae: 21.3501\n",
      "Epoch 2747/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 508.0115 - mae: 22.4900 - val_loss: 9.7747 - val_mae: 2.9351\n",
      "Epoch 2748/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.2698 - mae: 1.9441 - val_loss: 413.1027 - val_mae: 20.2937\n",
      "Epoch 2749/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 363.6122 - mae: 19.0037 - val_loss: 139.2661 - val_mae: 11.7555\n",
      "Epoch 2750/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 170.6755 - mae: 12.9759 - val_loss: 68.6638 - val_mae: 8.2200\n",
      "Epoch 2751/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 91.7934 - mae: 9.4585 - val_loss: 331.7138 - val_mae: 18.1783\n",
      "Epoch 2752/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 287.0211 - mae: 16.8681 - val_loss: 1.5365 - val_mae: 1.0536\n",
      "Epoch 2753/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.8079 - mae: 1.3763 - val_loss: 184.2925 - val_mae: 13.5359\n",
      "Epoch 2754/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 220.3199 - mae: 14.7651 - val_loss: 87.7455 - val_mae: 9.3021\n",
      "Epoch 2755/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 66.7224 - mae: 8.0176 - val_loss: 112.7770 - val_mae: 10.5616\n",
      "Epoch 2756/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 88.5687 - mae: 9.2802 - val_loss: 109.1590 - val_mae: 10.3950\n",
      "Epoch 2757/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 137.2237 - mae: 11.6146 - val_loss: 4.0234 - val_mae: 1.6918\n",
      "Epoch 2758/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10.9312 - mae: 2.9259 - val_loss: 170.1396 - val_mae: 12.9952\n",
      "Epoch 2759/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 140.1659 - mae: 11.7351 - val_loss: 17.7028 - val_mae: 4.0640\n",
      "Epoch 2760/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 29.7813 - mae: 5.2380 - val_loss: 5.7293 - val_mae: 2.1249\n",
      "Epoch 2761/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 13.2047 - mae: 3.2969 - val_loss: 26.1259 - val_mae: 4.9892\n",
      "Epoch 2762/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 16.7557 - mae: 3.7906 - val_loss: 7.5252 - val_mae: 2.5103\n",
      "Epoch 2763/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.1314 - mae: 1.7512 - val_loss: 8.9865 - val_mae: 2.7950\n",
      "Epoch 2764/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 18.0039 - mae: 3.9590 - val_loss: 3.6831 - val_mae: 1.6177\n",
      "Epoch 2765/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.5212 - mae: 1.4017 - val_loss: 21.7200 - val_mae: 4.5248\n",
      "Epoch 2766/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 13.7996 - mae: 3.3825 - val_loss: 1.5684 - val_mae: 1.0239\n",
      "Epoch 2767/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.3340 - mae: 1.7910 - val_loss: 2.7505 - val_mae: 1.2677\n",
      "Epoch 2768/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.8656 - mae: 2.3569 - val_loss: 14.0347 - val_mae: 3.5769\n",
      "Epoch 2769/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.4912 - mae: 2.5001 - val_loss: 6.1426 - val_mae: 2.2167\n",
      "Epoch 2770/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.6142 - mae: 1.6405 - val_loss: 3.8348 - val_mae: 1.6253\n",
      "Epoch 2771/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.4797 - mae: 2.6822 - val_loss: 2.3254 - val_mae: 1.3327\n",
      "Epoch 2772/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2944 - mae: 1.3123 - val_loss: 13.0073 - val_mae: 3.4288\n",
      "Epoch 2773/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.0743 - mae: 2.4260 - val_loss: 1.2248 - val_mae: 0.9724\n",
      "Epoch 2774/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.1575 - mae: 1.4379 - val_loss: 1.8881 - val_mae: 1.0565\n",
      "Epoch 2775/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.5292 - mae: 1.8433 - val_loss: 7.5252 - val_mae: 2.5043\n",
      "Epoch 2776/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.6226 - mae: 1.8075 - val_loss: 5.2017 - val_mae: 1.9873\n",
      "Epoch 2777/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.3328 - mae: 1.5681 - val_loss: 1.9425 - val_mae: 1.0673\n",
      "Epoch 2778/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.4136 - mae: 1.8279 - val_loss: 1.6881 - val_mae: 1.1321\n",
      "Epoch 2779/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3108 - mae: 1.3062 - val_loss: 8.0171 - val_mae: 2.5973\n",
      "Epoch 2780/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.1188 - mae: 1.8728 - val_loss: 1.4650 - val_mae: 1.0343\n",
      "Epoch 2781/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4135 - mae: 1.3224 - val_loss: 1.4946 - val_mae: 1.0167\n",
      "Epoch 2782/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.0942 - mae: 1.5882 - val_loss: 4.3544 - val_mae: 1.7713\n",
      "Epoch 2783/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0418 - mae: 1.5034 - val_loss: 4.2320 - val_mae: 1.7442\n",
      "Epoch 2784/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9995 - mae: 1.4942 - val_loss: 1.3646 - val_mae: 0.9992\n",
      "Epoch 2785/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.5441 - mae: 1.5000 - val_loss: 1.4760 - val_mae: 1.0389\n",
      "Epoch 2786/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3353 - mae: 1.3096 - val_loss: 5.1609 - val_mae: 1.9691\n",
      "Epoch 2787/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5834 - mae: 1.5886 - val_loss: 1.6910 - val_mae: 1.1358\n",
      "Epoch 2788/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2239 - mae: 1.3012 - val_loss: 1.3180 - val_mae: 0.9900\n",
      "Epoch 2789/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2066 - mae: 1.4559 - val_loss: 2.9028 - val_mae: 1.4880\n",
      "Epoch 2790/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4604 - mae: 1.3929 - val_loss: 3.4056 - val_mae: 1.5912\n",
      "Epoch 2791/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.6925 - mae: 1.4406 - val_loss: 1.2753 - val_mae: 0.9807\n",
      "Epoch 2792/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.7328 - mae: 1.3893 - val_loss: 1.4315 - val_mae: 1.0244\n",
      "Epoch 2793/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3132 - mae: 1.3077 - val_loss: 3.6151 - val_mae: 1.6312\n",
      "Epoch 2794/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.8246 - mae: 1.4612 - val_loss: 1.8140 - val_mae: 1.1844\n",
      "Epoch 2795/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1877 - mae: 1.3056 - val_loss: 1.2878 - val_mae: 0.9864\n",
      "Epoch 2796/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.7008 - mae: 1.3847 - val_loss: 2.2807 - val_mae: 1.3348\n",
      "Epoch 2797/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2623 - mae: 1.3435 - val_loss: 2.8442 - val_mae: 1.4751\n",
      "Epoch 2798/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4688 - mae: 1.3922 - val_loss: 1.3544 - val_mae: 1.0171\n",
      "Epoch 2799/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3950 - mae: 1.3209 - val_loss: 1.4619 - val_mae: 1.0364\n",
      "Epoch 2800/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2669 - mae: 1.3020 - val_loss: 2.8300 - val_mae: 1.4717\n",
      "Epoch 2801/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.4635 - mae: 1.3904 - val_loss: 1.8714 - val_mae: 1.2031\n",
      "Epoch 2802/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1768 - mae: 1.3073 - val_loss: 1.3383 - val_mae: 1.0141\n",
      "Epoch 2803/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4270 - mae: 1.3290 - val_loss: 2.0271 - val_mae: 1.2575\n",
      "Epoch 2804/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1931 - mae: 1.3158 - val_loss: 2.4958 - val_mae: 1.3921\n",
      "Epoch 2805/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3229 - mae: 1.3608 - val_loss: 1.4662 - val_mae: 1.0381\n",
      "Epoch 2806/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2535 - mae: 1.2984 - val_loss: 1.5204 - val_mae: 1.0552\n",
      "Epoch 2807/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2193 - mae: 1.2959 - val_loss: 2.4335 - val_mae: 1.3763\n",
      "Epoch 2808/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2929 - mae: 1.3528 - val_loss: 1.8935 - val_mae: 1.2118\n",
      "Epoch 2809/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1644 - mae: 1.3042 - val_loss: 1.4282 - val_mae: 1.0324\n",
      "Epoch 2810/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2822 - mae: 1.2993 - val_loss: 1.9321 - val_mae: 1.2257\n",
      "Epoch 2811/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1637 - mae: 1.3043 - val_loss: 2.2845 - val_mae: 1.3359\n",
      "Epoch 2812/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2338 - mae: 1.3351 - val_loss: 1.5721 - val_mae: 1.0729\n",
      "Epoch 2813/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1898 - mae: 1.2922 - val_loss: 1.5946 - val_mae: 1.0846\n",
      "Epoch 2814/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1809 - mae: 1.2916 - val_loss: 2.2275 - val_mae: 1.3196\n",
      "Epoch 2815/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2095 - mae: 1.3264 - val_loss: 1.8996 - val_mae: 1.2141\n",
      "Epoch 2816/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1509 - mae: 1.2992 - val_loss: 1.5271 - val_mae: 1.0578\n",
      "Epoch 2817/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2061 - mae: 1.2902 - val_loss: 1.8954 - val_mae: 1.2126\n",
      "Epoch 2818/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1479 - mae: 1.2983 - val_loss: 2.1402 - val_mae: 1.2936\n",
      "Epoch 2819/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1831 - mae: 1.3155 - val_loss: 1.6462 - val_mae: 1.1102\n",
      "Epoch 2820/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1593 - mae: 1.2894 - val_loss: 1.6516 - val_mae: 1.1128\n",
      "Epoch 2821/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1564 - mae: 1.2892 - val_loss: 2.0801 - val_mae: 1.2748\n",
      "Epoch 2822/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1683 - mae: 1.3087 - val_loss: 1.8654 - val_mae: 1.2015\n",
      "Epoch 2823/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1399 - mae: 1.2961 - val_loss: 1.5922 - val_mae: 1.0835\n",
      "Epoch 2824/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1656 - mae: 1.2882 - val_loss: 1.8516 - val_mae: 1.1964\n",
      "Epoch 2825/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1368 - mae: 1.2954 - val_loss: 2.0062 - val_mae: 1.2508\n",
      "Epoch 2826/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.1529 - mae: 1.3018 - val_loss: 1.6711 - val_mae: 1.1219\n",
      "Epoch 2827/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1410 - mae: 1.2877 - val_loss: 1.6754 - val_mae: 1.1238\n",
      "Epoch 2828/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1384 - mae: 1.2874 - val_loss: 1.9589 - val_mae: 1.2347\n",
      "Epoch 2829/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1439 - mae: 1.3000 - val_loss: 1.8105 - val_mae: 1.1805\n",
      "Epoch 2830/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.1291 - mae: 1.2937 - val_loss: 1.6234 - val_mae: 1.0993\n",
      "Epoch 2831/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1409 - mae: 1.2866 - val_loss: 1.8058 - val_mae: 1.1786\n",
      "Epoch 2832/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1265 - mae: 1.2935 - val_loss: 1.8958 - val_mae: 1.2124\n",
      "Epoch 2833/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1330 - mae: 1.2975 - val_loss: 1.6700 - val_mae: 1.1213\n",
      "Epoch 2834/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1274 - mae: 1.2869 - val_loss: 1.6801 - val_mae: 1.1259\n",
      "Epoch 2835/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1245 - mae: 1.2875 - val_loss: 1.8653 - val_mae: 1.2010\n",
      "Epoch 2836/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1272 - mae: 1.2963 - val_loss: 1.7574 - val_mae: 1.1590\n",
      "Epoch 2837/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1190 - mae: 1.2914 - val_loss: 1.6353 - val_mae: 1.1051\n",
      "Epoch 2838/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1240 - mae: 1.2851 - val_loss: 1.7654 - val_mae: 1.1621\n",
      "Epoch 2839/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1167 - mae: 1.2918 - val_loss: 1.8124 - val_mae: 1.1807\n",
      "Epoch 2840/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1186 - mae: 1.2940 - val_loss: 1.6597 - val_mae: 1.1165\n",
      "Epoch 2841/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1159 - mae: 1.2864 - val_loss: 1.6763 - val_mae: 1.1240\n",
      "Epoch 2842/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1132 - mae: 1.2873 - val_loss: 1.7961 - val_mae: 1.1741\n",
      "Epoch 2843/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.1144 - mae: 1.2931 - val_loss: 1.7143 - val_mae: 1.1405\n",
      "Epoch 2844/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1095 - mae: 1.2891 - val_loss: 1.6381 - val_mae: 1.1063\n",
      "Epoch 2845/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1112 - mae: 1.2850 - val_loss: 1.7320 - val_mae: 1.1479\n",
      "Epoch 2846/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1074 - mae: 1.2898 - val_loss: 1.7514 - val_mae: 1.1558\n",
      "Epoch 2847/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1071 - mae: 1.2907 - val_loss: 1.6480 - val_mae: 1.1108\n",
      "Epoch 2848/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.1057 - mae: 1.2853 - val_loss: 1.6689 - val_mae: 1.1203\n",
      "Epoch 2849/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1033 - mae: 1.2863 - val_loss: 1.7447 - val_mae: 1.1527\n",
      "Epoch 2850/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1035 - mae: 1.2900 - val_loss: 1.6812 - val_mae: 1.1256\n",
      "Epoch 2851/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1004 - mae: 1.2867 - val_loss: 1.6365 - val_mae: 1.1052\n",
      "Epoch 2852/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1004 - mae: 1.2841 - val_loss: 1.7045 - val_mae: 1.1355\n",
      "Epoch 2853/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0981 - mae: 1.2875 - val_loss: 1.7068 - val_mae: 1.1364\n",
      "Epoch 2854/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0970 - mae: 1.2874 - val_loss: 1.6371 - val_mae: 1.1053\n",
      "Epoch 2855/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0960 - mae: 1.2836 - val_loss: 1.6600 - val_mae: 1.1157\n",
      "Epoch 2856/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0939 - mae: 1.2847 - val_loss: 1.7057 - val_mae: 1.1357\n",
      "Epoch 2857/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0934 - mae: 1.2868 - val_loss: 1.6562 - val_mae: 1.1138\n",
      "Epoch 2858/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0913 - mae: 1.2840 - val_loss: 1.6327 - val_mae: 1.1030\n",
      "Epoch 2859/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0905 - mae: 1.2825 - val_loss: 1.6811 - val_mae: 1.1247\n",
      "Epoch 2860/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0889 - mae: 1.2849 - val_loss: 1.6734 - val_mae: 1.1212\n",
      "Epoch 2861/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0875 - mae: 1.2842 - val_loss: 1.6274 - val_mae: 1.1003\n",
      "Epoch 2862/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0865 - mae: 1.2816 - val_loss: 1.6497 - val_mae: 1.1105\n",
      "Epoch 2863/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0847 - mae: 1.2825 - val_loss: 1.6751 - val_mae: 1.1216\n",
      "Epoch 2864/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0839 - mae: 1.2836 - val_loss: 1.6367 - val_mae: 1.1043\n",
      "Epoch 2865/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0822 - mae: 1.2813 - val_loss: 1.6270 - val_mae: 1.0998\n",
      "Epoch 2866/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0811 - mae: 1.2805 - val_loss: 1.6604 - val_mae: 1.1148\n",
      "Epoch 2867/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0798 - mae: 1.2820 - val_loss: 1.6476 - val_mae: 1.1090\n",
      "Epoch 2868/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0783 - mae: 1.2811 - val_loss: 1.6185 - val_mae: 1.0956\n",
      "Epoch 2869/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0772 - mae: 1.2793 - val_loss: 1.6385 - val_mae: 1.1047\n",
      "Epoch 2870/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0757 - mae: 1.2801 - val_loss: 1.6499 - val_mae: 1.1097\n",
      "Epoch 2871/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0746 - mae: 1.2804 - val_loss: 1.6210 - val_mae: 1.0965\n",
      "Epoch 2872/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0732 - mae: 1.2786 - val_loss: 1.6197 - val_mae: 1.0958\n",
      "Epoch 2873/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0719 - mae: 1.2783 - val_loss: 1.6411 - val_mae: 1.1054\n",
      "Epoch 2874/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0707 - mae: 1.2791 - val_loss: 1.6264 - val_mae: 1.0987\n",
      "Epoch 2875/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0693 - mae: 1.2781 - val_loss: 1.6092 - val_mae: 1.0906\n",
      "Epoch 2876/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0682 - mae: 1.2769 - val_loss: 1.6253 - val_mae: 1.0980\n",
      "Epoch 2877/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0668 - mae: 1.2775 - val_loss: 1.6275 - val_mae: 1.0989\n",
      "Epoch 2878/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0655 - mae: 1.2773 - val_loss: 1.6066 - val_mae: 1.0892\n",
      "Epoch 2879/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0642 - mae: 1.2759 - val_loss: 1.6099 - val_mae: 1.0906\n",
      "Epoch 2880/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0629 - mae: 1.2758 - val_loss: 1.6223 - val_mae: 1.0962\n",
      "Epoch 2881/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0617 - mae: 1.2761 - val_loss: 1.6085 - val_mae: 1.0898\n",
      "Epoch 2882/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0603 - mae: 1.2750 - val_loss: 1.6000 - val_mae: 1.0858\n",
      "Epoch 2883/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0591 - mae: 1.2742 - val_loss: 1.6124 - val_mae: 1.0914\n",
      "Epoch 2884/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0579 - mae: 1.2745 - val_loss: 1.6094 - val_mae: 1.0899\n",
      "Epoch 2885/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0567 - mae: 1.2742 - val_loss: 1.5936 - val_mae: 1.0825\n",
      "Epoch 2886/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0554 - mae: 1.2732 - val_loss: 1.5961 - val_mae: 1.0835\n",
      "Epoch 2887/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0540 - mae: 1.2733 - val_loss: 1.5994 - val_mae: 1.0850\n",
      "Epoch 2888/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0528 - mae: 1.2734 - val_loss: 1.5864 - val_mae: 1.0788\n",
      "Epoch 2889/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0516 - mae: 1.2726 - val_loss: 1.5815 - val_mae: 1.0764\n",
      "Epoch 2890/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0503 - mae: 1.2722 - val_loss: 1.5878 - val_mae: 1.0793\n",
      "Epoch 2891/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0490 - mae: 1.2724 - val_loss: 1.5816 - val_mae: 1.0763\n",
      "Epoch 2892/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0478 - mae: 1.2719 - val_loss: 1.5723 - val_mae: 1.0718\n",
      "Epoch 2893/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0465 - mae: 1.2711 - val_loss: 1.5764 - val_mae: 1.0736\n",
      "Epoch 2894/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0453 - mae: 1.2711 - val_loss: 1.5769 - val_mae: 1.0738\n",
      "Epoch 2895/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0440 - mae: 1.2709 - val_loss: 1.5677 - val_mae: 1.0693\n",
      "Epoch 2896/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0428 - mae: 1.2701 - val_loss: 1.5668 - val_mae: 1.0688\n",
      "Epoch 2897/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0415 - mae: 1.2698 - val_loss: 1.5688 - val_mae: 1.0696\n",
      "Epoch 2898/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0403 - mae: 1.2699 - val_loss: 1.5604 - val_mae: 1.0655\n",
      "Epoch 2899/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0390 - mae: 1.2693 - val_loss: 1.5552 - val_mae: 1.0629\n",
      "Epoch 2900/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0378 - mae: 1.2688 - val_loss: 1.5582 - val_mae: 1.0643\n",
      "Epoch 2901/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0365 - mae: 1.2688 - val_loss: 1.5547 - val_mae: 1.0625\n",
      "Epoch 2902/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0353 - mae: 1.2684 - val_loss: 1.5478 - val_mae: 1.0591\n",
      "Epoch 2903/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0341 - mae: 1.2678 - val_loss: 1.5487 - val_mae: 1.0594\n",
      "Epoch 2904/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0328 - mae: 1.2677 - val_loss: 1.5472 - val_mae: 1.0586\n",
      "Epoch 2905/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0316 - mae: 1.2675 - val_loss: 1.5387 - val_mae: 1.0547\n",
      "Epoch 2906/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0304 - mae: 1.2670 - val_loss: 1.5367 - val_mae: 1.0540\n",
      "Epoch 2907/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0292 - mae: 1.2667 - val_loss: 1.5383 - val_mae: 1.0543\n",
      "Epoch 2908/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0279 - mae: 1.2666 - val_loss: 1.5328 - val_mae: 1.0525\n",
      "Epoch 2909/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0267 - mae: 1.2661 - val_loss: 1.5285 - val_mae: 1.0511\n",
      "Epoch 2910/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0255 - mae: 1.2655 - val_loss: 1.5304 - val_mae: 1.0515\n",
      "Epoch 2911/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0242 - mae: 1.2654 - val_loss: 1.5281 - val_mae: 1.0507\n",
      "Epoch 2912/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0230 - mae: 1.2650 - val_loss: 1.5214 - val_mae: 1.0485\n",
      "Epoch 2913/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0218 - mae: 1.2644 - val_loss: 1.5208 - val_mae: 1.0482\n",
      "Epoch 2914/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0205 - mae: 1.2643 - val_loss: 1.5201 - val_mae: 1.0478\n",
      "Epoch 2915/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0193 - mae: 1.2641 - val_loss: 1.5143 - val_mae: 1.0459\n",
      "Epoch 2916/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0181 - mae: 1.2635 - val_loss: 1.5121 - val_mae: 1.0451\n",
      "Epoch 2917/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0169 - mae: 1.2631 - val_loss: 1.5127 - val_mae: 1.0452\n",
      "Epoch 2918/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0157 - mae: 1.2630 - val_loss: 1.5076 - val_mae: 1.0435\n",
      "Epoch 2919/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.0145 - mae: 1.2625 - val_loss: 1.5036 - val_mae: 1.0421\n",
      "Epoch 2920/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0132 - mae: 1.2621 - val_loss: 1.5049 - val_mae: 1.0423\n",
      "Epoch 2921/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0120 - mae: 1.2619 - val_loss: 1.5025 - val_mae: 1.0415\n",
      "Epoch 2922/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0108 - mae: 1.2616 - val_loss: 1.4962 - val_mae: 1.0394\n",
      "Epoch 2923/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0096 - mae: 1.2611 - val_loss: 1.4941 - val_mae: 1.0386\n",
      "Epoch 2924/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0084 - mae: 1.2608 - val_loss: 1.4939 - val_mae: 1.0384\n",
      "Epoch 2925/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0072 - mae: 1.2606 - val_loss: 1.4896 - val_mae: 1.0369\n",
      "Epoch 2926/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.0060 - mae: 1.2602 - val_loss: 1.4866 - val_mae: 1.0359\n",
      "Epoch 2927/3000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.0048 - mae: 1.2597 - val_loss: 1.4872 - val_mae: 1.0359\n",
      "Epoch 2928/3000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0035 - mae: 1.2594 - val_loss: 1.4852 - val_mae: 1.0351\n",
      "Epoch 2929/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.0024 - mae: 1.2590 - val_loss: 1.4818 - val_mae: 1.0339\n",
      "Epoch 2930/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.0012 - mae: 1.2586 - val_loss: 1.4802 - val_mae: 1.0333\n",
      "Epoch 2931/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.9999 - mae: 1.2583 - val_loss: 1.4774 - val_mae: 1.0323\n",
      "Epoch 2932/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.9987 - mae: 1.2581 - val_loss: 1.4726 - val_mae: 1.0306\n",
      "Epoch 2933/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9976 - mae: 1.2577 - val_loss: 1.4705 - val_mae: 1.0298\n",
      "Epoch 2934/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9964 - mae: 1.2574 - val_loss: 1.4696 - val_mae: 1.0294\n",
      "Epoch 2935/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9952 - mae: 1.2571 - val_loss: 1.4663 - val_mae: 1.0282\n",
      "Epoch 2936/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9940 - mae: 1.2567 - val_loss: 1.4639 - val_mae: 1.0273\n",
      "Epoch 2937/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9927 - mae: 1.2562 - val_loss: 1.4638 - val_mae: 1.0271\n",
      "Epoch 2938/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9915 - mae: 1.2559 - val_loss: 1.4621 - val_mae: 1.0264\n",
      "Epoch 2939/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9904 - mae: 1.2554 - val_loss: 1.4594 - val_mae: 1.0255\n",
      "Epoch 2940/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9892 - mae: 1.2550 - val_loss: 1.4576 - val_mae: 1.0247\n",
      "Epoch 2941/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9880 - mae: 1.2547 - val_loss: 1.4548 - val_mae: 1.0237\n",
      "Epoch 2942/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9867 - mae: 1.2544 - val_loss: 1.4509 - val_mae: 1.0223\n",
      "Epoch 2943/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9856 - mae: 1.2541 - val_loss: 1.4490 - val_mae: 1.0216\n",
      "Epoch 2944/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9843 - mae: 1.2537 - val_loss: 1.4476 - val_mae: 1.0210\n",
      "Epoch 2945/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.9832 - mae: 1.2534 - val_loss: 1.4449 - val_mae: 1.0200\n",
      "Epoch 2946/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9819 - mae: 1.2530 - val_loss: 1.4431 - val_mae: 1.0193\n",
      "Epoch 2947/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9808 - mae: 1.2526 - val_loss: 1.4423 - val_mae: 1.0189\n",
      "Epoch 2948/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.9796 - mae: 1.2523 - val_loss: 1.4388 - val_mae: 1.0180\n",
      "Epoch 2949/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.9784 - mae: 1.2520 - val_loss: 1.4350 - val_mae: 1.0175\n",
      "Epoch 2950/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.9772 - mae: 1.2515 - val_loss: 1.4344 - val_mae: 1.0173\n",
      "Epoch 2951/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.9760 - mae: 1.2513 - val_loss: 1.4330 - val_mae: 1.0170\n",
      "Epoch 2952/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.9748 - mae: 1.2509 - val_loss: 1.4299 - val_mae: 1.0165\n",
      "Epoch 2953/3000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.9737 - mae: 1.2504 - val_loss: 1.4287 - val_mae: 1.0162\n",
      "Epoch 2954/3000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.9725 - mae: 1.2501 - val_loss: 1.4269 - val_mae: 1.0158\n",
      "Epoch 2955/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.9713 - mae: 1.2499 - val_loss: 1.4227 - val_mae: 1.0153\n",
      "Epoch 2956/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9701 - mae: 1.2494 - val_loss: 1.4211 - val_mae: 1.0149\n",
      "Epoch 2957/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9689 - mae: 1.2491 - val_loss: 1.4208 - val_mae: 1.0148\n",
      "Epoch 2958/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9678 - mae: 1.2488 - val_loss: 1.4178 - val_mae: 1.0143\n",
      "Epoch 2959/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9666 - mae: 1.2484 - val_loss: 1.4145 - val_mae: 1.0138\n",
      "Epoch 2960/3000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.9654 - mae: 1.2480 - val_loss: 1.4141 - val_mae: 1.0136\n",
      "Epoch 2961/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.9643 - mae: 1.2478 - val_loss: 1.4114 - val_mae: 1.0132\n",
      "Epoch 2962/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9631 - mae: 1.2474 - val_loss: 1.4081 - val_mae: 1.0127\n",
      "Epoch 2963/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.9619 - mae: 1.2470 - val_loss: 1.4079 - val_mae: 1.0126\n",
      "Epoch 2964/3000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.9607 - mae: 1.2467 - val_loss: 1.4067 - val_mae: 1.0123\n",
      "Epoch 2965/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9596 - mae: 1.2464 - val_loss: 1.4024 - val_mae: 1.0117\n",
      "Epoch 2966/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9584 - mae: 1.2459 - val_loss: 1.4012 - val_mae: 1.0114\n",
      "Epoch 2967/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.9573 - mae: 1.2456 - val_loss: 1.4000 - val_mae: 1.0111\n",
      "Epoch 2968/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9561 - mae: 1.2454 - val_loss: 1.3967 - val_mae: 1.0106\n",
      "Epoch 2969/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9549 - mae: 1.2449 - val_loss: 1.3955 - val_mae: 1.0104\n",
      "Epoch 2970/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9538 - mae: 1.2445 - val_loss: 1.3953 - val_mae: 1.0102\n",
      "Epoch 2971/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9526 - mae: 1.2443 - val_loss: 1.3915 - val_mae: 1.0097\n",
      "Epoch 2972/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9515 - mae: 1.2439 - val_loss: 1.3880 - val_mae: 1.0091\n",
      "Epoch 2973/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9503 - mae: 1.2435 - val_loss: 1.3881 - val_mae: 1.0090\n",
      "Epoch 2974/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9491 - mae: 1.2432 - val_loss: 1.3865 - val_mae: 1.0087\n",
      "Epoch 2975/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9480 - mae: 1.2429 - val_loss: 1.3831 - val_mae: 1.0082\n",
      "Epoch 2976/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9468 - mae: 1.2424 - val_loss: 1.3813 - val_mae: 1.0079\n",
      "Epoch 2977/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9457 - mae: 1.2422 - val_loss: 1.3793 - val_mae: 1.0075\n",
      "Epoch 2978/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9445 - mae: 1.2419 - val_loss: 1.3767 - val_mae: 1.0071\n",
      "Epoch 2979/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9434 - mae: 1.2415 - val_loss: 1.3755 - val_mae: 1.0068\n",
      "Epoch 2980/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9422 - mae: 1.2411 - val_loss: 1.3746 - val_mae: 1.0066\n",
      "Epoch 2981/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9411 - mae: 1.2407 - val_loss: 1.3726 - val_mae: 1.0062\n",
      "Epoch 2982/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9399 - mae: 1.2404 - val_loss: 1.3700 - val_mae: 1.0058\n",
      "Epoch 2983/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9388 - mae: 1.2400 - val_loss: 1.3679 - val_mae: 1.0054\n",
      "Epoch 2984/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9376 - mae: 1.2397 - val_loss: 1.3667 - val_mae: 1.0052\n",
      "Epoch 2985/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9365 - mae: 1.2394 - val_loss: 1.3651 - val_mae: 1.0048\n",
      "Epoch 2986/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9353 - mae: 1.2390 - val_loss: 1.3633 - val_mae: 1.0045\n",
      "Epoch 2987/3000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.9342 - mae: 1.2386 - val_loss: 1.3611 - val_mae: 1.0041\n",
      "Epoch 2988/3000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.9330 - mae: 1.2383 - val_loss: 1.3584 - val_mae: 1.0037\n",
      "Epoch 2989/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9319 - mae: 1.2379 - val_loss: 1.3570 - val_mae: 1.0034\n",
      "Epoch 2990/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9307 - mae: 1.2376 - val_loss: 1.3559 - val_mae: 1.0031\n",
      "Epoch 2991/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9296 - mae: 1.2372 - val_loss: 1.3540 - val_mae: 1.0028\n",
      "Epoch 2992/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9285 - mae: 1.2369 - val_loss: 1.3515 - val_mae: 1.0024\n",
      "Epoch 2993/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9273 - mae: 1.2366 - val_loss: 1.3493 - val_mae: 1.0020\n",
      "Epoch 2994/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9262 - mae: 1.2362 - val_loss: 1.3480 - val_mae: 1.0017\n",
      "Epoch 2995/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9250 - mae: 1.2359 - val_loss: 1.3466 - val_mae: 1.0014\n",
      "Epoch 2996/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9239 - mae: 1.2355 - val_loss: 1.3449 - val_mae: 1.0011\n",
      "Epoch 2997/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9228 - mae: 1.2351 - val_loss: 1.3426 - val_mae: 1.0007\n",
      "Epoch 2998/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9216 - mae: 1.2348 - val_loss: 1.3401 - val_mae: 1.0003\n",
      "Epoch 2999/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9205 - mae: 1.2345 - val_loss: 1.3390 - val_mae: 1.0001\n",
      "Epoch 3000/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9194 - mae: 1.2341 - val_loss: 1.3379 - val_mae: 0.9998\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3379 - mae: 0.9998\n",
      "Pérdida en los datos de prueba:  [1.3378905057907104, 0.9998353123664856]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n",
      "[[20.242994]\n",
      " [17.836763]\n",
      " [18.088707]\n",
      " [17.938267]\n",
      " [17.78779 ]\n",
      " [17.6372  ]\n",
      " [17.486502]\n",
      " [17.335783]\n",
      " [17.184925]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Cargar los datos en un data frame\n",
    "data = pd.read_csv('/Users/User/Desktop/Proyecto-CF/proyecto/data/Consolidado/Datos-Proyeccion-Natalidad.csv')  # Reemplaza 'datos.csv' con el nombre de tu archivo de datos\n",
    "data_test = pd.read_csv('/Users/User/Desktop/Proyecto-CF/proyecto/data/Consolidado/Datos-Proyeccion-Natalidad-test.csv')  # Reemplaza 'datos.csv' con el nombre de tu archivo de datos\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data.iloc[:, 0:4]  # Primeras cuatro columnas como características\n",
    "y = data.iloc[:, 4:]    # Última columna como etiqueta\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "#Crear el modelo de red neuronal\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, input_dim=4, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(300, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "#norm_layer.adapt(X_train)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=3000, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss_eval = model.evaluate(X_test, y_test)\n",
    "print('Pérdida en los datos de prueba: ', loss_eval)\n",
    "#Graficar el historial de entrenamiento\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, mae, 'y', label='Training mae')\n",
    "plt.plot(epochs, val_mae, 'r', label='Validation mae')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mae')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Realizar predicciones en nuevos datos\n",
    "predictions = model.predict(data_test)\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8ef788-0d30-4574-89e1-41047dd57810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-22 17:36:37,570] A new study created in memory with name: no-name-355c2d01-dd76-4862-b819-7778dee08a30\n",
      "[I 2024-01-22 17:40:52,841] Trial 0 finished with value: 1.7038010358810425 and parameters: {'num_hidden_layers': 6, 'num_epochs': 3121}. Best is trial 0 with value: 1.7038010358810425.\n",
      "[I 2024-01-22 17:45:07,852] Trial 1 finished with value: 0.8317801356315613 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3430}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 17:49:39,332] Trial 2 finished with value: 1.938305377960205 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3277}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 17:55:00,526] Trial 3 finished with value: 0.9129006862640381 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4472}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 17:59:03,215] Trial 4 finished with value: 2.01947283744812 and parameters: {'num_hidden_layers': 6, 'num_epochs': 3047}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 18:02:11,764] Trial 5 finished with value: 4.1301116943359375 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2471}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 18:05:17,950] Trial 6 finished with value: 1.651926040649414 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2503}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 18:07:02,440] Trial 7 finished with value: 1.1286542415618896 and parameters: {'num_hidden_layers': 3, 'num_epochs': 1370}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 18:12:53,492] Trial 8 finished with value: 1.8726874589920044 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4790}. Best is trial 1 with value: 0.8317801356315613.\n",
      "[I 2024-01-22 18:16:12,123] Trial 9 finished with value: 0.8166005611419678 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2721}. Best is trial 9 with value: 0.8166005611419678.\n",
      "[I 2024-01-22 18:17:25,175] Trial 10 finished with value: 2.031100273132324 and parameters: {'num_hidden_layers': 1, 'num_epochs': 1011}. Best is trial 9 with value: 0.8166005611419678.\n",
      "[I 2024-01-22 18:22:12,909] Trial 11 finished with value: 0.8055926561355591 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3793}. Best is trial 11 with value: 0.8055926561355591.\n",
      "[I 2024-01-22 18:27:18,006] Trial 12 finished with value: 2.3976407051086426 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3997}. Best is trial 11 with value: 0.8055926561355591.\n",
      "[I 2024-01-22 18:29:46,958] Trial 13 finished with value: 1.3917757272720337 and parameters: {'num_hidden_layers': 4, 'num_epochs': 1934}. Best is trial 11 with value: 0.8055926561355591.\n",
      "[I 2024-01-22 18:35:07,641] Trial 14 finished with value: 0.7999770045280457 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3803}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 18:40:19,850] Trial 15 finished with value: 1.6550939083099365 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3903}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 18:45:18,808] Trial 16 finished with value: 1.6670271158218384 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4088}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 18:51:48,490] Trial 17 finished with value: 1.6815168857574463 and parameters: {'num_hidden_layers': 5, 'num_epochs': 4984}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 18:56:25,333] Trial 18 finished with value: 1.2508368492126465 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3659}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 19:01:46,984] Trial 19 finished with value: 0.8294273018836975 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4386}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 19:06:02,543] Trial 20 finished with value: 0.936499297618866 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3581}. Best is trial 14 with value: 0.7999770045280457.\n",
      "[I 2024-01-22 19:09:13,654] Trial 21 finished with value: 0.7885860800743103 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2636}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:12:20,521] Trial 22 finished with value: 0.9097368717193604 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2547}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:14:56,166] Trial 23 finished with value: 1.4072450399398804 and parameters: {'num_hidden_layers': 4, 'num_epochs': 2027}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:17:32,471] Trial 24 finished with value: 0.9541104435920715 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2068}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:20:58,872] Trial 25 finished with value: 2.6089119911193848 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2881}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:25:29,887] Trial 26 finished with value: 0.828827977180481 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3719}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:30:55,733] Trial 27 finished with value: 1.5240145921707153 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4357}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:36:16,408] Trial 28 finished with value: 1.6720880270004272 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4170}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:40:18,987] Trial 29 finished with value: 1.8168959617614746 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3110}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:44:50,320] Trial 30 finished with value: 1.6502513885498047 and parameters: {'num_hidden_layers': 6, 'num_epochs': 3326}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:48:22,360] Trial 31 finished with value: 0.8515964150428772 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2708}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:51:58,950] Trial 32 finished with value: 0.8408126831054688 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2812}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:54:41,941] Trial 33 finished with value: 0.8684722185134888 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2302}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 19:58:51,193] Trial 34 finished with value: 1.677152395248413 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3351}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:00:57,472] Trial 35 finished with value: 1.2975605726242065 and parameters: {'num_hidden_layers': 2, 'num_epochs': 1722}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:04:40,774] Trial 36 finished with value: 0.826068639755249 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3105}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:09:06,545] Trial 37 finished with value: 0.8939669132232666 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3518}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:11:55,862] Trial 38 finished with value: 1.807862639427185 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2313}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:16:46,717] Trial 39 finished with value: 1.864235758781433 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3822}. Best is trial 21 with value: 0.7885860800743103.\n",
      "[I 2024-01-22 20:22:21,009] Trial 40 finished with value: 0.7764527797698975 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4681}. Best is trial 40 with value: 0.7764527797698975.\n",
      "[I 2024-01-22 20:27:51,449] Trial 41 finished with value: 0.8841732740402222 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4602}. Best is trial 40 with value: 0.7764527797698975.\n",
      "[I 2024-01-22 20:31:02,580] Trial 42 finished with value: 0.8116037845611572 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2647}. Best is trial 40 with value: 0.7764527797698975.\n",
      "[I 2024-01-22 20:36:41,027] Trial 43 finished with value: 1.753060221672058 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4767}. Best is trial 40 with value: 0.7764527797698975.\n",
      "[I 2024-01-22 20:40:13,586] Trial 44 finished with value: 0.7740398049354553 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2974}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 20:43:43,386] Trial 45 finished with value: 0.92420494556427 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2953}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 20:48:38,169] Trial 46 finished with value: 2.1485183238983154 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4215}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 20:52:28,822] Trial 47 finished with value: 0.8423012495040894 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3269}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 20:58:02,566] Trial 48 finished with value: 0.8254697322845459 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4643}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:01:02,810] Trial 49 finished with value: 0.9319466352462769 and parameters: {'num_hidden_layers': 4, 'num_epochs': 2370}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:05:46,068] Trial 50 finished with value: 1.0828070640563965 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3947}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:09:03,751] Trial 51 finished with value: 0.9615923762321472 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2744}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:12:03,505] Trial 52 finished with value: 0.9712897539138794 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2549}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:17:53,670] Trial 53 finished with value: 0.9463488459587097 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4931}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:21:41,167] Trial 54 finished with value: 0.9216946363449097 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3167}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:26:19,199] Trial 55 finished with value: 1.7160900831222534 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3485}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:29:32,943] Trial 56 finished with value: 1.2408455610275269 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2621}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:33:09,489] Trial 57 finished with value: 0.7835879921913147 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2982}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:37:00,767] Trial 58 finished with value: 0.8420765995979309 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3022}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:41:41,450] Trial 59 finished with value: 1.2194374799728394 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3723}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:45:49,012] Trial 60 finished with value: 0.9176470637321472 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3223}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:49:23,140] Trial 61 finished with value: 0.874194860458374 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2957}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:52:01,631] Trial 62 finished with value: 0.828984797000885 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2202}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:55:26,184] Trial 63 finished with value: 0.8972189426422119 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2817}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 21:58:38,869] Trial 64 finished with value: 4.106838703155518 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2655}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:01:36,205] Trial 65 finished with value: 0.9461801052093506 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2409}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:07:07,110] Trial 66 finished with value: 2.0562169551849365 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4277}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:11:08,377] Trial 67 finished with value: 0.8553691506385803 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3376}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:13:16,303] Trial 68 finished with value: 1.3718581199645996 and parameters: {'num_hidden_layers': 1, 'num_epochs': 1697}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:17:07,259] Trial 69 finished with value: 1.007861852645874 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2901}. Best is trial 44 with value: 0.7740398049354553.\n",
      "[I 2024-01-22 22:22:45,091] Trial 70 finished with value: 0.7078325748443604 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4499}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:28:03,375] Trial 71 finished with value: 0.7392086386680603 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4469}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:33:22,866] Trial 72 finished with value: 0.9284835457801819 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4536}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:38:43,860] Trial 73 finished with value: 0.9865684509277344 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4747}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:43:02,456] Trial 74 finished with value: 0.9426150918006897 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4049}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:47:53,272] Trial 75 finished with value: 0.9015182852745056 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4343}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:52:25,207] Trial 76 finished with value: 0.867832601070404 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4109}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 22:58:08,457] Trial 77 finished with value: 1.658538579940796 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4868}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:03:07,486] Trial 78 finished with value: 0.8698704838752747 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4425}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:08:32,369] Trial 79 finished with value: 1.8018943071365356 and parameters: {'num_hidden_layers': 5, 'num_epochs': 4517}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:12:52,644] Trial 80 finished with value: 1.0070542097091675 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3833}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:17:52,421] Trial 81 finished with value: 2.975590467453003 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4657}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:20:34,788] Trial 82 finished with value: 0.8178554177284241 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2505}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:25:03,978] Trial 83 finished with value: 0.8558341264724731 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4230}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:30:21,161] Trial 84 finished with value: 3.725637674331665 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4999}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:33:44,154] Trial 85 finished with value: 0.9000132083892822 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3049}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:36:43,980] Trial 86 finished with value: 0.8821213841438293 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2805}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:39:58,711] Trial 87 finished with value: 1.9630018472671509 and parameters: {'num_hidden_layers': 6, 'num_epochs': 2603}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:43:57,013] Trial 88 finished with value: 0.8224080204963684 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3568}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:49:03,481] Trial 89 finished with value: 0.8268110752105713 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4814}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:52:40,453] Trial 90 finished with value: 1.373415470123291 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3130}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:55:42,326] Trial 91 finished with value: 0.8982154130935669 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2702}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-22 23:58:54,048] Trial 92 finished with value: 2.7647502422332764 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2883}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:04:05,934] Trial 93 finished with value: 1.4381635189056396 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4698}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:06:30,662] Trial 94 finished with value: 0.9227430820465088 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2229}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:09:21,666] Trial 95 finished with value: 1.0294835567474365 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2449}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:12:50,343] Trial 96 finished with value: 0.8348233699798584 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3206}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:17:43,203] Trial 97 finished with value: 0.7589238286018372 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4561}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:22:38,880] Trial 98 finished with value: 0.8614574074745178 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4564}. Best is trial 70 with value: 0.7078325748443604.\n",
      "[I 2024-01-23 00:27:08,012] Trial 99 finished with value: 0.830962061882019 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4143}. Best is trial 70 with value: 0.7078325748443604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'num_hidden_layers': 1, 'num_epochs': 4499}\n",
      "Mejor MAE encontrada: 0.7078325748443604\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cargar los datos en un data frame\n",
    "data = pd.read_csv('/Users/User/Desktop/Proyecto-CF/proyecto/data/Consolidado/Datos-Proyeccion-Natalidad.csv')  \n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data.iloc[:, 0:4]  # Primeras cuatro columnas como características\n",
    "y = data.iloc[:, 4:]    # Última columna como etiqueta\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "# Obtener las características y las etiquetas de entrenamiento y prueba\n",
    "train_features = X_train[['Año', 'FPI (Nominal)', 'Precio Brent', 'Mundo (Inflacion)']]\n",
    "train_labels = y_train['Mundo (Natalidad)']\n",
    "test_features = X_test[['Año', 'FPI (Nominal)', 'Precio Brent', 'Mundo (Inflacion)']]\n",
    "test_labels = y_test['Mundo (Natalidad)']\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir los hiperparámetros a optimizar\n",
    "    #num_neurons = trial.suggest_int('n_neurons_layers', 32, 512)\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 6)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 1000, 5000)\n",
    "\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(300, activation='relu', input_dim=4))\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(layers.Dense(300, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(train_features, train_labels\n",
    "                        , epochs=num_epochs\n",
    "                        , validation_data=(X_test, y_test)                  \n",
    "                        ,batch_size=32\n",
    "                       , verbose=0\n",
    "                       )\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    loss,mae = model.evaluate(test_features, test_labels, verbose=0)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Crear el estudio de Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials = 100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)\n",
    "print(\"Mejor MAE encontrada:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f051f2-2192-416e-a787-5ecab407673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-23 01:09:11,248] A new study created in memory with name: no-name-19156e14-c36c-45ec-bd72-f03852eaf151\n",
      "[I 2024-01-23 01:11:24,798] Trial 0 finished with value: 2.003121852874756 and parameters: {'num_hidden_layers': 5, 'num_epochs': 1838}. Best is trial 0 with value: 2.003121852874756.\n",
      "[I 2024-01-23 01:15:07,393] Trial 1 finished with value: 2.6674082279205322 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3124}. Best is trial 0 with value: 2.003121852874756.\n",
      "[I 2024-01-23 01:20:05,986] Trial 2 finished with value: 1.245800256729126 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4254}. Best is trial 2 with value: 1.245800256729126.\n",
      "[I 2024-01-23 01:22:31,219] Trial 3 finished with value: 1.477622389793396 and parameters: {'num_hidden_layers': 5, 'num_epochs': 1934}. Best is trial 2 with value: 1.245800256729126.\n",
      "[I 2024-01-23 01:26:05,585] Trial 4 finished with value: 0.8437697291374207 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3227}. Best is trial 4 with value: 0.8437697291374207.\n",
      "[I 2024-01-23 01:27:22,462] Trial 5 finished with value: 2.202134609222412 and parameters: {'num_hidden_layers': 5, 'num_epochs': 1035}. Best is trial 4 with value: 0.8437697291374207.\n",
      "[I 2024-01-23 01:31:05,049] Trial 6 finished with value: 0.7389549612998962 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3334}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:33:39,581] Trial 7 finished with value: 0.8416519165039062 and parameters: {'num_hidden_layers': 4, 'num_epochs': 2173}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:35:14,401] Trial 8 finished with value: 1.2196059226989746 and parameters: {'num_hidden_layers': 1, 'num_epochs': 1438}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:38:57,778] Trial 9 finished with value: 1.9188199043273926 and parameters: {'num_hidden_layers': 6, 'num_epochs': 3033}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:44:17,368] Trial 10 finished with value: 0.9498827457427979 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4834}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:46:54,751] Trial 11 finished with value: 2.264742851257324 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2291}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:49:48,785] Trial 12 finished with value: 0.8272168636322021 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2554}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:54:04,856] Trial 13 finished with value: 0.8342501521110535 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3897}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 01:58:16,266] Trial 14 finished with value: 1.5913594961166382 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3735}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:00:55,002] Trial 15 finished with value: 0.8172054290771484 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2469}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:03:53,547] Trial 16 finished with value: 8.323813438415527 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2759}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:07:39,977] Trial 17 finished with value: 0.8479554653167725 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3564}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:12:29,852] Trial 18 finished with value: 0.8729453682899475 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4422}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:15:16,855] Trial 19 finished with value: 0.9326913356781006 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2607}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:17:10,409] Trial 20 finished with value: 1.4266804456710815 and parameters: {'num_hidden_layers': 2, 'num_epochs': 1676}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:20:06,180] Trial 21 finished with value: 1.0338892936706543 and parameters: {'num_hidden_layers': 3, 'num_epochs': 2529}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:24:01,887] Trial 22 finished with value: 0.9200360774993896 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3425}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:27:09,972] Trial 23 finished with value: 0.8369377851486206 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2820}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:29:43,047] Trial 24 finished with value: 1.5671381950378418 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2332}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:34:24,008] Trial 25 finished with value: 2.117258071899414 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3981}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:38:14,143] Trial 26 finished with value: 1.1742634773254395 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3325}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:40:36,188] Trial 27 finished with value: 1.026120901107788 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2075}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:43:49,345] Trial 28 finished with value: 0.8522979021072388 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2900}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:46:48,552] Trial 29 finished with value: 0.9375656843185425 and parameters: {'num_hidden_layers': 4, 'num_epochs': 2493}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:48:51,426] Trial 30 finished with value: 1.69315505027771 and parameters: {'num_hidden_layers': 3, 'num_epochs': 1758}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:53:01,809] Trial 31 finished with value: 0.9903342127799988 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3682}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 02:57:35,488] Trial 32 finished with value: 0.9282097220420837 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4014}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:01:01,484] Trial 33 finished with value: 0.8928964138031006 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3103}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:06:07,828] Trial 34 finished with value: 0.876008152961731 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4531}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:10:53,408] Trial 35 finished with value: 1.0733388662338257 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4136}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:15:17,496] Trial 36 finished with value: 0.7992545366287231 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3883}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:19:01,673] Trial 37 finished with value: 0.9022782444953918 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3429}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:22:53,632] Trial 38 finished with value: 1.4092704057693481 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3238}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:25:06,651] Trial 39 finished with value: 0.9564946293830872 and parameters: {'num_hidden_layers': 2, 'num_epochs': 1929}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:27:02,646] Trial 40 finished with value: 1.8055930137634277 and parameters: {'num_hidden_layers': 6, 'num_epochs': 1449}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:31:35,568] Trial 41 finished with value: 0.7832423448562622 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3798}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:36:31,828] Trial 42 finished with value: 0.8997715711593628 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4261}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:40:55,185] Trial 43 finished with value: 1.5188162326812744 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3710}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:44:13,589] Trial 44 finished with value: 26.78532600402832 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2955}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:49:45,059] Trial 45 finished with value: 1.4489415884017944 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4738}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:54:10,063] Trial 46 finished with value: 0.8100147247314453 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3834}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 03:58:21,974] Trial 47 finished with value: 0.8080887198448181 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3816}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:02:45,639] Trial 48 finished with value: 0.8655613660812378 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3818}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:07:15,432] Trial 49 finished with value: 1.7798075675964355 and parameters: {'num_hidden_layers': 5, 'num_epochs': 3548}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:12:32,319] Trial 50 finished with value: 0.824845016002655 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4287}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:17:23,442] Trial 51 finished with value: 2.504411458969116 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4031}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:21:38,629] Trial 52 finished with value: 0.846912145614624 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3553}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:26:17,757] Trial 53 finished with value: 0.9489139914512634 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3788}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:31:25,470] Trial 54 finished with value: 0.8664410710334778 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4515}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:35:57,181] Trial 55 finished with value: 1.084563136100769 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3902}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:41:02,932] Trial 56 finished with value: 1.0946344137191772 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4133}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:44:39,731] Trial 57 finished with value: 0.9920264482498169 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3190}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:48:21,258] Trial 58 finished with value: 0.9054332375526428 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3384}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:52:30,519] Trial 59 finished with value: 0.8673593997955322 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3547}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 04:56:41,231] Trial 60 finished with value: 0.8046192526817322 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3657}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:00:46,366] Trial 61 finished with value: 1.0880099534988403 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3662}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:03:51,097] Trial 62 finished with value: 1.3675073385238647 and parameters: {'num_hidden_layers': 2, 'num_epochs': 2693}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:08:04,873] Trial 63 finished with value: 0.8608076572418213 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3868}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:12:44,777] Trial 64 finished with value: 0.825954020023346 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4126}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:16:11,337] Trial 65 finished with value: 1.0593537092208862 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3036}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:20:13,239] Trial 66 finished with value: 0.8808591365814209 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3471}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:24:12,438] Trial 67 finished with value: 0.7917084097862244 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3666}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:28:10,661] Trial 68 finished with value: 0.7538735866546631 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3646}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:31:47,634] Trial 69 finished with value: 0.813995361328125 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3301}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:35:48,688] Trial 70 finished with value: 16.920698165893555 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3694}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:40:06,935] Trial 71 finished with value: 6.909757614135742 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3913}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:45:02,564] Trial 72 finished with value: 1.0307409763336182 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4364}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:49:03,632] Trial 73 finished with value: 0.8649154305458069 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3614}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:53:11,716] Trial 74 finished with value: 0.7972403764724731 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3785}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 05:56:58,889] Trial 75 finished with value: 1.014809250831604 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3459}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:01:21,260] Trial 76 finished with value: 0.7748684287071228 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4019}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:05:43,766] Trial 77 finished with value: 0.762277364730835 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4043}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:10:10,392] Trial 78 finished with value: 0.7823880314826965 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4104}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:14:34,654] Trial 79 finished with value: 0.9272971749305725 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3997}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:19:09,233] Trial 80 finished with value: 1.236339807510376 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4178}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:23:28,719] Trial 81 finished with value: 0.9724757075309753 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4030}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:28:20,617] Trial 82 finished with value: 0.8912864327430725 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4486}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:33:23,746] Trial 83 finished with value: 0.8398617506027222 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4625}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:38:05,607] Trial 84 finished with value: 0.8084774017333984 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4295}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:42:22,883] Trial 85 finished with value: 0.8791497349739075 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3944}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:46:27,205] Trial 86 finished with value: 0.9824349880218506 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3752}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:51:05,600] Trial 87 finished with value: 0.8518267869949341 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4097}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 06:56:49,103] Trial 88 finished with value: 1.9099262952804565 and parameters: {'num_hidden_layers': 6, 'num_epochs': 4396}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:02:40,870] Trial 89 finished with value: 0.8048651218414307 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4963}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:07:45,712] Trial 90 finished with value: 0.8513098955154419 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4192}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:12:09,300] Trial 91 finished with value: 0.8566229343414307 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3636}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:16:47,291] Trial 92 finished with value: 0.9305858612060547 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3795}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:20:39,955] Trial 93 finished with value: 0.8814923763275146 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3254}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:24:47,080] Trial 94 finished with value: 0.9582854509353638 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3496}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:29:00,261] Trial 95 finished with value: 0.8519717454910278 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3375}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:34:14,571] Trial 96 finished with value: 1.5601927042007446 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4056}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:38:58,712] Trial 97 finished with value: 0.7820250391960144 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3926}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:43:44,846] Trial 98 finished with value: 0.8029187321662903 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3935}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:48:11,276] Trial 99 finished with value: 0.8412530422210693 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3755}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:52:49,409] Trial 100 finished with value: 0.8101414442062378 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3885}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 07:58:07,479] Trial 101 finished with value: 0.78255295753479 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4220}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:03:21,405] Trial 102 finished with value: 1.0124479532241821 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4198}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:09:19,882] Trial 103 finished with value: 1.886635661125183 and parameters: {'num_hidden_layers': 5, 'num_epochs': 4276}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:14:17,953] Trial 104 finished with value: 0.9200111031532288 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4006}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:19:01,483] Trial 105 finished with value: 0.9029204249382019 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3845}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:24:18,784] Trial 106 finished with value: 0.7585281729698181 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4348}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:29:55,105] Trial 107 finished with value: 3.269193649291992 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4679}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:35:15,668] Trial 108 finished with value: 1.3267226219177246 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4387}. Best is trial 6 with value: 0.7389549612998962.\n",
      "[I 2024-01-23 08:40:21,468] Trial 109 finished with value: 0.7075782418251038 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4093}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 08:45:47,728] Trial 110 finished with value: 1.9368716478347778 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4338}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 08:50:54,681] Trial 111 finished with value: 0.8159891963005066 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4091}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 08:56:07,396] Trial 112 finished with value: 1.94596266746521 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4216}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:01:50,127] Trial 113 finished with value: 1.6744694709777832 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4589}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:07:12,600] Trial 114 finished with value: 0.7982139587402344 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4451}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:11:29,139] Trial 115 finished with value: 0.7634620666503906 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3594}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:15:28,085] Trial 116 finished with value: 1.165535807609558 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3114}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:19:45,382] Trial 117 finished with value: 0.8801990151405334 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3556}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:24:04,518] Trial 118 finished with value: 0.8679063320159912 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3691}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:25:22,031] Trial 119 finished with value: 1.6526246070861816 and parameters: {'num_hidden_layers': 1, 'num_epochs': 1049}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:30:13,551] Trial 120 finished with value: 0.8434617519378662 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4109}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:35:01,948] Trial 121 finished with value: 0.77820885181427 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3993}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:39:43,237] Trial 122 finished with value: 0.7288017272949219 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3983}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:44:20,284] Trial 123 finished with value: 0.9677075147628784 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3929}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:49:22,524] Trial 124 finished with value: 0.8383151292800903 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4245}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:54:14,006] Trial 125 finished with value: 0.8990461826324463 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3988}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 09:59:14,028] Trial 126 finished with value: 0.8402743935585022 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4147}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:04:09,966] Trial 127 finished with value: 0.9688385725021362 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4056}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:09:40,028] Trial 128 finished with value: 0.8593398332595825 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4335}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:14:10,715] Trial 129 finished with value: 0.7513859868049622 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3869}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:18:44,210] Trial 130 finished with value: 0.8065914511680603 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3880}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:23:22,636] Trial 131 finished with value: 0.8866547346115112 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3963}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:28:11,978] Trial 132 finished with value: 0.7463387250900269 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4074}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:33:06,257] Trial 133 finished with value: 0.8453258872032166 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4172}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:38:03,422] Trial 134 finished with value: 1.7178446054458618 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4010}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:42:45,059] Trial 135 finished with value: 0.9750334620475769 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4265}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:47:12,246] Trial 136 finished with value: 0.8504551649093628 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4085}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:51:23,860] Trial 137 finished with value: 0.8409936428070068 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3828}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 10:55:39,584] Trial 138 finished with value: 1.0044244527816772 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3735}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:00:01,545] Trial 139 finished with value: 0.8376023769378662 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3958}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:04:05,654] Trial 140 finished with value: 1.1539006233215332 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3615}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:08:30,149] Trial 141 finished with value: 1.1320427656173706 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3774}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:12:57,112] Trial 142 finished with value: 0.859954833984375 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4103}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:17:15,745] Trial 143 finished with value: 7.809780597686768 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3894}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:22:04,606] Trial 144 finished with value: 0.847945511341095 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4185}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:26:29,734] Trial 145 finished with value: 0.7964333295822144 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3990}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:31:05,637] Trial 146 finished with value: 1.9775958061218262 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3839}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:34:56,444] Trial 147 finished with value: 0.9420024156570435 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3345}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:39:53,474] Trial 148 finished with value: 0.8909477591514587 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4425}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:43:59,942] Trial 149 finished with value: 0.8942263126373291 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3714}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:48:36,797] Trial 150 finished with value: 0.9707215428352356 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4051}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:52:35,927] Trial 151 finished with value: 0.8336796164512634 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3567}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 11:56:27,161] Trial 152 finished with value: 0.8368975520133972 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3466}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:00:27,744] Trial 153 finished with value: 4.496942520141602 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3619}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:04:42,392] Trial 154 finished with value: 0.8168754577636719 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3801}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:09:25,867] Trial 155 finished with value: 0.7774257659912109 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4229}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:14:06,776] Trial 156 finished with value: 0.7651469111442566 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4249}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:18:55,182] Trial 157 finished with value: 0.8458561301231384 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4301}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:23:57,807] Trial 158 finished with value: 7.940525531768799 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4504}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:28:37,064] Trial 159 finished with value: 0.939518392086029 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4201}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:33:22,053] Trial 160 finished with value: 0.8894386291503906 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4260}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:37:58,695] Trial 161 finished with value: 1.1956490278244019 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4117}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:42:41,966] Trial 162 finished with value: 0.9257193803787231 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4063}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:47:12,392] Trial 163 finished with value: 0.8052376508712769 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3938}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:52:14,529] Trial 164 finished with value: 1.0513114929199219 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4380}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 12:56:54,129] Trial 165 finished with value: 0.8331025242805481 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4166}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:01:39,134] Trial 166 finished with value: 0.7233649492263794 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4019}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:06:39,897] Trial 167 finished with value: 1.8559725284576416 and parameters: {'num_hidden_layers': 4, 'num_epochs': 4032}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:11:37,571] Trial 168 finished with value: 0.8817683458328247 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4251}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:16:45,198] Trial 169 finished with value: 1.5981343984603882 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4336}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:21:33,276] Trial 170 finished with value: 1.6223479509353638 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4136}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:26:04,681] Trial 171 finished with value: 0.78505939245224 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3881}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:30:38,217] Trial 172 finished with value: 0.7600405216217041 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3996}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:35:09,453] Trial 173 finished with value: 0.7635411024093628 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3970}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:39:30,854] Trial 174 finished with value: 0.7848232984542847 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3988}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:43:57,173] Trial 175 finished with value: 0.8040288090705872 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3925}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:48:33,969] Trial 176 finished with value: 0.8787238001823425 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4063}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:53:11,407] Trial 177 finished with value: 0.8751456141471863 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3998}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 13:57:24,445] Trial 178 finished with value: 0.8423493504524231 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3865}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:02:01,892] Trial 179 finished with value: 0.8589274287223816 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4128}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:06:30,484] Trial 180 finished with value: 4.0988006591796875 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4060}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:11:11,613] Trial 181 finished with value: 0.8133350014686584 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4181}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:15:44,532] Trial 182 finished with value: 0.890381932258606 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3928}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:20:49,064] Trial 183 finished with value: 0.8017275333404541 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4222}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:25:40,877] Trial 184 finished with value: 0.9507696628570557 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4031}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:30:53,115] Trial 185 finished with value: 0.9646546840667725 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4310}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:35:41,509] Trial 186 finished with value: 0.8122539520263672 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4110}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:39:53,411] Trial 187 finished with value: 5.418218612670898 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3778}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:43:37,893] Trial 188 finished with value: 0.8187758326530457 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3175}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:48:11,591] Trial 189 finished with value: 0.8132010698318481 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3955}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:53:27,041] Trial 190 finished with value: 0.9435927271842957 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4429}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 14:57:58,900] Trial 191 finished with value: 0.8436050415039062 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3883}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:02:06,241] Trial 192 finished with value: 1.426433801651001 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3700}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:06:30,743] Trial 193 finished with value: 0.852387547492981 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3839}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:10:56,747] Trial 194 finished with value: 4.127743721008301 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3965}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:15:36,658] Trial 195 finished with value: 0.7955867052078247 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4239}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:19:45,307] Trial 196 finished with value: 0.758922815322876 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3761}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:24:16,066] Trial 197 finished with value: 5.107244491577148 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4129}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:28:22,471] Trial 198 finished with value: 0.8857135772705078 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3750}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:32:47,979] Trial 199 finished with value: 0.8355181217193604 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3996}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:37:21,083] Trial 200 finished with value: 0.8571518659591675 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4053}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:41:34,872] Trial 201 finished with value: 0.9655895233154297 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3824}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:45:55,932] Trial 202 finished with value: 0.9291907548904419 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3909}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:50:09,871] Trial 203 finished with value: 0.8330936431884766 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3695}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:54:52,167] Trial 204 finished with value: 0.812804102897644 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4184}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 15:58:53,711] Trial 205 finished with value: 0.7409250736236572 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3597}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:02:49,423] Trial 206 finished with value: 0.799066960811615 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3504}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:06:49,696] Trial 207 finished with value: 0.7343516945838928 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3568}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:10:47,481] Trial 208 finished with value: 0.9137829542160034 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3592}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:14:44,083] Trial 209 finished with value: 0.8860166072845459 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3498}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:18:03,708] Trial 210 finished with value: 0.8014454245567322 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2902}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:21:44,457] Trial 211 finished with value: 0.882771372795105 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3304}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:25:32,901] Trial 212 finished with value: 0.8304595947265625 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3441}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:29:42,656] Trial 213 finished with value: 0.8180232644081116 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3650}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:33:06,552] Trial 214 finished with value: 0.7885585427284241 and parameters: {'num_hidden_layers': 1, 'num_epochs': 2393}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:37:11,661] Trial 215 finished with value: 0.8489617109298706 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3602}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:41:02,196] Trial 216 finished with value: 0.9253635406494141 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3406}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:45:35,230] Trial 217 finished with value: 0.9906817674636841 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4059}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:49:48,255] Trial 218 finished with value: 0.875944972038269 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3770}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:54:26,615] Trial 219 finished with value: 2.0785322189331055 and parameters: {'num_hidden_layers': 3, 'num_epochs': 3968}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 16:59:10,829] Trial 220 finished with value: 0.885280191898346 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4317}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:03:39,878] Trial 221 finished with value: 0.9693188071250916 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3824}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:08:05,460] Trial 222 finished with value: 2.12672758102417 and parameters: {'num_hidden_layers': 4, 'num_epochs': 3710}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:12:45,838] Trial 223 finished with value: 0.7381030321121216 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4134}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:17:27,096] Trial 224 finished with value: 1.0861926078796387 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4170}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:22:00,246] Trial 225 finished with value: 0.8494232892990112 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4125}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:26:52,647] Trial 226 finished with value: 0.963649332523346 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4244}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:31:47,571] Trial 227 finished with value: 0.9374046325683594 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4070}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:36:29,566] Trial 228 finished with value: 0.8768689632415771 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4001}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:40:46,722] Trial 229 finished with value: 0.8409707546234131 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3881}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:45:33,295] Trial 230 finished with value: 1.1473437547683716 and parameters: {'num_hidden_layers': 3, 'num_epochs': 4104}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:50:00,761] Trial 231 finished with value: 1.0607147216796875 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3963}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:54:24,252] Trial 232 finished with value: 0.8569359183311462 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3866}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 17:58:27,343] Trial 233 finished with value: 0.8606785535812378 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3545}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:02:47,659] Trial 234 finished with value: 0.8019207715988159 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3770}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:07:22,216] Trial 235 finished with value: 0.8755916953086853 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4023}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:11:58,494] Trial 236 finished with value: 0.8034430742263794 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4238}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:16:16,782] Trial 237 finished with value: 0.7903232574462891 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3916}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:18:57,455] Trial 238 finished with value: 1.55189847946167 and parameters: {'num_hidden_layers': 5, 'num_epochs': 2151}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:22:59,692] Trial 239 finished with value: 0.8150069117546082 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3631}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:27:41,684] Trial 240 finished with value: 0.7965462803840637 and parameters: {'num_hidden_layers': 2, 'num_epochs': 4150}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:32:00,705] Trial 241 finished with value: 0.8127032518386841 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3995}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:36:30,856] Trial 242 finished with value: 0.847163736820221 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4052}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:40:45,719] Trial 243 finished with value: 0.8634253740310669 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3931}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:45:05,107] Trial 244 finished with value: 1.04573655128479 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3984}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:49:32,317] Trial 245 finished with value: 17.208101272583008 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4091}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:54:05,980] Trial 246 finished with value: 0.8507126569747925 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4196}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 18:58:20,296] Trial 247 finished with value: 0.9200761318206787 and parameters: {'num_hidden_layers': 1, 'num_epochs': 3854}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 19:02:37,437] Trial 248 finished with value: 0.88189697265625 and parameters: {'num_hidden_layers': 2, 'num_epochs': 3793}. Best is trial 109 with value: 0.7075782418251038.\n",
      "[I 2024-01-23 19:07:22,607] Trial 249 finished with value: 4.269286155700684 and parameters: {'num_hidden_layers': 1, 'num_epochs': 4331}. Best is trial 109 with value: 0.7075782418251038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'num_hidden_layers': 3, 'num_epochs': 4093}\n",
      "Mejor MAE encontrada: 0.7075782418251038\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cargar los datos en un data frame\n",
    "data = pd.read_csv('/Users/User/Desktop/Proyecto-CF/proyecto/data/Consolidado/Datos-Proyeccion-Natalidad.csv')  \n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data.iloc[:, 0:4]  # Primeras cuatro columnas como características\n",
    "y = data.iloc[:, 4:]    # Última columna como etiqueta\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "# Obtener las características y las etiquetas de entrenamiento y prueba\n",
    "train_features = X_train[['Año', 'FPI (Nominal)', 'Precio Brent', 'Mundo (Inflacion)']]\n",
    "train_labels = y_train['Mundo (Natalidad)']\n",
    "test_features = X_test[['Año', 'FPI (Nominal)', 'Precio Brent', 'Mundo (Inflacion)']]\n",
    "test_labels = y_test['Mundo (Natalidad)']\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir los hiperparámetros a optimizar\n",
    "    #num_neurons = trial.suggest_int('n_neurons_layers', 32, 512)\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 6)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 1000, 5000)\n",
    "\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(300, activation='relu', input_dim=4))\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(layers.Dense(300, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(train_features, train_labels\n",
    "                        , epochs=num_epochs\n",
    "                        , validation_data=(X_test, y_test)                  \n",
    "                        ,batch_size=32\n",
    "                       , verbose=0\n",
    "                       )\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    loss,mae = model.evaluate(test_features, test_labels, verbose=0)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Crear el estudio de Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials = 250)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)\n",
    "print(\"Mejor MAE encontrada:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c0077-e032-42f4-9ba2-21ad871b17c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
